<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2025 February 16, 09:39 -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Morality And Selfishness FAQs</title>
<meta name="author" content="Zero Contradictions" />
<meta name="description" content="Morality, selfishness, and altruism are best understood via game theory and biological realism. These FAQs address the objections against moral relativism." />
<meta name="generator" content="Org Mode" />
<meta property="og:url" content="https://zerocontradictions.net/faqs/morality">
<meta property="og:type" content="article">
<meta property="og:image" content="https://zerocontradictions.net/images/bad-guys-vs-anti-bad-guys-meme.jpg">
<link rel="stylesheet" type="text/css" href="/style.css">
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="/directory"> UP </a>
 |
 <a accesskey="H" href="/"> HOME </a>
</div><div id="content" class="content">
<header>
<h1 class="title">Morality And Selfishness FAQs</h1>
<p class="subtitle" role="doc-subtitle">Understanding Morality with Game Theory and Biological Realism</p>
</header><nav id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#intro">1. Introduction (Start Here)</a></li>
<li><a href="#general-questions">2. General Questions</a>
<ul>
<li><a href="#origin-of-morality">2.1. Where does morality come from?</a></li>
<li><a href="#memetic-traditions">2.2. How is morality related to memetic traditions?</a></li>
<li><a href="#evolution-effects-on-morality">2.3. How has evolution affected human morality?</a></li>
<li><a href="#why-value-equality">2.4. Why is equality a common moral value?</a></li>
<li><a href="#deontological-ethics-problems">2.5. Why are consequentialist ethics better than deontological ethics?</a></li>
<li><a href="#morality-and-technology">2.6. Aren&rsquo;t technological advancements driven by improving morality?</a></li>
<li><a href="#amoralism-moral-relativism-nihilism">2.7. What&rsquo;s the difference between moral relativism, amoralism, moral nihilism, etc?</a></li>
<li><a href="#morality-vs-ethics">2.8. What is the difference between morality and ethics?</a></li>
</ul>
</li>
<li><a href="#pragmatosphere-questions">3. Pragmatosphere Specific Questions</a>
<ul>
<li><a href="#biorealism">3.1. What is Biological Realism?</a></li>
<li><a href="#social-darwinism">3.2. What is the difference between Biological Realism and Social Darwinism?</a></li>
<li><a href="#humanism">3.3. What is Humanism?</a></li>
<li><a href="#christianity-humanism-wokism">3.4. What are the differences between Christianity, Humanism, and Wokism?</a></li>
<li><a href="#abyss-for-value">3.5. Why does the Abyss for Truth and Value matter?</a></li>
<li><a href="#shoulds-and-shouldnts">3.6. In terms of should&rsquo;s and shouldn&rsquo;ts, what would be an ideal ethical system?</a></li>
<li><a href="#thoughts-on-less-wrong">3.7. What do you think about rationalist forums like Less Wrong?</a></li>
<li><a href="#effective-altruism">3.8. What do you think about Effective Altruism?</a></li>
</ul>
</li>
<li><a href="#objectivity-questions">4. Subjectivity/Objectivity Questions</a>
<ul>
<li><a href="#why-not-objective">4.1. Why isn&rsquo;t morality objective?</a></li>
<li><a href="#reason-and-morality">4.2. Why can&rsquo;t the reason and rationality be the basis for objective morality?</a></li>
<li><a href="#dangerous-black-and-white-morals">4.3. Why is it dangerous to have a black-and-white sense of morality?</a></li>
<li><a href="#utilitarianism">4.4. Why is Utilitarianism <i>not</i> the best way to define morality?</a></li>
<li><a href="#common-laws">4.5. Most societies have laws that prohibit theft, murder, and rape, so doesn&rsquo;t this indicate that some things are objectively immoral?</a></li>
<li><a href="#cooperation-not-objectively-moral">4.6. Why are contract-ethics and cooperation not objectively moral?</a></li>
<li><a href="#moral-progress">4.7. Isn&rsquo;t historical moral progress evidence that morality is objective?</a></li>
<li><a href="#not-everybody-wants-tech-society">4.8. Surely everybody wants to live in a prosperous, technologically-advanced society, right?</a></li>
<li><a href="#not-an-appeal-to-people">4.9. Isn&rsquo;t it an appeal to the people fallacy to argue for societies based on consensus?</a></li>
<li><a href="#not-a-subjectivist-fallacy">4.10. Isn&rsquo;t it a subjectivist fallacy to insist that morality is perspective-dependent?</a></li>
<li><a href="#standpoint-theory-meaninglessness">4.11. The Meaninglessness of the Standpoint Theory of Truth</a></li>
<li><a href="#Qs-for-moralists">4.12. Questions For Moralists About Universal Rights</a></li>
<li><a href="#when-life-becomes-zero-sum">4.13. When Life Becomes Zero-Sum</a></li>
</ul>
</li>
<li><a href="#selfishnes-vs-altruism-questions">5. Selfishness Versus Altruism Questions</a>
<ul>
<li><a href="#selfishness-definitions">5.1. Wouldn&rsquo;t a more coherent definition of the word &ldquo;selfishness&rdquo; be &ldquo;pursuing your own interests at the expense of others&rdquo;?</a></li>
<li><a href="#altruism-and-evolution">5.2. Isn&rsquo;t Altruism part of human evolution?</a>
<ul>
<li><a href="#reciprocal-altruism">5.2.1. What about Reciprocal Altruism?</a></li>
<li><a href="#kin-selection-theory-bogus">5.2.2. What about Kin Selection Theory providing a basis for Altruism?</a></li>
<li><a href="#bees-and-ants-arent-altruistic">5.2.3. Aren&rsquo;t worker ants and worker bees examples of altruism existing in Nature, since they can&rsquo;t reproduce and thus only work for the good of their species?</a></li>
</ul>
</li>
<li><a href="#helping-others">5.3. Doesn&rsquo;t helping out your friends and family count as altruism?</a></li>
<li><a href="#helping-everybody">5.4. Why shouldn&rsquo;t we help everybody?</a></li>
<li><a href="#cynicalism-is-not-selfishness">5.5. Isn&rsquo;t it misguided to have such a cynical view of human nature?</a></li>
<li><a href="#why-we-should-be-selfish">5.6. Why should we be selfish?</a></li>
<li><a href="#altruism-and-civilization">5.7. Isn&rsquo;t Altruism integral to human civilization?</a></li>
<li><a href="#cooperation-vs-collectivism">5.8. What is the difference between cooperation versus collectivism?</a></li>
</ul>
</li>
<li><a href="#libertarian-questions">6. Libertarian Questions</a>
<ul>
<li><a href="#the-NAP">6.1. Isn&rsquo;t the Libertarian Non-Aggression Principle (NAP) the objective origin of morality?</a></li>
<li><a href="#necessary-evil">6.2. But there&rsquo;s no such thing as a necessary evil.</a></li>
<li><a href="#universally-preferable">6.3. Why isn&rsquo;t morality the same thing as &ldquo;universally preferable behavior&rdquo;?</a></li>
</ul>
</li>
<li><a href="#technology-and-moral-progress">7. How Does Technology Create The Illusion Of Moral Progress?</a>
<ul>
<li><a href="#illusions-in-moralist-communities">7.1. Technological Changes That Various Moralists Would Claim To Be &ldquo;Moral Progress&rdquo;</a></li>
<li><a href="#ideologies-future-progress">7.2. Future Moral Progress According To Various Ideologues</a></li>
<li><a href="#moral-progress-without-tech">7.3. &ldquo;Moral Progress&rdquo; That Wasn&rsquo;t Caused By Advancing Technology</a></li>
</ul>
</li>
<li><a href="#glossary">8. Glossary</a></li>
</ul>
</div>
</nav>

<div id="outline-container-intro" class="outline-2">
<h2 id="intro"><span class="section-number-2">1.</span> Introduction (Start Here)</h2>
<div class="outline-text-2" id="text-intro">
<p>
Many of the questions on this page address the same objections and misunderstandings, so it will feel repetitive and redundant to read <i>all</i> the questions and answers on this page.
If you would like to read an actual essay that would answer many potential questions in a more structured format, then we recommend the following:
</p>
<ul class="org-ul">
<li><a href="https://thewaywardaxolotl.blogspot.com/2020/07/what-is-morality.html">What Is Morality?</a>: This essay explains what morality is.</li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2024/08/the-case-against-moral-realism.html">The Case Against Moral Realism</a>: This essay is an explicit refutation against moral realism and most secular conceptions of morality (though it&rsquo;s relevant to non-secular conceptions as well).</li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-value.html">What Is Value?</a>: This essay explains what value is.</li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2024/07/sam-harriss-argument-for-objective.html">Refuting Sam Harris&rsquo;s Argument For Objective Morality</a>.</li>
</ul>

<p>
Summary of this Ethical Philosophy:
</p>
<ul class="org-ul">
<li>Morality depends on value, and value is perspective-dependent. <a href="../epistemology/axiology">There is no objective foundation for value</a>. Likewise for morality.</li>
<li>Morality is heavily shaped by <a href="https://thewaywardaxolotl.blogspot.com/2017/09/evolution-and-morality.html">evolution</a> and <a href="https://thewaywardaxolotl.blogspot.com/2015/12/god-is-telomeme.html">memetic traditions and fashions</a>. Most people&rsquo;s moral values <a href="#origin-of-morality">were formed in a 6-step process</a>.</li>
<li><a href="#kin-selection-theory-bogus">Every purported example of altruism occurring in nature is actually selfishness</a>.</li>
<li>It&rsquo;s unreasonable to oppose natural phenomena that are beyond mankind&rsquo;s control. For example, it&rsquo;s unreasonable to oppose hierarchy because social hierarchies are natural and <a href="https://en.wikipedia.org/wiki/The_Son_Also_Rises_(book)">they&rsquo;re often strongly influenced by people&rsquo;s genetics</a>, which we cannot change. For similar reasons, it&rsquo;s also pointless to oppose <a href="https://thewaywardaxolotl.blogspot.com/2015/09/life-is-violent.html">violence in nature</a>, to <a href="../misc/case-against-efilism#self-defeating">oppose the existence of life (efilism)</a>, or to <a href="https://www.reddit.com/r/AntiVegan/wiki/index/health">be vegan if it&rsquo;s necessary for humans to eat animals in order to be healthy</a>.</li>
<li><a href="../civilization/political-philosophy#intro">Evolutionary Biology is the best initial field to study for forming social frameworks</a>.</li>
<li>&ldquo;Moral Progress&rdquo; is an <a href="#technology-and-moral-progress">illusion that is primarily created by the advancement of technology</a>.</li>
<li>Without cooperation, <a href="#when-life-becomes-zero-sum">life becomes zero-sum when the population reaches the carrying capacity</a> of its environment.</li>
</ul>
<p>
Note: Given that there are so many diverse ideas, viewpoints, and moral philosophies that a random person could have about morality, it&rsquo;s likely that only a fraction of these FAQs will answer any random people&rsquo;s questions or beliefs about morality.
But many of these questions are discussed often, and it&rsquo;s convenient for other pages on this website to link to these questions and explanations when relevant, hence why this page exists.
</p>
</div>
</div>

<div id="outline-container-general-questions" class="outline-2">
<h2 id="general-questions"><span class="section-number-2">2.</span> General Questions</h2>
<div class="outline-text-2" id="text-general-questions">
</div>
<div id="outline-container-origin-of-morality" class="outline-3">
<h3 id="origin-of-morality"><span class="section-number-3">2.1.</span> Where does morality come from?</h3>
<div class="outline-text-3" id="text-origin-of-morality">
<p>
In this context, we are defining morality as &ldquo;what a person thinks people should and shouldn&rsquo;t do, i.e. what a person <i>wants</i> other people to do, <a href="../epistemology/axiology">according to their values</a>&rdquo;, which is usually coupled with the assumption/belief that those values are objective.
More simply, morality may be defined as the belief in objective value.
Note that &ldquo;morality&rdquo; has <a href="https://en.wiktionary.org/wiki/morality#English">many different definitions</a>, so it is highly vulnerable to the <a href="../language/sapir-whorf-theory">Sapir-Whorf Effect</a>.
</p>


<p>
Morality originates from one&rsquo;s personal values, in a 6-step process that typically consists of:
</p>
<ul class="org-ul">
<li>Collective values.</li>
<li>The individual internalization of collective values.</li>
<li>The assumption that collective values are objective, and thus &ldquo;moral&rdquo;.</li>
<li>A folk theory of morality.</li>
<li>Individual and collective moral myths.</li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2023/10/israel-palestine-and-moral-confusion.html?m=1">Pattern-matching situations</a> with evaluated moral judgements and assumptions to situations that are unevaluated or need to be re-evaluated.</li>
</ul>

<p>
Read More: <a href="https://thewaywardaxolotl.blogspot.com/2020/07/what-is-morality.html">What is Morality?</a>
</p>
</div>
</div>

<div id="outline-container-memetic-traditions" class="outline-3">
<h3 id="memetic-traditions"><span class="section-number-3">2.2.</span> How is morality related to memetic traditions?</h3>
<div class="outline-text-3" id="text-memetic-traditions">
<p>
To a large extent, culture is arbitrary.
Other aspects are less arbitrary in the sense that there are strong tendencies for different cultures to arrive at the same customs.
Many of these less arbitrary customs and taboos originated because they increased the reproductive success of the people who practiced them to the point of becoming dominant habits within the culture.
These are also known as <a href="https://thewaywardaxolotl.blogspot.com/2015/12/god-is-telomeme.html">traditions</a>.
Over time, these traditions and taboos come to be collective values of the practicing cultures.
In turn, they form a substantial basis for what is deemed &ldquo;moral&rdquo; and &ldquo;immoral&rdquo;.
The traditions then propagate onto the next generations via the individual internalization of collective values for every individual.
</p>

<p>
More Information: <a href="https://thewaywardaxolotl.blogspot.com/2020/07/what-is-morality.html">What is Morality? - Blithering Genius</a>
</p>
</div>
</div>

<div id="outline-container-evolution-effects-on-morality" class="outline-3">
<h3 id="evolution-effects-on-morality"><span class="section-number-3">2.3.</span> How has evolution affected human morality?</h3>
<div class="outline-text-3" id="text-evolution-effects-on-morality">
<p>
Main Essay: <a href="https://thewaywardaxolotl.blogspot.com/2017/09/evolution-and-morality.html">Evolution and Morality - Blithering Genius</a>.
</p>

<ul class="org-ul">
<li>Evolution selected for egoism and selfishness over altruism. Hence, altruism is a losing reproductive strategy whenever there is a competing pro-selfishness strategy.</li>
<li>Since mutual cooperation among selfishness individuals enables each individual to gain more than if they each worked alone, humans evolved a emotional accounting system to keep track of what they owe and what they are owed from their respective communities.</li>
<li>Humans have a natural intuition that life is good and life should be preserved in many cases, even when it&rsquo;s not very practical (e.g. pro-lifers being against abortion, people against death penalties, people against suicide, assisted suicide, or even suicide with dignity, etc).</li>
<li>Humans are more likely to favor their children, spouses, family, friends, and other people in their social networks and communities over outsiders, in terms of perks, special advice/tips/tricks, and goods (cronyism/tribalism/favoritism).</li>
<li>Humans are tribalistic, and develop their own internal labels for who to designate within their in-groups and out-groups.</li>
<li>Humanists view love as sacred, even though it doesn&rsquo;t exist merely to make humans feel good. Likewise, people may feel spiteful and vengeful when their partners cheat or break up with them. Regarding cheating, this implicitly causes humans to value consent.</li>
<li>Humans dislike loneliness and favor being in communities and groups.</li>
<li>Humans will tend to justify themselves, even if doing so is hypocritical or wrong from the collective moral perspective.</li>
</ul>
</div>
</div>

<div id="outline-container-why-value-equality" class="outline-3">
<h3 id="why-value-equality"><span class="section-number-3">2.4.</span> Why is equality a common moral value?</h3>
<div class="outline-text-3" id="text-why-value-equality">
<p>
There are various reasons why it makes sense to value equality from a societal perspective:
</p>

<ul class="org-ul">
<li>Social Stability: Societies that strive for equality may be more stable than less equal societies, depending on the balance of power between all of society&rsquo;s members. Equality is more likely to be achieved when <i>power</i> has a relatively equal distribution among a population. For instance, it&rsquo;s not easy for a dictator to rise to amass great power and rule with an iron fist when <a href="../faqs/pro-gun-arguments-guide.pdf">every other citizen is armed with a gun</a>.</li>
<li>Uniformity: The more uniform everything is in an industrial civilization, the more interchangeable and thus cheaper everything becomes.</li>
<li>Meritocracy: Equality is necessary for meritocracy. If people are born with less equal opportunities than others, then human capital is more likely to be misallocated.</li>
<li>Economic Prosperity: Reducing economic inequality may increase economic prosperity and growth. When wealth is distributed more evenly, a larger portion of the population has the means to participate in economic activities.</li>
</ul>
<p>
There are also historical reasons why modern culture values equality.
Equality and altruism are both Christian values.
<a href="#humanism">Humanism</a> is the main ideology of the Modern West and it arose from Humanism.
The Holocaust, the defeat of the Nazis, and the baby boom that caused the <a href="https://thewaywardaxolotl.blogspot.com/2017/06/the-sixties.html">1960s counter-culture</a> were the most pivotal series of social events in the 20th century.
It strengthened the Western value in equality to become a dominant social value.
It initiated <a href="../civilization/wokism#wokism-theory">the transition</a> from Christianity to Humanism and Wokism]].
</p>

<p>
Thomas Jefferson&rsquo;s &ldquo;all men are created equal&rdquo; was about rejecting the divine right of kings.
However, some ideologues ignore this context and teach that the Founding Fathers of the United States believed in their ideological definition of equality, as opposed to stability or freedom.
This is a misinterpretation, and thus not true.
</p>

<hr>

<p>
There are limitations to valuing equality.
If we made everyone 100% equal in wealth, then other inequalities would matter more anyway, e.g. genetic inequality, sexual inequality, moral inequality, etc.
Only 20% of people can be in the top 20% of anything (wealth, social status, talents, looks, etc).
Since humans will always be unequal in some way, it&rsquo;s futile to prioritize wealth and other forms of energy equality as a moral goal.
<a href="../civilization/wokism#demographic-quotas">The same argument can also be made against demographic quotas</a> and why they&rsquo;re equally pointless to pursue.
There are also no reasons why people have to value equality from a purely individualist perspective.
Equality is a means to an end.
From a biological perspective, the best society is the one that does everything to serve you, while you give nothing in return.
<a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Humans are intrinsically selfish</a>.
</p>


<p>
List of things that not everybody can have in a society:
</p>
<ul class="org-ul">
<li>Genes that are optimized for doing some particular task(s) or advantage(s).
<ul class="org-ul">
<li>Intelligence</li>
<li>Other Genetic Tradeoffs</li>
</ul></li>
<li>Social Status
<ul class="org-ul">
<li>Fame &amp; Fortune</li>
<li>Wealth (to some extent)</li>
<li>Beauty</li>
</ul></li>
<li>Equality</li>
<li>Et Cetera</li>
</ul>
<p>
To some extent, Equality is more of an idealistic concept, rather than a realistic concept.
It&rsquo;s something that people and societies want to aim for in many contexts.
However, it&rsquo;s not always possible, since it&rsquo;s always defined relative to the current condition, and since desires are limitless.
</p>


<figure id="orgb6f30aa">
<img src="../images/inequality-equality-equity-justice.jpg" alt="Inequality, Equality, Equity, and &quot;Justice&quot;." width="676">

<figcaption><span class="figure-number">Figure 1: </span>Some woke SJWs have even more extreme perspectives on &ldquo;equality&rdquo;, &ldquo;equity&rdquo;, and &ldquo;justice&rdquo;. This image has <a href="https://brittonicmemetics.wordpress.com/2020/08/10/equality/">a lot of metaphors that don&rsquo;t map well onto reality</a>.</figcaption>
</figure>

<p>
Read more: <a href="../civilization/wokism#wokism-theory">What caused the rise of wokism?</a>
</p>
</div>
</div>

<div id="outline-container-deontological-ethics-problems" class="outline-3">
<h3 id="deontological-ethics-problems"><span class="section-number-3">2.5.</span> Why are consequentialist ethics better than deontological ethics?</h3>
<div class="outline-text-3" id="text-deontological-ethics-problems">
<p>
Some people view morality as a list of rules that shall never be violated.
The justification at a macro-level is that these rules have consequences that cannot be considered at a micro-level.
To put this in perspective, let&rsquo;s take the example of lying.
If a drug addict lies to a police officer about the presence of cocaine in his house, he can avoid getting arrested.
But if too many people lie, then people won&rsquo;t trust each other.
Here the micro level concern is getting arrested, and the macro level concern is social trust.<sup><a id="fnr.1" class="footref" href="#fn.1" role="doc-backlink">1</a></sup>
</p>

<p>
Deontology needlessly elevates the value of rules over the consequences of them.
Rules cannot be reasonably formed without some sort of appeal to consequence, because <a href="../epistemology/axiology#what-are-values">it&rsquo;s not possible to judge a value without another value to judge it by</a>.
When rules and values are made without appreciating the consequences of them, they become arbitrary and shitty.
For example, you can&rsquo;t explain why a rule saying that a man can have sex with whichever women he wants is a bad rule without an appeal to the consequences of that rule.
You could argue that the first rule violates the autonomy of the women.
However, you would need to justify why women are entitled to a certain amount of autonomy, which requires appealing to the consequences of implementing that autonomy.
In these scenarios, the appeal of the Non-Aggression comes from reducing the amount of coercion that occurs.
<span class="underline"><i>If the justification for the NAP ultimately appeals to consequences, then why not evaluate the actions and specific rules you make based on the consequences themselves, rather than some general rule that doesn&rsquo;t always work out?</i></span>
</p>

<p>
It is true that rules are important for setting precedents.
If people stole and pirated whenever they want in a society, people would be less incentivized to create wealth, which is a net negative.
On the other hand, respecting private property creates a macro-level effect of encouraging wealth because people will think it won&rsquo;t be stolen.
However, would 10 acts of fraud intended to fund research into embryo selection be ethical? I would say yes – you increase the amount of utility in the society without severely damaging the precedent of private property.
10 acts of fraud are the kind of crime that makes the papers for a few days until people forget about it, rather than something that seriously undermines people&rsquo;s trust.
</p>

<p>
Sure, people frequently engaging in actions that break rules would undermine the precedents that these rules uphold.
However, there are clearly violations of rules that don&rsquo;t break the precedent they set.
Let&rsquo;s take private property as an example.
When people having a right to property, that incentivizes them to protect it and create more value.
Taxing people at the threat of incarceration would be a violation of private property.
However, if these taxes are used for institutions that help uphold private property, then there is no moral objection to it as they are massively preventing the very thing they are violating.
</p>


<p>
Read More: <a href="../epistemology/reasoning-skills#appeal-to-consequences">When Appeal to Consequences <i>is</i> a Valid Fallacy</a>.
</p>
</div>
</div>

<div id="outline-container-morality-and-technology" class="outline-3">
<h3 id="morality-and-technology"><span class="section-number-3">2.6.</span> Aren&rsquo;t technological advancements driven by improving morality?</h3>
<div class="outline-text-3" id="text-morality-and-technology">
<p>
No, this is backwards. &ldquo;Moral progress&rdquo; is an illusion, and <a href="#technology-and-moral-progress">the illusion is created by technological advancements</a>.
</p>
</div>
</div>

<div id="outline-container-amoralism-moral-relativism-nihilism" class="outline-3">
<h3 id="amoralism-moral-relativism-nihilism"><span class="section-number-3">2.7.</span> What&rsquo;s the difference between moral relativism, amoralism, moral nihilism, etc?</h3>
<div class="outline-text-3" id="text-amoralism-moral-relativism-nihilism">
<p>
Moral Relativism is the position that morality is subjective and perspective-dependent.
This term covers a range of different philosophical positions with different nuances.
Moral Relativists believe that different individuals, groups, and cultures can all have different conceptions of morality that are each justified according to their own perspectives.
</p>

<p>
Amoralism is an absence of, indifference towards, disregard for, or incapacity for morality.
We define &ldquo;amoral&rdquo; similar to how most people define &ldquo;atheist&rdquo;.
Atheism is a doctrine where its believers don&rsquo;t believe in or reject the existence of &ldquo;God&rdquo;.
Amoralism is a doctrine where its believers reject morality.
</p>

<p>
Moral Nihilism is the meta-ethical view that nothing is morally right or morally wrong.
In some contexts, moral nihilism may be used in a way that represents our position on morality.
In other contexts, it does not represent our position on morality.
So, I prefer &ldquo;Amoralism&rdquo; over &ldquo;Moral Nihilism&rdquo; in most contexts.
</p>

<p>
Another term (that I invented) is &ldquo;post-Overton&rdquo; or &ldquo;post-Overtonism&rdquo;.
Under a post-Overton conception of morality, one no longer pattern matches between different situations to figure out what seems &ldquo;moral&rdquo;.
Instead, a post-Overtonist directs their actions to maximize their personal values, even if it’s only for psychological benefit.
People who still believe in morality are trying to shift the Overton window and one direction or another.
They are still in the pattern-matching <a href="#origin-of-morality">phase of morality</a> where they have still failed to recognize that it is a delusion.
</p>
</div>
</div>

<div id="outline-container-morality-vs-ethics" class="outline-3">
<h3 id="morality-vs-ethics"><span class="section-number-3">2.8.</span> What is the difference between morality and ethics?</h3>
<div class="outline-text-3" id="text-morality-vs-ethics">
<p>
&ldquo;Ethics&rdquo; and &ldquo;Morality&rdquo; are often used interchangeably in common discourse.
But when they are used for more specific connotations, they are as follows:
</p>
<ul class="org-ul">
<li>Ethics is generally considered the standards of &ldquo;good&rdquo; and &ldquo;bad&rdquo;, &ldquo;right&rdquo; or &ldquo;wrong&rdquo; that are imposed by some outside group, (e.g. a society or profession).</li>
<li>Morality is one&rsquo;s own personal sense of right and wrong.
It&rsquo;s not imposed by anyone.
It&rsquo;s just what you <i>personally</i> think is &ldquo;good&rdquo; and &ldquo;bad&rdquo;.</li>
</ul>

<p>
Morality and Ethics can both conflict.
For example, one might live in a society that agrees on a certain code of conduct that you personally disagree with.
For example, you might think that free speech is always going to be right, but live somewhere that if people think defaming religious icons for example is wrong.
The ethics say that you should do what the society imposes on you, whereas your morals (your own personal beliefs about what&rsquo;s right and wrong) say you should do something else.
Your ethics and your morality disagree.
</p>

<p>
It is important to note that philosophers are generally talking about what is <i>universally</i> right or wrong, when they&rsquo;re using these terms.
They&rsquo;re not talking about what a specific society says, or what a person thinks.
They&rsquo;re talking about what is right or wrong <i>universally</i>.
</p>

<p>
Some philosophers believe that all we can say about &ldquo;good&rdquo; and &ldquo;bad&rdquo; is just what societies or groups say (ethics).
This is called <a href="https://en.wikipedia.org/wiki/Relativism">Relativism</a>.
</p>

<p>
Others think that all we can say about right and wrong is what we personally feel (morals, using this distinction).
This is called <a href="https://en.wikipedia.org/wiki/Emotivism">Emotivism</a>.
</p>

<p>
However, philosophers rarely use these two terms, &ldquo;ethics&rdquo; and &ldquo;morals&rdquo; to mean two different concepts in philosophy.
Generally they&rsquo;re going to be interchangeable.
</p>
</div>
</div>
</div>

<div id="outline-container-pragmatosphere-questions" class="outline-2">
<h2 id="pragmatosphere-questions"><span class="section-number-2">3.</span> Pragmatosphere Specific Questions</h2>
<div class="outline-text-2" id="text-pragmatosphere-questions">
</div>
<div id="outline-container-biorealism" class="outline-3">
<h3 id="biorealism"><span class="section-number-3">3.1.</span> What is Biological Realism?</h3>
<div class="outline-text-3" id="text-biorealism">
<p>
Video: <a href="https://odysee.com/@BlitheringGenius:2/BiologicalRealism:b">Biological Realism - Blithering Genius</a>.
</p>

<p>
Biological Realism is a collection of truth claims and implications regarding evolutionary biology for humans, and life more generally.
It encompasses the following topics and concepts:
</p>
<ul class="org-ul">
<li><a href="https://en.wikipedia.org/wiki/Evolution">Evolution</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2023/11/debunking-selfish-gene.html">The Phenocentric Theory of Biological Purpose</a></li>
<li><a href="../faqs/race">Race Realism</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2017/01/what-is-feminism.html">Sex Realism</a></li>
<li><a href="https://en.wikipedia.org/wiki/Evolutionary_psychology">Evolutionary Psychology</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Life Is Selfish, Not Altruistic</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2014/07/game-theory-and-society.html">Game Theory</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2015/09/life-is-violent.html">Life is Violent</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2019/01/sex-death-and-complexity.html">Inevitable Mortality</a></li>
<li><a href="../faqs/overpopulation">Population Dynamics</a></li>
<li><a href="../faqs/eugenics">Eugenics vs Dysgenics</a> (with respect to biological value and adaptations)</li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2022/02/motivation.html">Motivation Theory</a>: Humans and other life don&rsquo;t live to be happy. They are designed to reproduce.</li>
<li>The Effects &amp; Dangers of <a href="https://en.wikipedia.org/wiki/Supernormal_stimulus">Supernormal Stimuli</a> (Superstimuli)</li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2014/02/modern-romance.html">The Dating Black Pill</a>: Lookism, Game Theory, and Evolution Awareness<sup><a id="fnr.2" class="footref" href="#fn.2" role="doc-backlink">2</a></sup></li>
<li>Diet Realism: Diets like <a href="../misc/case-against-carnivore-diet">the Carnivore Diet</a>, Veganism<sup><a id="fnr.3" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>, highly-processed foods, etc are unhealthy.</li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2023/09/fires-polar-bears-and-global-warming.html">Forest fires are natural</a>. They have to occur regularly.</li>
</ul>

<p>
Some of these beliefs are more widely accepted and/or implicitly acknowledged than others.
Some online communities may also accept some aspects of biological realism, while denying other aspects.
For example, most of the Human BioDiversity (HBD) community tends to accept race realism, sex realism, and eugenics/dysgenics, while failing to accept the phenocentric theory of evolution, population dynamics, absolute selfishness, and sometimes even morality and motivation.
Other times, people might partially accept some of these concepts, while misunderstanding the rest of them (e.g. support for race idealism, kin altruism, <a href="../faqs/eugenics#why-laissez-faire-is-best">top-down eugenics</a>, etc).
This FAQs page focuses on morality and selfishness specifically.
</p>

<p>
To be clear, biological realism is <i>not</i> a value system or a lifestyle.
It&rsquo;s just a set of truth claims.
Accepting biological realism may influence a person&rsquo;s values.
But accepting biological realism does <i>not</i> logically commit a believer to value reproduction, or anything really.
<a href="../misc/case-against-efilism#self-defeating">Efilism is an example of a philosophy</a> that is heavily influenced by biological realism that rejects life.
</p>

<p>
Read More: <a href="../#biorealism">Biological Realism Essay / Video Links</a>.
</p>

<hr>
<div class="opponent" id="org327cdf3">
<p>
Do you view humans to simply be a biological species, like any other?
</p>

</div>
<p>
Yes. <a href="https://thewaywardaxolotl.blogspot.com/2014/02/we-cannot-transcend-evolution.html">Humans cannot transcend evolution</a>.
<a href="../misc/industrial-society-and-its-future-manifesto">Technology does not make humans invincible</a>.
Just because humans are the most intelligent form of life ever known to have existed, that doesn&rsquo;t mean that humans aren&rsquo;t susceptible to the same population dynamics and other biological realities that all other animals must face.
It is still the case that <a href="../faqs/eugenics#gattaca">genes are largely responsible for predetermining every person&rsquo;s destiny</a>, that whoever has the most children is destined to have their genes become more common in the future, and that <a href="https://thewaywardaxolotl.blogspot.com/2015/09/life-is-violent.html">human populations have the potential to exceed their carrying capacities</a> to the point of causing war, disease, and famine in order to decrease their populations.
</p>
</div>
</div>

<div id="outline-container-social-darwinism" class="outline-3">
<h3 id="social-darwinism"><span class="section-number-3">3.2.</span> What is the difference between Biological Realism and Social Darwinism?</h3>
<div class="outline-text-3" id="text-social-darwinism">
<p>
Biological Realism and <a href="https://en.wikipedia.org/wiki/Social_Darwinism">Social Darwinism</a> both accept evolution, genetic / innate variation between organisms / entities, and the competitive nature of life.
However, they also have multiple differences:
</p>
<ul class="org-ul">
<li>Social Darwinism has an implicit set of value judgments and value claims, in addition to its set of truth claims.
Biological Realism only contains truth claims.</li>
<li><a href="../faqs/eugenics#what-is-eugenics">Eugenics also involves value judgments</a>, so Social Darwinism often overlaps with eugenics.</li>
<li>Social Darwinism favors imposing social hierarchies on people, whereas Biological Realism doesn&rsquo;t necessarily.
As a Biological Realist, I&rsquo;ve explicitly written that <a href="../faqs/race#races-better-than-others">I oppose racial hierarchies</a> in favor of a meritocratic and individualist society.</li>
<li>Social Darwinism can apply to imperial or economic contexts, rather than biological or social contexts.
For example, Social Darwinism has been used to justify colonialism and laissez-faire capitalism.</li>
<li>Social Darwinism doesn&rsquo;t cover all the aspects and breadth of Biological Realism.</li>
</ul>
</div>
</div>

<div id="outline-container-humanism" class="outline-3">
<h3 id="humanism"><span class="section-number-3">3.3.</span> What is Humanism?</h3>
<div class="outline-text-3" id="text-humanism">
<p>
<i>See: <a href="../#wokism">Analyzing Humanism / Wokism / Soulism</a></i>.
</p>

<p>
Humanism is a secular, liberal, hedonistic, pro-altruism <a href="https://thewaywardaxolotl.blogspot.com/2014/07/the-communists-who-took-power-in.html">utopian ideology</a> and religion that has supplanted Christianity as the main moral value system of the modern Western World.
Humanists take for granted that personal happiness is the purpose of life, technology is always good, humans are naturally morally good, sympathy is always &ldquo;better&rdquo; than hate, and that tolerance of other cultures and beliefs is good, as long as they agree with humanism.
</p>

<p>
Like all religions, there are different varieties of humanism, so this general description doesn&rsquo;t necessarily describe exactly what all humanists believe, but it does describe the gist and general tenants of the ideology.
In most cases, the main distinction(s) between each of the different factions of humanists is they can&rsquo;t all agree on what is &ldquo;morally good&rdquo;.
Humanism may also be called <a href="https://expandingrationality.substack.com/p/soulism">Soulism</a>.
Humanism/Soulism is related to <a href="https://expandingrationality.substack.com/p/what-is-wokism">Wokism</a>, but there are some differences between the two.
</p>

<p>
Humanism is popular because it appeals to moral intuitions in the absence of traditional supernatural religious beliefs.
Humanism is not a legitimate philosophy because it doesn&rsquo;t have a theory of truth, nor a theory of value, nor a theory of society.
<a href="https://americanhumanist.org/humanism/manifesto3/">When we investigate and critique the Humanist Manifesto</a>, we find that it&rsquo;s all just rhetoric designed to affirm prior intuitions, rather than question them.
The main goal of philosophy is to question assumptions, and every real philosophy ought to do that.
</p>

<p>
<a href="https://en.wiktionary.org/wiki/humanism">The third sense of &ldquo;humanism&rdquo; defined on Wiktionary</a> is the most similar to this section&rsquo;s definition:
</p>
<blockquote>
<p>
An ethical system that centers on humans and their values, needs, interests, abilities, dignity and freedom; especially used for a secular one which rejects theistic religion and superstition.
</p>
</blockquote>
</div>
</div>

<div id="outline-container-christianity-humanism-wokism" class="outline-3">
<h3 id="christianity-humanism-wokism"><span class="section-number-3">3.4.</span> What are the differences between Christianity, Humanism, and Wokism?</h3>
<div class="outline-text-3" id="text-christianity-humanism-wokism">
<p>
All three ideologies have many varieties.
They are all pro-altruism and pro-hedonism, with the exception of some varieties of Christianity.
There is a lot of overlap between Christianity and Humanism, and between Humanism and Wokism.
However, Christianity and Wokism don&rsquo;t overlap very much.
It&rsquo;s rare for someone to be both religious and wokist.
</p>

<p>
The main differences between Christianity and Humanism are:
</p>
<ul class="org-ul">
<li>Christianity is religious, whereas Humanism is secular.</li>
<li>Christianity is more likely to accept natural biological values than Humanism.</li>
<li>Christianity is more right-leaning, whereas Humanists can be virtually any political ideology.</li>
<li>Humanists are more diverse in their political, philosophical, and ideological beliefs.</li>
</ul>
<p>
Aside from the different beliefs on religion, the compatibility between Christianity and Humanism depends on the variants of Christianity and Humanism in question.
Christianity and Humanism are both pro-altruism, so Humanist values are often compatible with Christian values and vice versa.
</p>

<p>
The main differences between Humanism and Wokism are:
</p>
<ul class="org-ul">
<li>Wokism is left-wing, whereas Humanism isn&rsquo;t necessarily left-wing.
<ul class="org-ul">
<li>Most Conservatives have Humanist values.</li>
<li>Right-Libertarians aren&rsquo;t leftist, although they associate oppression with the state, and they sometimes virtue-signal.
Right-Libertarians are arguably wokist in that sense, but they are much less likely to reject or invert biological values.</li>
<li>Transhumanists aren&rsquo;t usually wokist.</li>
<li>Ayn Randian Objectivists aren&rsquo;t wokists, but they are humanists.</li>
</ul></li>
<li>Wokism doesn&rsquo;t necessarily have to be secular or pro-technology, unlike Humanists.
<ul class="org-ul">
<li>Christians and Muslims can still be wokist and leftist, even if it&rsquo;s not common.</li>
<li>Communism doesn&rsquo;t have to secular. Religious Communists have existed, and many exist today.</li>
<li>Neo-Luddites / Anarcho-Primitivists aren&rsquo;t pro-technology, and don&rsquo;t have to be secular.</li>
</ul></li>
<li>Wokism tends to feature higher virtue-signaling.</li>
<li>Wokism puts greater emphasis on systemic oppression.</li>
</ul>
<p>
The vast majority of Wokists could also be classified as Humanists, but not every Humanist is a Wokist.
</p>

<hr>
<p>
We can roughly summarize the <a href="../civilization/wokism#wokism-theory">chronology of the most dominant ideologies in the West</a> as follows:
</p>
<ol class="org-ol">
<li>Christianity was the historically dominant ideology of the West for nearly two millennia.</li>
<li>Social Darwinism arose in the mid-to-late-1800s. It <a href="../civilization/wokism#social-darwinism-peak">peaked in the West from the 1900s</a> to World War II.</li>
<li>Humanism / Soulism arose after World War II.</li>
<li>Wokism arose as the leftist version of Humanism during the 1960s to the current year (2025).</li>
</ol>
<p>
Social Darwinism died out in the mid-1900s, many people still follow Christianity, some people are just Humanists or Soulists, and some people are Wokists.
Christianity -&gt; Humanism -&gt; Wokism.
</p>

<p>
Read more: <a href="../civilization/wokism#wokism-theory">What Caused The Rise of Wokism?</a>
</p>
</div>
</div>

<div id="outline-container-abyss-for-value" class="outline-3">
<h3 id="abyss-for-value"><span class="section-number-3">3.5.</span> Why does the Abyss for Truth and Value matter?</h3>
<div class="outline-text-3" id="text-abyss-for-value">
<p>
Accepting the abyss {<a href="https://thewaywardaxolotl.blogspot.com/2023/06/lucifers-question.html">(1)</a>, <a href="https://thewaywardaxolotl.blogspot.com/2016/07/what-is-abyss.html">(2)</a>, <a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-value.html">(3)</a>, <a href="https://thewaywardaxolotl.blogspot.com/2015/10/the-nihilist-and-carpenter.html">(4)</a>} enables us to reject assumptions about how we should live our lives.
</p>

<p>
In my own experience, <a href="../misc/philosophical-journey#efilism-phase">when I was Efilist-leaning</a>, it was a problem for me because my desires contradicted what seemed to have been the &ldquo;right thing to do&rdquo;.
Once I recognized that there&rsquo;s no objective basis for morality, this enabled me to reject the values and beliefs that conflicted with my desires.
So, recognizing that there&rsquo;s an abyss for value and morality has helped me.
</p>

<p>
Recognizing that biological value arises from causality by the loop of reproduction also gives me a way to &ldquo;immanentize the abyss&rdquo; by <a href="../epistemology/axiology#reproduction-objective-purpose">fulfilling my objective purpose and what I evolved to do (reproduction)</a>.
</p>
</div>
</div>

<div id="outline-container-shoulds-and-shouldnts" class="outline-3">
<h3 id="shoulds-and-shouldnts"><span class="section-number-3">3.6.</span> In terms of should&rsquo;s and shouldn&rsquo;ts, what would be an ideal ethical system?</h3>
<div class="outline-text-3" id="text-shoulds-and-shouldnts">
<p>
From a societal perspective, we favor <a href="https://thewaywardaxolotl.blogspot.com/2020/04/toward-rational-humanism.html">rational humanism</a> and a <a href="https://brittonicmemetics.wordpress.com/2020/06/26/designed-culture/">rationally designed culture</a>.
The society would value cooperation and shun defecting.
Legally speaking, this ideal society would have a lot of individual freedom, but <a href="#memetic-traditions">memetic traditions that promote higher fertility</a> would naturally be the most prevalent in the society.
Over time, those traditions would likely be deemed &ldquo;moral&rdquo; and actions that don&rsquo;t conform with those traditions would be deemed &ldquo;immoral&rdquo;.
However, a society that practices <a href="../faqs/eugenics">eugenic population control</a> would theoretically become very intelligent and culturally aware after a few hundred years or so of evolution, so it would probably eventually adopt a rational, laissez-faire approach to social norms and legal codes.
</p>

<hr>
<div class="opponent" id="org540f33f">
<p>
What is Rational Humanism?
</p>

</div>
<p>
<a href="https://thewaywardaxolotl.blogspot.com/2020/04/toward-rational-humanism.html">Rational Humanism</a> is a proposed ideology for replacing (Naive) Humanism as the primary ideology of the Western World.
The individual core value of Rational Humanism is Reproduction, while the collective core value is Civilization.
In comparison to Naive Humanism, Rational Humanism embraces selfishness, it defines more sustainable values, and it isn&rsquo;t fundamentally deceptive.
</p>

<p>
Note: The Rational Humanism that we endorse is a movement and ideology that we would prefer to be adopted by humans in the 21st century.
It should not be confused with <a href="https://en.wikipedia.org/wiki/Rationalist_humanism">&ldquo;Rational Humanism&rdquo; of the Enlightenment Movement</a>.
</p>

<p>
Read More: <a href="https://thewaywardaxolotl.blogspot.com/2020/04/toward-rational-humanism.html">Toward Rational Humanism</a>.
</p>
</div>
</div>

<div id="outline-container-thoughts-on-less-wrong" class="outline-3">
<h3 id="thoughts-on-less-wrong"><span class="section-number-3">3.7.</span> What do you think about rationalist forums like Less Wrong?</h3>
<div class="outline-text-3" id="text-thoughts-on-less-wrong">
<p>
<a href="../#blogroll">The Pragmatosphere</a> and <a href="https://www.lesswrong.com/">Less Wrong</a> both share <a href="https://en.wikipedia.org/wiki/Rationalism">rationalism</a> as a fundamental characteristic of their philosophies.
Less Wrong was founded by <a href="https://en.wikipedia.org/wiki/Eliezer_Yudkowsky">Eliezer Yudkowsky</a> in 2009, whereas the Pragmatosphere was founded by <a href="https://youtube.fandom.com/wiki/Blithering_Genius">Blithering Genius</a> in 2013.
The Pragmatosphere is much smaller, so its followers have more unified beliefs.
By contrast, Less Wrong is a <a href="../civilization/democracy#big-tent-strategy">big tent movement</a> and is much larger.
So although there&rsquo;s a lot of beliefs and ideas associated with Less Wrong, not all of its followers perfectly overlap in their beliefs.
</p>

<p>
There are many differences and disagreements between the two rationalist movements.
The following observations and criticisms apply towards Less Wrong, from the perspective of the Pragmatosphere.
Since Less Wrong is a big tent as aforementioned, not all of these criticisms necessarily apply to every LessWronger.
Some of these criticisms also highlight things that we wish had more emphasis within Less Wrong and related movements, so they may not necessarily be disagreements.
</p>
<ul class="org-ul">
<li><a href="#biorealism">Biological realism</a> is not a main tenet. Many LessWrongers reject aspects of biology.</li>
<li>Most of them believe in <a href="https://thewaywardaxolotl.blogspot.com/2020/07/what-is-morality.html">morality</a>. Most of them are <a href="#humanism">humanists</a>.</li>
<li>There are disagreements relating to &ldquo;<a href="#effective-altruism">Effective Altruism</a>&rdquo;.</li>
<li>It&rsquo;s rational to be <a href="../civilization/technology#thoughts-on-AI">concerned with how the advancement of AI will affect humans</a>. However, we predict that the misuse and/or abuse of AI by humans will be a much bigger problem than AI misalignment.</li>
<li>Some of them are <a href="https://thewaywardaxolotl.blogspot.com/2015/01/technology-and-progress.html">too optimistic about technology</a> and its (future) effects on humanity (e.g. <a href="../civilization/space-colonization">space colonization</a>, cryogenics, <a href="../faqs/eugenics#genetic-engineering">genetic engineering</a>, etc).</li>
<li>Some of them have <a href="../epistemology/academia-critique">too much faith in academic research</a>.</li>
<li>There isn&rsquo;t enough emphasis on <a href="../civilization/georgism-crash-course">Georgism</a> and <a href="../faqs/overpopulation#nowhere-close-bogus">resource scarcity</a> in those circles.</li>
<li>Most of them greatly underestimate how much <a href="../faqs/overpopulation">overpopulation is a potential threat to humanity</a>.
Like most people, they&rsquo;re more concerned with climate change, <a href="../civilization/climate-change#why-public-fears">for various reasons</a> (e.g. the negative consequences of climate change are more immediately noticeable than overpopulation).</li>
<li>Most of them don&rsquo;t support <a href="../faqs/eugenics">using reproduction licenses to enforce eugenic population control</a>.</li>
<li>Most of them don&rsquo;t apply the <a href="https://en.wikipedia.org/wiki/Subject_and_object_(philosophy)">subject-object dichotomy</a> for understanding <a href="https://thewaywardaxolotl.blogspot.com/2023/08/theories-of-knowledge.html">truth and knowledge</a>, <a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-value.html">value</a>, <a href="https://thewaywardaxolotl.blogspot.com/2020/05/free-will-determinism-and-choice.html">free will and determinism</a>, etc.</li>
<li>Most of them aren&rsquo;t consciously aware of <a href="../language/sapir-whorf-theory">Sapir-Whorf Theory</a>, its implications, or its applications.</li>
<li>The rest of their epistemology is hit-or-miss.</li>
</ul>

<p>
The gateway to a rational community is the <a href="#abyss-for-value">Abyss</a>, the recognition that there are no assumptions that we can take for granted in philosophy.
Even though the Less Wrong forum was created to focus on promoting rationality, it&rsquo;s mostly degenerated into a cult of misguided people who are preoccupied with AI misalignment, futurism, and effective altruism.
They are confusing their unexamined assumptions for rationality, as most people do.
Eliezer Yudkowsky is justified in criticizing mainstream academic philosophy since most of it is frankly garbage, but we don&rsquo;t believe that the philosophy that he&rsquo;s created is much better, for all the reasons that we&rsquo;ve stated here.
</p>

<p>
<a href="https://en.wikipedia.org/wiki/Objectivism">Ayn Randian Objectivists</a> also claim and think they are rationalists, but <a href="../misc/critiquing-ayn-rands-objectivism">I have a low opinion about them and their philosophy</a>.
In my experience, most Randian Objectivists merely parrot Ayn Rand quotes, while choosing to not think for themselves.
The average LessWronger is definitely more rational, intelligent, and open-minded than the average Objectivist.
</p>

<p>
Even though <a href="../#blogroll">The Pragmatosphere</a> and <a href="https://www.lesswrong.com/">Less Wrong</a> claim and believe they are rationalist, they both propose remarkably different theories of epistemology.
Both movements also hold extraordinarily different beliefs, values, and priorities for humanity.
We encourage more Less Wrongers to read and think about the works of the Pragmatosphere, but we also believe it&rsquo;s unlikely that the two rational movements will ever merge to any great extent.
<a href="https://www.lesswrong.com/users/zero-contradictions">Most of my posts on LessWrong</a> haven&rsquo;t gotten a lot of attention, and the ones that transgress the forum&rsquo;s moral boundaries received a lot of downvotes.
The effective altruism forum also banned my account without giving me any warning or notice as to why I was banned.
That suggests that EA is more of a cult and echo chamber, rather than a true rationalist movement.
</p>
</div>
</div>

<div id="outline-container-effective-altruism" class="outline-3">
<h3 id="effective-altruism"><span class="section-number-3">3.8.</span> What do you think about Effective Altruism?</h3>
<div class="outline-text-3" id="text-effective-altruism">
<p>
Effective Altruism (EA) is a 21st-century social movement that purports to &ldquo;use evidence and reason to figure out how to benefit others as much as possible, and taking action on that basis&rdquo;.
EA has many good intentions, and I believe that it&rsquo;s a mostly positive intellectual movement overall.
But I&rsquo;d also say that it&rsquo;s ignorant in many ways, and that will be the focus of this essay.
</p>

<p>
For starters, promoting altruism raises the question of why anyone should be obligated to help others, at the expense of improving their own future and their descendants&rsquo; futures instead.
<a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Humans are naturally selfish</a>.
People can help others if they want to, but if they&rsquo;re doing so at their own expense, then they are ultimately self-sacrificing their own futures.
In some ways, the justification for EA assumes a <a href="#helping-everybody">fallacy of composition</a> since EA believes that people can and should help everyone.
</p>

<p>
At the very least, I disagree that some of the things that EA aims to accomplish should be labeled as &ldquo;altruism&rdquo;.
I don&rsquo;t believe that biological, psychological, or energetic altruism can exist in nature long-term, or be self-sustaining.
Many of the goals that I&rsquo;d like society to achieve would be better described as &ldquo;Effective Cooperation&rdquo; (e.g. <a href="../civilization/georgism-crash-course">Georgism</a>, <a href="../faqs/overpopulation">population control</a>, less corruption, etc), when it comes to solving <a href="../civilization/political-philosophy#government-goals">problems of cooperation</a>.
Other improvements that I&rsquo;d like to see in society are better described as self-improvement or improvements to the culture (e.g. expanded rationality, healthier (plant-based) diets, etc).
</p>

<hr>
<p>
EA also assumes Utilitarianism, <a href="../faqs/morality#utilitarianism">which fails to account for individual perspectives and the calculation problem</a>.
To the contrary, I&rsquo;d argue that a lot of charities that supposedly have the greatest amount of &ldquo;good&rdquo; for humanity would contribute to overpopulation, which would negate their benefits in the long run.
For example, programs to prevent malaria, provide clean water, and feed starving families in Sub-Saharan Africa would <a href="../faqs/overpopulation#rising-wealth-and-fertility">hasten the Earth&rsquo;s likelihood of becoming overpopulated</a> and exacerbate dysgenics.
We certainly sympathize with those who do not have enough to eat or drink, but inadvertently boosting the fertility of the developing world could make the humanity worse off as a whole by exacerbating ecological overshoot, while doing nothing to raise the Earth&rsquo;s carrying capacity or to slow its population growth.
</p>

<p>
Unfortunately, most EA proponents are oblivious to the Earth&rsquo;s ongoing ecological overshoot because they tend to believe in <a href="../faqs/overpopulation#why-DTT-is-wrong">Demographic Transition Theory</a> (they think that populations stabilize).
<a href="../faqs/overpopulation#if-no-pop-regulation">Billions of people will die without population control</a>,
and yet there are no major EA proponents who are doing anything to educate people and raise the political will to enforce EPC or increase access to contraception (as far as I know).
In fact, many effective altruists oppose population control on the basis that it would prevent some people from fulfilling their desires.
They believe that population control is immoral because it conflicts with their <a href="#humanism">humanist</a> values.
This ignores that reproduction has serious consequences that affect <i>everybody</i>, and it also ignores how <a href="../faqs/overpopulation#human-rights">population control would protect more human rights than it &ldquo;violates&rdquo;</a>.
</p>

<p>
Since EA proponents have a flawed understanding of human nature and they don&rsquo;t understand population dynamics, this is a great illustration of how the calculation problem undermines the EA intent to accomplish the &ldquo;greatest benefit for all&rdquo;.
Ironically, many of our <a href="https://www.youtube.com/watch?v=I9gu-Nodlnc">Pragmatopian proposals</a> would accomplish exactly what effective altruists would believe is &ldquo;best&rdquo; for Humanity, if only they had the knowledge and rationality for understanding and accepting them.
Despite this, most EAs still oppose population control anyway because it does not align with their Humanist values.
</p>

<p>
One of the best things that EA could do to help the <a href="https://en.wikipedia.org/wiki/Global_North_and_Global_South">Global South</a> would be to provide them with cheap, abundant, and accessible contraception.
It would lower resource consumption and the risk of overpopulation.
The Global South cannot implement population control unless it has abundant contraception, so increasing access to contraception in the global south is a prerequisite to implementing population control.
We also know that <a href="../faqs/overpopulation#wealth-fertility-rates-correlation">low fertility would make it easier to grow the economy</a> of the Global South and create the conditions and lifestyles that are necessary for helping the Global South adapt to modernity.
</p>

<hr>
<p>
Two other main focuses of EA are animal welfare and AI existential risk, but it&rsquo;s debatable if these are worth pursuing.
Humans are omnivores, and <a href="https://expandingrationality.substack.com/p/diet-and-human-evolution">eating meat was important for human evolution</a>.<sup><a id="fnr.3.100" class="footref" href="#fn.3" role="doc-backlink">3</a></sup>
<a href="https://thewaywardaxolotl.blogspot.com/2022/02/motivation.html">If pain and pleasure balance out</a>, then it&rsquo;s also questionable if animals suffer as much as it&rsquo;s claimed that they do.
I don&rsquo;t believe that humanity has any obligation to abolish factory farming, but I do believe that <a href="https://www.youtube.com/@Viva-Longevity/videos">plant-based diets are the healthiest</a>, are better for the environment, and should be promoted more.
I&rsquo;m aligned with EA on this issue to that extent.
</p>

<p>
I&rsquo;m also <a href="../civilization/technology#AI-safety">not convinced that AGI will pose an existential risk to humanity</a>.
I think that AI misalignment is unlikely and that most research into AI misalignment is probably misguided, but I&rsquo;m not opposed to researching AI safety or strongly regulating AI.
<a href="../civilization/technology#AI-pros-cons">I am pessimistic about how AI will affect humanity&rsquo;s future</a>.
</p>

<p>
I also dislike how <a href="../civilization/georgism-crash-course">Georgism</a> and <a href="https://en.wikipedia.org/wiki/YIMBY_movement">YIMBYism</a> have hardly any influence in the EA movement, thus far.
</p>

<p>
Lastly, I agree with many of the <a href="https://en.wikipedia.org/wiki/Effective_altruism">other criticisms made against EA on Wikipedia</a>, at the time of this writing (2024 August).
EA is likely to give more influence to society&rsquo;s wealthy elites if it continues to rise in popularity, and effective altruists will probably use EA to mask their selfishness.
For all the reasons that I&rsquo;ve described, I believe that EA is a misguided movement.
<a href="https://www.youtube.com/watch?v=I9gu-Nodlnc">The EA movement has failed to identify Humanity&rsquo;s greatest problems</a>, so it&rsquo;s not focused on solving them.
Nevertheless, I do think that some of the problems that EA is focused on solving have <i>some</i> good benefits for humanity.
</p>

<p>
My recommendations for improving EA are related to my criticisms of EA.
EA should change its name and goals to <a href="https://www.youtube.com/watch?v=I9gu-Nodlnc">focus on sustaining and preserving modern civilization</a>, which is much more fragile than most people realize.
The movement should refocus its priorities accordingly.
In particular, increasing access to contraception in the Global South, encouraging healthy sustainable plant-based diets, implementing Georgism across the Earth, enforcing eugenic population control, and expanding rationality should be top priorities.
The movement would also benefit from having <a href="../civilization/technology">greater skepticism of technology</a>.
</p>
</div>
</div>
</div>

<div id="outline-container-objectivity-questions" class="outline-2">
<h2 id="objectivity-questions"><span class="section-number-2">4.</span> Subjectivity/Objectivity Questions</h2>
<div class="outline-text-2" id="text-objectivity-questions">
<p>
When it comes to morality, moralists could be divided in roughly 3 categories:
</p>
<ul class="org-ul">
<li>The first category is people who are spooked by morality. They never questioned or thought about morality in enough detail to realize that it’s nonexistent as far as they are concerned it’s just an objective rule that they have to obey or else they feel guilt, shame, etc.</li>
<li>The second category of people is people who use their morality to justify selfish desires. This is often unconscious, often tied to the power process, especially if it’s about promoting some form of wokism.</li>
<li>The third category of people are people who fall into both. They believe that there are objective rules that everybody has to obey, and they never questioned it. They also benefit, psychologically from believing that they are is an objective good and evil, and that they are on the good side, so why would they question it if it makes them feel better about themselves?</li>
</ul>
</div>

<div id="outline-container-why-not-objective" class="outline-3">
<h3 id="why-not-objective"><span class="section-number-3">4.1.</span> Why isn&rsquo;t morality objective?</h3>
<div class="outline-text-3" id="text-why-not-objective">
<p>
This FAQs page disproves many arguments in favor of objective morality.
But for an essay-style format, we recommend reading: <a href="https://thewaywardaxolotl.blogspot.com/2024/08/the-case-against-moral-realism.html">The Case Against Moral Realism</a>.
</p>

<p>
Moral Objectivism is the ethical view that all or some actions have intrinsic positive value (&ldquo;are good&rdquo;) and intrinsic negative value (&ldquo;are bad/evil&rdquo;), regardless of context, consequence, or perspective.
</p>

<p>
It&rsquo;s important to note that morality is not a set of &ldquo;rules&rdquo;, but rather a set of &ldquo;values&rdquo;.
The values may appear and be described as &ldquo;rules&rdquo; by people who believe in objective morality, but we shall show why it&rsquo;s more appropriate to describe them as &ldquo;values&rdquo;.
</p>




<figure id="org6f9f747">
<img src="../images/is-ought-explanation-of-morality.jpg" alt="The is-ought gap explanation of morality." width="677">

</figure>

<p>
The act of crossing the is-ought gap may even be called the &ldquo;Is-Ought Fallacy&rdquo; in appropriate cases.
</p>
</div>
</div>

<div id="outline-container-reason-and-morality" class="outline-3">
<h3 id="reason-and-morality"><span class="section-number-3">4.2.</span> Why can&rsquo;t the reason and rationality be the basis for objective morality?</h3>
<div class="outline-text-3" id="text-reason-and-morality">
<p>
The following paragraphs were paraphrased and written more concisely from StateOfTheNihil&rsquo;s essay, &ldquo;<a href="https://stateofthenihil.wordpress.com/2019/09/22/reason-is-not-the-basis-for-morality/">Reason is Not the Basis for Morality</a>&rdquo;.
</p>

<p>
This assumption relies on a misunderstanding of how reason and knowledge work.
Reason is a psychological mechanism where thought conforms to rules for thinking (a logic).
The nature of logical reasoning prevents it from being a suitable foundation for anything, let alone morality.
</p>

<p>
It can be tempting to conclude that morality is based on rationality since <a href="../epistemology/axiology#what-are-values">it&rsquo;s possible for values to contradict each other, to be based on false or unquestioned assumptions, and/or to be justified by fallacious reasoning</a>.
If some value systems are contradictory and others are not, that should imply that some moral systems are better than others, right?
It does, but reason alone is still not sufficient for building an incontrovertible moral foundation.
There is no uniquely rational way to define value philosophically since values depend on other values.
Reason makes your thinking consistent, but reason does not provide a foundation.
</p>

<p>
When you make a valid deduction, you are reasoning from established propositions.
The established propositions are assumptions made for that particular step of reasoning.
The act of making a valid inference does not depend on the actual truth-value of any given assumption.
They are merely assumed to be true in the abstract.
The point here is that the starting point, particularly the truth-value of the starting point, is not relevant to validity.
Logic is only concerned with the transmission of assumed truth down into a conclusion.
Logic has to do with the flow of thought, not the starting point of thought.
</p>

<p>
Any attempt to provide a rational foundation for morality will invariably require contradicting itself.
To start, there needs to be a framework where specific ethical actions can be deduced from more general first principles.
But these first principles will never have a justification, themselves.
Reason makes it possible to construct a valid flow of thought from first principles, but it does not have the artillery to provide justification for those first principles.
If you appeal to some principle from which you can deduce that first principle, then the first principle loses its status and the principle you&rsquo;ve deduced it from is now the new first principle.
We&rsquo;re now back where we started, needing justification for our starting point.
</p>

<div class="opponent" id="orgfc151cb">
<p>
But first principles are self-evidently true. They do not depend on other principles for justification, as they justify their own truth-value.
</p>

</div>
<p>
&ldquo;Self-evidence&rdquo; is a gloriously vague assertion, ripe for equivocation.
It&rsquo;s also not a valid epistemological concept since anything can be questioned and rejected.
</p>

<div class="opponent" id="org53523d8">
<p>
Intuition can form a basis for morality.
</p>

</div>
<p>
First, intuition is not universal, just as self-evidence is not universal.
What strikes you as intuitive will depend, in part, on culture.
Most people accepted slavery as a norm in society for thousands of years, until within the last couple centuries.
Whatever intuition you go with is arbitrary.
</p>

<p>
Second, intuition is not necessarily coherent, as is assumed by these lapsed rationalists.
The idea is that we are able to come up with a complete and coherent framework that will jive with all of our intuitions.
But there is no reason to assume this.
Intuition is influenced by indoctrination, education, and social factors, which destabilizes the first principle as well.
Appeals to self-evidence or to intuition are arbitrary and there is no way to settle disputes between different parties.
</p>

<p>
It&rsquo;s also a mistake to assume that values can be based on sensory knowledge instead of emotional knowledge.
<a href="../epistemology/axiology#what-are-values">Values can be coordinated with reason</a>, but reason and sensory knowledge alone cannot form an objective basis for morality.
</p>
</div>
</div>

<div id="outline-container-dangerous-black-and-white-morals" class="outline-3">
<h3 id="dangerous-black-and-white-morals"><span class="section-number-3">4.3.</span> Why is it dangerous to have a black-and-white sense of morality?</h3>
<div class="outline-text-3" id="text-dangerous-black-and-white-morals">
<p>
Even if morality were objective, there&rsquo;s always more ways to be wrong than there are ways to be right, so anybody who <i>thinks</i> that they are abiding by supposedly objective moral standards is probably wrong.
Many people would also use their belief that they are imposing the one and only true &ldquo;objective&rdquo; morality as a justification to rule with an iron fist.
</p>
</div>
</div>

<div id="outline-container-utilitarianism" class="outline-3">
<h3 id="utilitarianism"><span class="section-number-3">4.4.</span> Why is Utilitarianism <i>not</i> the best way to define morality?</h3>
<div class="outline-text-3" id="text-utilitarianism">
<p>
There are multiple reasons:
</p>
<ol class="org-ol">
<li>Utilitarianism is defined as maximizing &ldquo;well-being&rdquo;, and &ldquo;well-being&rdquo; is subjective.
That&rsquo;s why there&rsquo;s <a href="https://en.wikipedia.org/wiki/Utilitarianism">many different types of Utiliarianism</a>.</li>
<li>Utilitarianism doesn&rsquo;t have any practical solutions to the moral calculation problem.
Every single person and faction of society has different utilitarian calculations that would be &ldquo;best&rdquo; for their own lives.
A lot of Utilitarians get caught up in failing to recognize that corruption within a society is &ldquo;morally good&rdquo; from the perspective of the corrupt people.
Corruption is cooperation in such contexts.</li>
<li>Utilitarianism implies that I should sacrifice my own well-being if there are situations where it would benefit everybody else.
It depends on the situation of course, but I wouldn&rsquo;t do that in most cases.
Fortunately, I rarely face dilemmas where I have sacrifice my own self-interests.
I do cooperate with others, but those relationships are reciprocal chains of giving and taking.</li>
<li>It simply isn&rsquo;t feasible for each individual to act according to utilitarianism. In practice, an individual has the knowledge to act selfishly in his own interests, but not the knowledge to act altruistically for maximizing <i>everybody&rsquo;s</i> collective average self interests.</li>
</ol>


<figure id="org8cabfe5">
<img src="../images/yet-another-universal-moral-system.jpg" alt="Yet another purportedly universal moral system." width="420">

</figure>


<p>
The Connection Between The Various Types Of Utiliarianism With The Various Types Of Hedonism
</p>

<table>


<colgroup>
<col  class="org-left">

<col  class="org-center">

<col  class="org-center">

<col  class="org-center">
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Question</th>
<th scope="col" class="org-center">Mainstream</th>
<th scope="col" class="org-center">Efilism</th>
<th scope="col" class="org-center">Zero Contradictions</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">If Life Violent?</td>
<td class="org-center">It shouldn&rsquo;t be</td>
<td class="org-center">Yes, and life is worse thing ever.</td>
<td class="org-center">Yes, but this isn&rsquo;t necessarily a &ldquo;bad&rdquo; thing.</td>
</tr>

<tr>
<td class="org-left">Hedonism/Utilitarianism?</td>
<td class="org-center">Positive &amp; Negative Utilitarianism</td>
<td class="org-center">Supremacy of Negative Utilitarianism</td>
<td class="org-center">N/A, they balance out, and it&rsquo;s subjective.</td>
</tr>

<tr>
<td class="org-left">Altruism?</td>
<td class="org-center">Yes.</td>
<td class="org-center">Yes, absolutely.</td>
<td class="org-center">No, because nature is intrinsically selfish.</td>
</tr>
</tbody>
</table>

<p>
Most people and all Efilists are Utilitarians. The difference is that most people will assign some value to positive hedonism, whereas Efilists will assign either no value to positive hedonism or value it as completely subordinate to Utilitarianism (Positive Hedonism is only valuable if Negative Hedonism is satisfied). In addition, Efilists recognize that life is inherently violent.
</p>

<p>
Positive and Negative Utilitarianism only differ by the type of hedonism that they favor. <a href="../misc/case-against-efilism#hedonism-is-not-self-evident">Hedonism is not self-evident</a>.
</p>
</div>
</div>

<div id="outline-container-common-laws" class="outline-3">
<h3 id="common-laws"><span class="section-number-3">4.5.</span> Most societies have laws that prohibit theft, murder, and rape, so doesn&rsquo;t this indicate that some things are objectively immoral?</h3>
<div class="outline-text-3" id="text-common-laws">
<p>
Legal systems are intersubjective, but that&rsquo;s not the same thing as objective.
</p>
<blockquote>
<p>
Every civilization has to solve the same problems of cooperation.
And every civilization solved those problems with the state.
Every civilization has laws that solve problems of cooperation.
E.g. the law against murder solves the prisoner&rsquo;s dilemma that exists between strangers: that each might kill the other.
The law allows strangers to live and work together, so it enables large-scale societies.
Likewise for the other core laws, such as laws establishing property rights and marriage, etc.
These solve problems of cooperation.
Those laws are part of the overall package of civilization, which includes the state, written language, and math.
</p>

<p>
Humans have roughly the same emotional structure, although individuals vary.
That common human nature is not &ldquo;good&rdquo; by your moral standards.
We have the capacity for positive and negative empathy, cooperation and competition.
</p>

<p>
Human nature is selfish, and humans can often benefit by killing other humans, raping other humans, taking their stuff, etc.
So, we evolved the capacity for both friendship and hatred, cooperation and violent competition.
Societies have to prevent internal violence, but they project violence outward, and societies use violence to impose internal non-violence.
We often cooperate to compete.
War is a cooperative endeavor.
</p>

<p>
All civilizations fought wars in which they killed, raped, seized property, etc.
Civilization is based on conquering land and establishing a monopoly on violence by the use of violence.
War is a human universal.
Society is cooperative, but we often cooperate to compete.
Society doesn&rsquo;t eliminate competition.
It transfers it to a higher level, so we are competing as a unit with other societies or with nature.
At the margins, life is zero-sum.
Once an ecosystem is fully populated, one way of life can only increase at the expense of another.
That applies to species, societies and civilizations.
&#x2013; Blithering Genius, <a href="https://thewaywardaxolotl.blogspot.com/2022/07/answering-ancap-questions.html"> Answering Ancap Questions</a>
</p>
</blockquote>
<p>
It&rsquo;s also incorrect to assert that theft, murder, rape, etc are objectively wrong.
If it&rsquo;s possible for someone to benefit themself by killing, raping, and stealing, then that implies that those actions can be subjectively good from a person&rsquo;s point of view.
</p>
</div>
</div>

<div id="outline-container-cooperation-not-objectively-moral" class="outline-3">
<h3 id="cooperation-not-objectively-moral"><span class="section-number-3">4.6.</span> Why are contract-ethics and cooperation not objectively moral?</h3>
<div class="outline-text-3" id="text-cooperation-not-objectively-moral">
<p>
If cooperating together was the objectively best choice (i.e. it offers the greatest individual reward for each player and defection is guaranteed to not happen), then prisoner&rsquo;s dilemmas wouldn&rsquo;t exist at all in the first place.
Conversely, if prisoner&rsquo;s dilemmas didn&rsquo;t exist, then there would be no inquiry as to why someone would choose anything less than the option with the greatest potential reward and what can be done to achieve that.
The fact that game theoretical problems exist is evidence enough that contract ethics are subjective, rather than objective.
</p>
</div>
</div>

<div id="outline-container-moral-progress" class="outline-3">
<h3 id="moral-progress"><span class="section-number-3">4.7.</span> Isn&rsquo;t historical moral progress evidence that morality is objective?</h3>
<div class="outline-text-3" id="text-moral-progress">
<p>
No. <a href="#technology-and-moral-progress">The creation of &ldquo;Moral progress&rdquo; is an illusion</a>.
Most &ldquo;improvements&rdquo; in &ldquo;moral progress&rdquo; are really just advancements in technology, not so much improvements in people deciding to behave &ldquo;better&rdquo;.
</p>

<p>
Moreover, most people who make this argument are defining &ldquo;moral progress&rdquo; according to modern Western standards of morality, but those are far from being a universal conception of morality.
For example, traditionalists and Fundamentalist Muslims both have very different idea of moral progress, and would disagree with the Western conception.
</p>
</div>
</div>

<div id="outline-container-not-everybody-wants-tech-society" class="outline-3">
<h3 id="not-everybody-wants-tech-society"><span class="section-number-3">4.8.</span> Surely everybody wants to live in a prosperous, technologically-advanced society, right?</h3>
<div class="outline-text-3" id="text-not-everybody-wants-tech-society">
<p>
Contrary to popular belief, not everybody wants to live in a technologically-advanced society where everybody lives harmoniously with each other.
Many people assume that everybody wants exactly this, and that this implies the existence of an objectively-correct morality, but there are some notably interesting ideologies that oppose it: Efilism and Neo-Luddism.
</p>

<p>
<a href="https://thewaywardaxolotl.blogspot.com/2017/06/efilism.html">Efilists</a> disagree because they believe in absolute negative-utilitarianism, that not even the existence of the smallest quantity of pain can ever be morally justified.
Efilists recognize that wherever life exists, problems will never go away.
Efilists thus believe that the most morally correct thing to do would be to eliminate all life so that problems will stop existing forever.
</p>

<p>
It&rsquo;s also naive to believe that technology is the solution to all of humanity&rsquo;s problems.
It is impossible for life to exist without problems, because once again, problems will never go away for as long as life continues to exist.
<a href="https://en.wikipedia.org/wiki/Neo-Luddism">Neo-Luddites</a> and Anarcho-Primitivists (Anprims) even argue that technology causes more problems than it solves.
</p>

<p>
Both of these ideologies have their shortfallings, but in some ways, these two ideologies are more enlightened than the conventional Humanist worldview of the West.
There might even be more ideologies that oppose this premise than just the two counter-examples that I have mentioned here.
But the bottom line is that it&rsquo;s not universally agreed upon that a utopia where maximal morality is achieved would be a harmonious, technologically-advanced society.
Hence, the premise that everybody wants to achieve that cannot be assumed as a basis for objective morality.
</p>

<p>
The instinctive generation of values by our brains does not provide us with a basis for value either, unless we make a conscious choice to an important question, and we recognize that it technically has no rational basis.
Answering <a href="https://thewaywardaxolotl.blogspot.com/2023/06/lucifers-question.html">Lucifer&rsquo;s Question to affirm or reject life</a> is the point at which a subject crosses the <a href="#why-not-objective">is-ought gap</a>.
</p>
</div>
</div>

<div id="outline-container-not-an-appeal-to-people" class="outline-3">
<h3 id="not-an-appeal-to-people"><span class="section-number-3">4.9.</span> Isn&rsquo;t it an appeal to the people fallacy to argue for societies based on consensus?</h3>
<div class="outline-text-3" id="text-not-an-appeal-to-people">
<p>
No. Appeal to the People might be a valid fallacy for epistemological or scientific reasoning, but it&rsquo;s <i>not</i> a legitimate fallacy when reasoning about ethical or political philosophy.
Epistemology and Science are based on sensory knowledge, whereas Ethics and Politics are based on emotional/value knowledge.
If anything, the real fallacy here is trying to apply sensory knowledge outside of its scope of appropriate use.
</p>
</div>
</div>

<div id="outline-container-not-a-subjectivist-fallacy" class="outline-3">
<h3 id="not-a-subjectivist-fallacy"><span class="section-number-3">4.10.</span> Isn&rsquo;t it a subjectivist fallacy to insist that morality is perspective-dependent?</h3>
<div class="outline-text-3" id="text-not-a-subjectivist-fallacy">
<p>
No. This lacks an understanding about the epistemological limits of human reasoning.
Epistemology and science are based on sensory knowledge, whereas morality is based on emotional/value knowledge.
Sensory knowledge about reality is convergent between multiple minds, whereas <a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-subjectivity.html">emotional/value knowledge isn&rsquo;t necessarily so</a>.
The real fallacy here is trying to apply sensory knowledge outside of its scope of appropriate use.
</p>

<div class="opponent" id="orgb27613a">
<p>
Doesn&rsquo;t science use some value judgments too? (e.g. certain analytical methods on observation are more accurate than others) This would mean that science is also based on value to some extent, right?
</p>

</div>
<p>
To an extent, yes.
But the difference is that morality isn&rsquo;t based on sensory knowledge at all.
Read more: <a href="https://thewaywardaxolotl.blogspot.com/2023/08/theories-of-knowledge.html">Theories of Knowledge</a>
</p>

<div class="opponent" id="org737c5b8">
<p>
But if we assume there couldn&rsquo;t be objective moral standards, then people will have the freedom to do whatever they want.
It would also imply that no one and no action can be morally judged as &ldquo;bad&rdquo; or &ldquo;good&rdquo;, including the Holocaust.
</p>

</div>
<p>
Not necessarily.
Even if we conclude subjective morality, there are still laws that are <a href="https://en.wikipedia.org/wiki/Intersubjectivity">intersubjectively</a> agreed upon that prevent people from doing whatever they want.
And I can still judge people even though I don&rsquo;t believe in objective morality.
I do it all the time, so there&rsquo;s no contradictions there.
</p>

<p>
It is true that the Holocaust (and every historical event for that matters) is and was not objectively bad since there&rsquo;s always a perspective from which they could be viewed as &ldquo;good&rdquo;.
But that doesn&rsquo;t mean that we can&rsquo;t still view them as &ldquo;bad&rdquo; from a rational and clearly-defined perspective.
</p>
</div>
</div>

<div id="outline-container-standpoint-theory-meaninglessness" class="outline-3">
<h3 id="standpoint-theory-meaninglessness"><span class="section-number-3">4.11.</span> The Meaninglessness of the Standpoint Theory of Truth</h3>
<div class="outline-text-3" id="text-standpoint-theory-meaninglessness">
<p>
See: <a href="../epistemology/representationalism#standpoint-theory-meaninglessness">Philosophy of Truth: The Meaninglessness of the Standpoint Theory of Truth</a>.
</p>
</div>
</div>

<div id="outline-container-Qs-for-moralists" class="outline-3">
<h3 id="Qs-for-moralists"><span class="section-number-3">4.12.</span> Questions For Moralists About Universal Rights</h3>
<div class="outline-text-3" id="text-Qs-for-moralists">
<div class="opponent" id="org090f782">
<p>
There is a universal set of rights that every individual should be entitled to.
</p>

</div>
<ul class="org-ul">
<li>What is this so-called universal set of rights?</li>
<li>Can you state every right within this universal set?</li>
<li>Why does this universal set of rights exist?</li>
<li>Where does this universal set of rights come from? What is your <a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-value.html">theory of value</a>?</li>
<li>Why is this so-called universal set of rights better than every other theory of rights?</li>
<li>Who enforces it? If you can&rsquo;t enforce it, why should I care about it?</li>
<li>What happens if people disobey or violate it?</li>
<li>Why can&rsquo;t everybody agree on which rights should be included in the universal set?</li>
<li>Why don&rsquo;t most people already follow and abide by this universal set of rights?</li>
<li>Do you believe it&rsquo;s immoral to force someone else to conform to your own morality? Why or why not?</li>
<li>How do you explain and reconcile how moral views vary from culture to culture, and change over time?</li>
<li>How can you be certain that what&rsquo;s &ldquo;moral&rdquo; now will also be moral in the future?</li>
<li>What should we do if what&rsquo;s &ldquo;moral&rdquo; now is unlikely to remain moral in the future?</li>
<li>Why should I support other people&rsquo;s universal rights, when it doesn&rsquo;t benefit or affect me?</li>
<li>How can you prove to me that you didn&rsquo;t just make this all up?</li>
</ul>
<p>
The simpler belief is that there is no universal set of human rights.
<a href="../epistemology/reasoning-skills#philosophical-razors">Occam&rsquo;s Razor</a> concludes that that is the correct conclusion.
If moralists don&rsquo;t have any arguments that a &ldquo;universal set of human rights&rdquo; is the simpler belief, then they should concede.
</p>

<p>
To be clear, legal rights are a coherent concept because they are created and enforced by a government.
Moral rights are not a coherent concept because they presuppose morality, they presuppose that morality is universal, etc.
I can reject morality and still explain why legal rights exist.
There is nothing contradictory about that.
What is contradictory is to take morality (however that&rsquo;s defined) for granted.
</p>

<p>
People understand that international human rights are a recent construct, one that has been <i>selectively</i> applied over and over.
But they ignore that history has rarely ever operated in this fashion, except in limited capacity.
</p>
</div>
</div>

<div id="outline-container-when-life-becomes-zero-sum" class="outline-3">
<h3 id="when-life-becomes-zero-sum"><span class="section-number-3">4.13.</span> When Life Becomes Zero-Sum</h3>
<div class="outline-text-3" id="text-when-life-becomes-zero-sum">
<p>
Without cooperation, life becomes zero-sum when the population reaches the carrying capacity of its environment.
If either of those conditions are not meant (not possible to cooperate with others, or population is below environment&rsquo;s carrying capacity), then life can be &ldquo;positive sum&rdquo;.
The point in recognizing the conditions for life to be zero-sum is to show further evidence why morality is not objective.
When life does become zero-sum, it&rsquo;s every man for himself.
</p>
<ul class="org-ul">
<li>For every prey that gets eaten alive, there is a predator who doesn&rsquo;t starve to death.</li>
<li>For every prey that escapes, there is a predator who ends up starving to death.</li>
<li>For every guy who misses a job opportunity, someone else will get it instead.</li>
<li>For every male that doesn&rsquo;t get to mate with the prized female, some other victorious male does.</li>
<li>For every slave, there is a slave owner who profits big time.</li>
<li>For every guy who lost money on the stock market, someone else gained money. For every buyer, there is a seller and vice versa.</li>
<li>For every guy who lost scarce, precious resources, someone else acquired those valuable resources and used them to survive another day, become more reproductively successful, and have more offspring than the loser.</li>
<li><a href="../civilization/case-against-libertarianism#life-is-zero-sum">Every existing organism can only exist at the cost of another</a>.</li>
<li>And so forth.</li>
</ul>
<p>
When there are winners who can only come at the expense of losers, it&rsquo;s in everyone&rsquo;s self-interest to be a winner rather than a loser.
In such cases, people are <i>not</i> obligated to care about whether that causes someone else to incur negative consequences.
Evolution is the game that runs literally everything, so that&rsquo;s the game everybody <i>has to</i> play, even if it comes at the cost of others.
</p>

<p>
Now, life doesn&rsquo;t always have to be a zero-sum game.
When individuals cooperate with each other, they can both become better off if they manage to solve the prisoner&rsquo;s dilemma between each other.
Unfortunately, it isn&rsquo;t always guaranteed that the other side won&rsquo;t defect, and that&rsquo;s why cooperating is not an objectively good choice.
</p>

<table class="noborders"><colgroup><col class="org-left"><col class="org-left"></colgroup><tbody><tr>
<td class="org-left"><img src="../images/bad-guys-vs-anti-bad-guys-meme.jpg" alt="Meme about determining who the bad guys are." width="420"></td>
<td class="org-left"><img src="../images/russell-emotive-conjugation.jpg" alt="Meme about hating foreigners to justify conquering them." width="600"></td>
</tr></tbody></table>
</div>
</div>
</div>

<div id="outline-container-selfishnes-vs-altruism-questions" class="outline-2">
<h2 id="selfishnes-vs-altruism-questions"><span class="section-number-2">5.</span> Selfishness Versus Altruism Questions</h2>
<div class="outline-text-2" id="text-selfishnes-vs-altruism-questions">
<p>
If you would like to read an actual essay explaining Selfishness versus Altruism, then we recommend reading: <a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Altruism and Selfishness</a>.
</p>
</div>

<div id="outline-container-selfishness-definitions" class="outline-3">
<h3 id="selfishness-definitions"><span class="section-number-3">5.1.</span> Wouldn&rsquo;t a more coherent definition of the word &ldquo;selfishness&rdquo; be &ldquo;pursuing your own interests at the expense of others&rdquo;?</h3>
<div class="outline-text-3" id="text-selfishness-definitions">
<p>
No, not at all. Consider the following dictionary entries:
</p>
<ul class="org-ul">
<li><a href="https://en.wiktionary.org/wiki/selfishness#English">Wiktionary defines selfishness as</a>: The quality of being selfish; the condition of putting one&rsquo;s own interests before those of others.</li>
<li><a href="https://www.merriam-webster.com/dictionary/selfishness">Merriam Webster defines selfishness as</a>: The quality or state of being selfish : a concern for one&rsquo;s own welfare or advantage at the expense of or in disregard of others.</li>
<li><a href="https://www.dictionary.com/browse/selfishness">Dictionary.com defines selfishness as</a>: The quality or state of caring only for oneself or one&rsquo;s own interests.</li>
</ul>
<p>
The phrases &ldquo;regardless of others&rdquo;, &ldquo;without regard for others&rdquo;, or &ldquo;in disregard of others&rdquo; all simply mean that you are concerned with yourself, and not concerned with other people.
In other words, you are acting for your benefit, not theirs.
On the other hand, a prepositional phrase like &ldquo;at the expense of others&rdquo; has very different semantics since it would imply that you can only benefit yourself if others are negatively affected by your actions.
</p>
</div>
</div>

<div id="outline-container-altruism-and-evolution" class="outline-3">
<h3 id="altruism-and-evolution"><span class="section-number-3">5.2.</span> Isn&rsquo;t Altruism part of human evolution?</h3>
<div class="outline-text-3" id="text-altruism-and-evolution">
<p>
No, it isn&rsquo;t. All of the so-called examples of altruism in human evolution are misunderstandings of how evolution actually works:
</p>
<ul class="org-ul">
<li><a href="https://www.amazon.com/dp/B0BPXJ85W7">Debunking the Selfish Gene by T. K. Van Allen</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Altruism and Selfishness</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2014/04/bees-are-not-social.html">Bees are not Altruistic</a></li>
<li><a href="https://www.youtube.com/watch?v=K97OP2p9JTQ">Pathological Altruism</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2014/04/family-and-society.html">Family, Transfers of Energy, and Exchanges of Labor</a></li>
</ul>
<p>
If anything, altruism is self-defeating, and any attempt to establish altruism in nature would be quickly erased as soon as evolution takes back the helm and reinstates selfishness.
Altruism cannot evolve, due to the free-rider problem.
</p>
</div>

<div id="outline-container-reciprocal-altruism" class="outline-4">
<h4 id="reciprocal-altruism"><span class="section-number-4">5.2.1.</span> What about Reciprocal Altruism?</h4>
<div class="outline-text-4" id="text-reciprocal-altruism">
<p>
If Altruism is defined as &ldquo;acting to benefit others&rdquo;, then Reciprocal Altruism is an oxymoron.
If it&rsquo;s guaranteed that you&rsquo;re going to get helped back, then it&rsquo;s not really altruism. It&rsquo;s selfishness and <a href="../faqs/morality#cooperation-vs-collectivism">cooperation</a>.
</p>
</div>
</div>

<div id="outline-container-kin-selection-theory-bogus" class="outline-4">
<h4 id="kin-selection-theory-bogus"><span class="section-number-4">5.2.2.</span> What about Kin Selection Theory providing a basis for Altruism?</h4>
<div class="outline-text-4" id="text-kin-selection-theory-bogus">
<p>
Main Article: <a href="https://thewaywardaxolotl.blogspot.com/2019/07/kin-selection-theory-is-wrong.html">Why Kin Selection Theory is Wrong</a>.
</p>

<p>
The nutshell summary is that:
</p>
<ol class="org-ol">
<li>Parents care for their children because they have strong selfish incentives to do so for their own reproductive success,</li>
<li>Kin altruism between siblings is best explained as the parents&rsquo; selfish behavior being expressed in the children as part of their extended phenotype (cooperative children are easier to raise than non-cooperative children),</li>
<li>Stotting/pronking is a demonstration to predators to try catching someone else in the herd that is obviously less physically fit than the pronker, and</li>
<li>Friends helping friends is cooperation motivated by selfish interest and the <a href="https://thewaywardaxolotl.blogspot.com/2014/04/family-and-society.html">emotional accounting system</a>, not &ldquo;reciprocal altruism&rdquo; (which is oxymoronic since altruism is selfless).</li>
<li>Other purported examples of kin altruism can be further debunked on a case-by-case basis.</li>
</ol>

<p>
Suppose you have a population of individuals who are altruistic (that is, self-sacrificing) for the good of the race or species (or any group &#x2013; it doesn&rsquo;t matter).
Now suppose you introduce a variant individual who is purely selfish: only works for the good of his children, not the good of the group.
As a member of the group, he will receive transfers of energy from others, but he will not give anything back, and thus he will have more energy to invest in his offspring.
The selfish strategy will always outcompete the altruistic strategy.
</p>

<p>
That is why love is a very narrow thing.
We care for our mates, our children, our grandchildren, perhaps a little for our nephews and nieces, but that&rsquo;s about it.
Even though we all share 99.9% of our DNA with one another, we are still selected for reproductive selfishness, because any deviation from that strategy would be quickly eliminated by natural selection.
</p>
</div>
</div>

<div id="outline-container-bees-and-ants-arent-altruistic" class="outline-4">
<h4 id="bees-and-ants-arent-altruistic"><span class="section-number-4">5.2.3.</span> Aren&rsquo;t worker ants and worker bees examples of altruism existing in Nature, since they can&rsquo;t reproduce and thus only work for the good of their species?</h4>
<div class="outline-text-4" id="text-bees-and-ants-arent-altruistic">
<p>
It is true that worker bees and worker ants can&rsquo;t reproduce, but once again, this is a misunderstanding of how evolution works in <a href="https://en.wikipedia.org/wiki/Haplodiploidy">haplodiploid species like ants, bees, and wasps</a>.
Evolution is selecting for the genes of the Queens, not the worker ants.
The Queen has control over which eggs get fertilized with sperm stored from mating, so the drones are pure extensions of the Queen because they only carry her genes.
A male&rsquo;s genes are from its mother, a worker&rsquo;s genes are from its mother and its father&rsquo;s mother.
In bees and ants, all genes pass through a female body at least every second generation.
Usually, that female body was a Queen. This means that all ant genes are selected for their ability to help Queens reproduce.
Thus, this is <i>not</i> a case of altruism existing in Nature.
</p>

<p>
In other cases when organisms ostensibly sacrifice themselves for the survival of the species, they do so because it ensures the survival of their children, not their species, which increases their reproductive success.
If organisms did sacrifice themselves for their own species, but not their children, then their genes would die out, and altruism would cease to exist within that species.
</p>

<p>
For more information, read: <a href="https://thewaywardaxolotl.blogspot.com/2014/04/bees-are-not-social.html">Bees are not Altruistic</a>.
</p>
</div>
</div>
</div>

<div id="outline-container-helping-others" class="outline-3">
<h3 id="helping-others"><span class="section-number-3">5.3.</span> Doesn&rsquo;t helping out your friends and family count as altruism?</h3>
<div class="outline-text-3" id="text-helping-others">
<p>
Usually no, and this is also a misunderstanding of what true altruism actually is.
If you&rsquo;re helping people out who will probably help you back in the future or return the favor, then that&rsquo;s selfish behavior, not altruistic behavior.
When people are helping out their family and friends, <a href="https://thewaywardaxolotl.blogspot.com/2014/04/family-and-society.html">they are typically doing transactions between their emotional accounting systems</a>.
These accounting systems evolved not because humans evolved to be altruistic, but rather because <a href="https://en.wikipedia.org/wiki/Tit_for_tat">tit-for-tat</a> has proven to be the most effective game-theoretical strategy.
</p>
</div>
</div>

<div id="outline-container-helping-everybody" class="outline-3">
<h3 id="helping-everybody"><span class="section-number-3">5.4.</span> Why shouldn&rsquo;t we help everybody?</h3>
<div class="outline-text-3" id="text-helping-everybody">
<p>
It&rsquo;s a <a href="https://en.wikipedia.org/wiki/Fallacy_of_composition">Composition Fallacy</a> to assume that being able to help others implies that we can collectively help the entire world.
<a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Altruism is not sustainable in nature</a>.
At most, we can help people who are likely to help ourselves, and that is the natural limit to which people can sustainably help others.
</p>
</div>
</div>

<div id="outline-container-cynicalism-is-not-selfishness" class="outline-3">
<h3 id="cynicalism-is-not-selfishness"><span class="section-number-3">5.5.</span> Isn&rsquo;t it misguided to have such a cynical view of human nature?</h3>
<div class="outline-text-3" id="text-cynicalism-is-not-selfishness">
<p>
We don&rsquo;t equate selfishness to &ldquo;cynicalism&rdquo;, hence why we define the two differently.
If someone is selfish, then they are prioritizing the pursuit of their self interests first and foremost, but they will often have to obey their emotional accounting systems as a means to an end.
</p>

<p>
We define cynicalism as being selfish, except that you don&rsquo;t adhere to your emotional accounting system.
If someone helps out a cynical person, the cynical person would accept the help, but then they wouldn&rsquo;t help the helper back, which would incentivize the helper to not help the cynical person in the future.
</p>
</div>
</div>

<div id="outline-container-why-we-should-be-selfish" class="outline-3">
<h3 id="why-we-should-be-selfish"><span class="section-number-3">5.6.</span> Why should we be selfish?</h3>
<div class="outline-text-3" id="text-why-we-should-be-selfish">
<p>
Because we have no other choice.
We can only do what we want to do, so in that sense, we&rsquo;re always being (psychologically) selfish.
Some people might want to be nicer than others, and some might want to be cruel.
Regardless, all voluntary acts are based on desires.
</p>

<p>
<a href="../epistemology/determinism#determinism-vs-free-will">Desires are not chosen</a>.
A serial killer chooses to kill, but does not choose to want to kill.
Likewise, a philanthropist chooses to help the poor, but does not choose to want to help the poor.
Both are acting on their desires.
Both are psychologically selfish.
</p>

<p>
<a href="#altruism-and-evolution">Altruism cannot evolve due to the free-rider problem</a>, so life evolved to be selfish instead.
</p>
</div>
</div>

<div id="outline-container-altruism-and-civilization" class="outline-3">
<h3 id="altruism-and-civilization"><span class="section-number-3">5.7.</span> Isn&rsquo;t Altruism integral to human civilization?</h3>
<div class="outline-text-3" id="text-altruism-and-civilization">
<p>
No, not at all.
Society is not based on altruism at any level: global, racial, national, or even tribal.
Society is based on cooperation between selfish individuals, not Altruism and Collectivism.
</p>

<p>
<a href="https://www.youtube.com/watch?v=K97OP2p9JTQ">Every altruistic civilization is doomed to fail</a>.
</p>
</div>
</div>

<div id="outline-container-cooperation-vs-collectivism" class="outline-3">
<h3 id="cooperation-vs-collectivism"><span class="section-number-3">5.8.</span> What is the difference between cooperation versus collectivism?</h3>
<div class="outline-text-3" id="text-cooperation-vs-collectivism">
<p>
First, we have to define <i>collectivism</i>: when individuals place the collective above the individual for the sake of the collective.
</p>

<p>
Next, we have to define <i>cooperation</i>.
Cooperation is when rational individuals work together for mutual benefit as a way to achieve their self-interests, however, they <i>never</i> place the group above the individuals for the sake of the group.
Cooperation requires trust (the expectation of reciprocity), and every individual who <i>collaborates</i> does so with the expectation that they will get something in return.
</p>

<p>
Typically, most collectivists will take examples of <i>cooperation</i> and erroneously classify those examples as situations where collectivism is a good thing, in order to promote actual instances of collectivism, such as socialism, pious religions, and authoritarianism.
When collectivists frame cooperation as collectivism, they often portray it as being based on empathy or affection instead of trust since they don&rsquo;t understand that cooperation is based on selfishness.
</p>
</div>
</div>
</div>

<div id="outline-container-libertarian-questions" class="outline-2">
<h2 id="libertarian-questions"><span class="section-number-2">6.</span> Libertarian Questions</h2>
<div class="outline-text-2" id="text-libertarian-questions">
</div>
<div id="outline-container-the-NAP" class="outline-3">
<h3 id="the-NAP"><span class="section-number-3">6.1.</span> Isn&rsquo;t the Libertarian Non-Aggression Principle (NAP) the objective origin of morality?</h3>
<div class="outline-text-3" id="text-the-NAP">
<p>
No, and for several reasons.
</p>
<ol class="org-ol">
<li><a href="../civilization/case-against-libertarianism#deontological-ethics-problems">Consequentialist Ethics are superior to deontological ethics</a>.</li>
<li><a href="../civilization/case-against-libertarianism#NAP">It is misleading to think of the Libertarian NAP as a single principle</a>.</li>
<li><a href="../civilization/case-against-libertarianism#life-is-zero-sum">The Libertarian NAP ignores that life becomes zero-sum when a population reaches the carrying capacity of the environment</a>.</li>
</ol>
</div>
</div>

<div id="outline-container-necessary-evil" class="outline-3">
<h3 id="necessary-evil"><span class="section-number-3">6.2.</span> But there&rsquo;s no such thing as a necessary evil.</h3>
<div class="outline-text-3" id="text-necessary-evil">
<p>
This question assumes that &ldquo;evil&rdquo; is well-defined and objective, but it isn&rsquo;t. <a href="#deontological-ethics-problems">It also assumes that humans should act according to deontological ethics</a>.
</p>
</div>
</div>

<div id="outline-container-universally-preferable" class="outline-3">
<h3 id="universally-preferable"><span class="section-number-3">6.3.</span> Why isn&rsquo;t morality the same thing as &ldquo;universally preferable behavior&rdquo;?</h3>
<div class="outline-text-3" id="text-universally-preferable">
<p>
Because moral preferences depend on perspective.
</p>

<p>
For example, most people in Japan, the United States, and Europe view the <a href="https://en.wikipedia.org/wiki/Assassination_of_Shinzo_Abe">Assassination of Shinzo Abe</a> to be a &ldquo;morally bad&rdquo; thing since they like Japan, but most people in China and Korea view his assassination to be a &ldquo;morally good&rdquo; thing because they hate Japan.
If it was truly the case that it is &ldquo;universally preferable&rdquo; to condemn murder, then why are there hundreds of millions people who applaud the assassination and celebrate the assassin as a hero?
</p>


<p>
The following addresses a list of objections by someone who defines morality as &ldquo;universally preferable behavior&rdquo;.
</p>

<div class="opponent" id="org57be85d">
<p>
Nobody can logically defend the position that NAP-violations can be morally good.
</p>

</div>
<p>
Of course they can.
For the same reason why Libertarians can&rsquo;t agree on whether abortion violates the NAP or not.
Or how Libertarians can&rsquo;t agree on whether blackmailing is NAP-compliant.
Or how Ancaps may drop-kick people out who disagree with their interpretation of the NAP.
The bottom line is that &ldquo;Aggression&rdquo; is subjective, so the NAP is also subjective.
</p>

<div class="opponent" id="org336a369">
<p>
Only creatures that have the mental capacity to conceive of abstract rules can be bound and protected by said rules - and only if they reciprocate.
</p>

</div>
<p>
That is very arbitrary.
By the same logic, a newborn infant or a person with severe dementia may not be protected by the Libertarian NAP if they lack the mentally ability to understand it.
Most people would disagree and insist that those humans deserve the same legal protections as more mentally capable humans.
</p>

<div class="opponent" id="orga5198fa">
<p>
In moral terms, the only important criteria is if they&rsquo;re able to understand and reciprocate rules. Moral rules, if they exist, are a subset of these that ought to be universally upheld.
</p>

</div>
<p>
According to who, and why?
For starters, this claim doesn&rsquo;t make any sense since your definition of morality has been easily debunked.
</p>

<div class="opponent" id="org9b7db99">
<p>
Modern moral theory says you aren&rsquo;t obligated to help someone hanging off the edge of a cliff.
</p>

</div>
<p>
Modern Liberals disagree.
Who&rsquo;s to say that your beliefs are more correct than theirs, besides yourself?
</p>

<div class="opponent" id="org4acc855">
<p>
Other species are not subject to the same moral protections as us, since they can neither conceive nor reciprocate moral norms.
</p>

</div>
<p>
If that&rsquo;s true, then human babies, severely retarded people, and the mentally disabled elderly do not have the same legal protections as everyone else.
This contradicts most people&rsquo;s moral intuitions in the modern world.
</p>

<div class="opponent" id="orga96a223">
<p>
Animals shouldn&rsquo;t breed if there isn&rsquo;t enough energy around to sustain themselves. Just like a mother is being cruel/evil if she has babies that she cannot feed.
</p>

</div>
<p>
And yet animals will still breed anyway irregardless.
If there&rsquo;s a famine and civilization collapses, the most reasonable thing to do from a biological/evolutionary/game-theoretic point-of-view is to take what you can and give nothing back.
Because that is what will maximize your reproductive success.
And all the organisms that follow that strategy will spread their genes to a greater extent, whereas the most altruistic ones who choose to have fewer offspring will have their kind die out.
</p>

<div class="opponent" id="org341e04b">
<p>
&ldquo;Humans aren&rsquo;t fighting over the last bits of air, land, water, etc.
</p>

</div>
<p>
That&rsquo;s literally what they&rsquo;ve done all throughout modern history.
The modern era is only an exception to that, and <a href="../civilization/technology#modern-civilization-permanent-collapse">it won&rsquo;t last forever unless we do something about it</a>.
</p>

<div class="opponent" id="org942f820">
<p>
Our competitions are chosen / voluntary.
</p>

</div>
<p>
No, they aren&rsquo;t.
If competition was truly voluntary, then there would be no competition at all because everyone would avoid it.
One of the most fundamental principles of geopolitics is that selfish players (countries in this case) will compete against each other for scarce resources.
And there are no permanent friends, only temporary allies for as long as the right conditions for cooperation hold true.
</p>

<div class="opponent" id="org870f38f">
<p>
Having one more human born on this planet won&rsquo;t hurt any existing human.
</p>

</div>
<p>
If it&rsquo;s exactly <i>one</i> human, then probably not.
But it isn&rsquo;t.
The world population is increasing by several tens of millions of humans every year.
Only a fool would insist that this continuing trend could never go wrong on a planet with finite resources.
Unlimited population growth is unsustainable, and that&rsquo;s what we&rsquo;re heading towards.
</p>

<div class="opponent" id="org30d3077">
<p>
The energies in our ecosystems aren&rsquo;t that scarce.
</p>

</div>
<p>
Yes they are, and they always have been.
And it will only become more apparent as the world population continues to grow.
If that continues, all it will take is another major crisis or two to catastrophically disrupt the world&rsquo;s food/resource supply chains.
In such an unfortunate event, humanity will catch a glimpse of how biological systems have <i>always</i> worked.
</p>
</div>
</div>
</div>

<div id="outline-container-technology-and-moral-progress" class="outline-2">
<h2 id="technology-and-moral-progress"><span class="section-number-2">7.</span> How Does Technology Create The Illusion Of Moral Progress?</h2>
<div class="outline-text-2" id="text-technology-and-moral-progress">
<p>
&ldquo;Moral Progress&rdquo; is an illusion created by the advancement of technology.
Without technology, we wouldn&rsquo;t have seen any improvements in material conditions for humans.
Historically, humans only started to care about moral progress when they no longer had to focus on just being able to survive 24/7, something that has only been made possible by the advent of technology.
A human who is focused on survival 24/7 would never have any time to think nor care about what&rsquo;s moral because they&rsquo;re only focused on what helps them survive, as well as what helps their community survive since the community aids the survival.
If humans had historically prioritize the morals that most people have in the modern world over their own survival, then their genes and memes would fail to make the next generation, compared to other humans who did.
</p>

<p>
Large-scale cooperation facilitated by Capitalism and the Rule of Law has made it possible for more people than ever to not have to live in abject poverty.
</p>
<ul class="org-ul">
<li>The widespread adoption of vaccines and modern medicine has made it possible to eradicate many diseases that have historically plagued human societies.</li>
<li>In modern post-WWII times, war has been quite uncommon compared to its historical presence, but this has only been made possible due to the establishment of improved living conditions around the world (thus reducing the need to compete for resources worldwide), free trade (which reduces conflicts between nations), and the intense favorability to avoid the gruesome potential for destruction and nuclear war that has never been seen before.</li>
<li>Modern contraception and birth control made it possible to not have children born into undesirable conditions.</li>
<li><a href="../civilization/why-georgism-lost-popularity#20th-century-mistakes">The automobile relieved the pressure on land values</a> and land rent by making it possible for people to move out of the cities and into the suburbs, although this has only been a temporary fix since the core problem has yet to be resolved by universal LVT.</li>
<li>The abolition of many cruel punishments were at least partly due to technology and economic progress.
Better technology for prisons and the economic ability to support prisoners makes it easier to eliminate the death penalty and other forms of capital punishment.
Poorer society cannot afford to lock up thieves, so they&rsquo;ll flog them instead.</li>
<li>The printing press and the expansion of literacy led to intellectual and religious freedom, which contributed to the decline of religious persecution, and other forms of discrimination.</li>
<li>The decline in ableism has been partially aided by newer technologies that help disabled people gain the same or similar abilities to everyone else.</li>
<li>Since people in developed countries aren&rsquo;t focused on surviving 24/7 anymore, they can afford to promote things like humans rights or environmentalism.</li>
</ul>

<p>
People who believe in &ldquo;moral progress&rdquo; usually believe in some hypothetical &ldquo;<a href="https://en.wikipedia.org/wiki/End_of_history">End of History</a>&rdquo;.
They also tend to believe that their ideology encapsulates the End of History.
Many End of History narratives also overlook the <a href="https://en.wikipedia.org/wiki/Anthropic_principle">Anthropic Principle</a> and have <a href="https://en.wikipedia.org/wiki/Hindsight_bias">Hindsight Bias</a>.
</p>
</div>

<div id="outline-container-illusions-in-moralist-communities" class="outline-3">
<h3 id="illusions-in-moralist-communities"><span class="section-number-3">7.1.</span> Technological Changes That Various Moralists Would Claim To Be &ldquo;Moral Progress&rdquo;</h3>
<div class="outline-text-3" id="text-illusions-in-moralist-communities">
<p>
The following is a list of changes enabled by technology that various moralists would claim to be &ldquo;moral progress&rdquo; according to their perceptions of the world.
</p>
<ul class="org-ul">
<li>Vegan diets only being made possible since humans don&rsquo;t rely on hunting and gathering anymore, clothing made from plants or plant materials instead of animal hides and fabrics, etc (according to vegans&rsquo; perspectives).</li>
<li>Gender reassignment surgeries / sex change operations / hormone therapies that make it possible for gender dysphoric people to change their bodies to be more like the opposite sex and less like the biological sex that they were born to.</li>
<li>Dating websites and dating apps have made it easier than ever for homosexuals and bisexuals to find a partner, and they are now the leading method for finding a partner in many parts of the world.</li>
<li>Anti-natalists view contraception and abortion as some of the most important technological inventions ever.</li>
<li>Capitalists view technology favorably because technology has caused capitalism to progress and improve people&rsquo;s standard of living.</li>
</ul>
</div>
</div>

<div id="outline-container-ideologies-future-progress" class="outline-3">
<h3 id="ideologies-future-progress"><span class="section-number-3">7.2.</span> Future Moral Progress According To Various Ideologues</h3>
<div class="outline-text-3" id="text-ideologies-future-progress">
<ul class="org-ul">
<li>The technological ability to create synthetic pills that could supply humans with necessary vitamins and minerals that can only be found in animals and not plants (some nutrition-conscious vegans have argued that this should replace eating animal products as the way to acquire those nutrients for humans and other necessarily omnivorous species).</li>
<li>Ancaps often argue that their fantasy worlds will have amazing technologies like seasteading, blockchains, and more that will enable them to live in a super &ldquo;ethical&rdquo; utopia that has never been seen before. But if new/innovative technologies are necessary to make such utopias possible, then hypothetical &ldquo;moral improvements&rdquo; like the kinds alluded to by ancaps are only made possible by advancing technologies, as it has always been the case.</li>
<li>Efilists believe that humanity should destroy the Earth and render it uninhabitable for all sentient life, but this never would have been possible in previous eras because the necessary technology for accomplishing this goal never existed prior to modernity.</li>
<li>All kinds of Utopian Ideologists want to colonize Mars because it gives them something to work towards as a means of fulfilling their needs for the <a href="../misc/industrial-society-and-its-future-manifesto#power-process">power process</a>. They also because they perceive Mars as a place of opportunity and free of foreign interference to set up whatever so-called utopia and utopian ideology that they believe in. Examples:
<ul class="org-ul">
<li>Ancaps who want Mars to be a so-called Ancapistan paradise.</li>
<li>Communists and Anarcho-Communists who want Mars to be a so-called (Anarcho)-Communist paradise.</li>
<li>Some Esperanto Speakers who would like Esperanto to become the language of Mars.</li>
</ul></li>
</ul>

<p>
Moreover, <a href="../civilization/technology#futurist-fantasies">it&rsquo;s extremely unlikely that humanity will ever colonize Mars due to the Laws of Physics and Economic Realities</a>.
</p>
</div>
</div>

<div id="outline-container-moral-progress-without-tech" class="outline-3">
<h3 id="moral-progress-without-tech"><span class="section-number-3">7.3.</span> &ldquo;Moral Progress&rdquo; That Wasn&rsquo;t Caused By Advancing Technology</h3>
<div class="outline-text-3" id="text-moral-progress-without-tech">
<p>
Even some of these changes were partially caused by technology and economic progress to some extent, but they seem to be the most far removed from being caused by technology as the other examples that I thought of.
</p>
<ul class="org-ul">
<li>The replacement of monarchies by democracies.</li>
<li>The progression of human rights (e.g. freedom of expression, right to fair trial, etc).</li>
<li>The decline of religious persecution, racial segregation, racism, sexism, homophobia, xenophobia, ableism, etc.</li>
<li>The decline of European colonialism. Eventually, it became too expensive to rule overseas colonies, and the local populations began protesting and fighting for independence.
Ironically, European colonialism actually seems to have been mostly beneficial in most (but not all) cases since technologies caused declines in infant mortality rates, starvation, diseases, and other factors that have limited the local populations.</li>
</ul>

<p>
Interestingly, Neo-Luddites and Anarcho-Primitivists are some of the few people who believe that the progression of technology has actually caused a significant regression in moral progress.
Virtually everyone else enthusiastically views technology as a way to continue &ldquo;moral progress&rdquo;.
</p>

<p>
Besides Neo-Luddites, the most extreme communists and socialists might also believe that humanity hasn&rsquo;t made much moral progress since they hate capitalism so much, even though capitalism has been largely beneficial for humanity.
</p>
</div>
</div>
</div>
<div id="outline-container-glossary" class="outline-2">
<h2 id="glossary"><span class="section-number-2">8.</span> Glossary</h2>
<div class="outline-text-2" id="text-glossary">
<p>
For clarity, these are the definitions that are used throughout this FAQs post:
</p>
<dl class="org-dl">
<dt>Morality (subjective)</dt><dd>What a person thinks people should and shouldn&rsquo;t do, i.e. what a person <i>wants</i> other people to do and/or how a person <i>wants</i> other people to behave, <a href="../epistemology/axiology">according to their values</a>. Note that &ldquo;morality&rdquo; has <a href="https://en.wiktionary.org/wiki/morality#English">many different definitions</a>, so it is highly vulnerable to the <a href="../language/sapir-whorf-theory">Sapir-Whorf Effect</a>.</dd>
<dt>Morality (colloquial)</dt><dd>The intersubjective consensus (within some group of people) of &ldquo;right&rdquo; and &ldquo;wrong&rdquo;, &ldquo;good&rdquo; and &ldquo;bad/evil&rdquo;, or what people should and shouldn&rsquo;t do, usually formed according to collective values. Since what people consider to be morally right or morally wrong depends on morality, this is a circular definition, and hence a meaningless one.</dd>
<dt>Morality (platonic realm)</dt><dd>The conception that morality has a platonic realm that everybody should try to follow. This does not exist in reality.</dd>
<dt>Post-Overton</dt><dd>The philosophical position that game theory, the intrinsic selfishness of life, and <a href="../faqs/morality#memetics">memetics</a> are the best way to understand morality. It is similar to moral relativism since it posits that morality can only be based on subjective values (which are perspective-dependent), but it&rsquo;s different since it also embraces the game-theoretic assumptions of selfishness and rationality, as well as the <a href="../faqs/morality#when-life-becomes-zero-sum">zero-sum nature of life</a>. Post-Overtons believe that the only legitimate rights are legal rights.</dd>
<dt>Post-Moralism</dt><dd>The same thing as Post-Overton, but with a different name.</dd>
<dt>Amoralism</dt><dd>An absence of, indifference towards, disregard for, or incapacity for morality.</dd>
<dt>(no term)</dt><dd>Moral Objectivism is the ethical view that all or some actions have intrinsic positive value (&ldquo;are good&rdquo;) and intrinsic negative value (&ldquo;are bad/evil&rdquo;), regardless of context, consequence, or perspective.</dd>
<dt>Moral Relativism</dt><dd>The position that morality is subjective and perspective-dependent. This term covers a range of different philosophical positions with different nuances. Moral Relativists believe that different individuals, groups, and cultures can all have different conceptions of morality that are each justified according to their own perspectives.</dd>
<dt>Moral Nihilism</dt><dd>The view that nothing is morally right or morally wrong.</dd>
<dt>Moral Realism</dt><dd>The position that moral propositions refer to objective features of the world. &ldquo;Moral Realism&rdquo; is a misnomer, and a sub-category of moral objectivism.</dd>
<dt>Is-Ought Gap</dt><dd>i</dd>
<dt>Is-Ought Fallacy</dt><dd>i</dd>
<dt>Normative</dt><dd>i</dd>
<dt>Selfishness</dt><dd>Acting for your own benefit, regardless of others.</dd>
<dt>Altruism</dt><dd>Acting for the benefit of other, at some cost to oneself.</dd>
<dt>Cynicalism</dt><dd>Selfishness, except that you take what you can, and give nothing back. A cynical person does not use a emotional accounting system, nor are they interested in cooperating during a prisoner&rsquo;s dilemma.
<ul class="org-ul">
<li>Note: We are aware that we are defining Cynicalism in a non-standard way, but we are doing so because we believe that the most common definition of &ldquo;Cynicalism&rdquo; is too closely related to the definition for &ldquo;Selfishness&rdquo;, and we think that &ldquo;Cynicalism&rdquo; would be better used to convey a shade of meaning that most people tend to mistakenly associate with the headword &ldquo;Selfishness&rdquo;. By explicitly defining &ldquo;Selfishness&rdquo; and &ldquo;Cynicalism&rdquo;, we can contrast the two definitions to show what &ldquo;Selfishness&rdquo; is not what most people think it is.</li>
</ul></dd>
<dt>Emotional Accounting System (EAS)</dt><dd>The system of emotions in a human&rsquo;s brain (and some other species&rsquo; brains too) that motivates people to do give-and-take behavior, or exchanges of labor. Evolution caused the EAS to develop in humans since they are more reproductively successful when they engage in give and take behavior within human tribes. The EAS is the primary reason why people are not <b>cynical</b>, and the behavior that EASs encourage does not count as &ldquo;reciprocal altruism&rdquo; since &ldquo;reciprocal altruism&rdquo; is an oxymoron.</dd>
<dt>Collaboration/Cooperation</dt><dd>When rational individuals work together for mutual benefit. When people are collaborating, the group is <i>never</i> places above the individuals for the sake of the group. Cooperation requires trust (the expectation of reciprocity), and every individual who <i>collaborates</i> does so with the expectation that they will get something in return.</dd>
<dt>Collectivism</dt><dd>When individuals place the collective above the individual for the sake of the collective.</dd>
<dt>Utopian Ideology</dt><dd>Any naive ideology that people will believe in order to claim moral superiority and maintain the illusion of knowledge. <b>Utopian Ideologies</b> typically use the <b>Rhetoric of Exploitation</b>, simple-minded worldviews, moral narratives, visionary fantasies, and effective memetic propagations to delude people and spread the ideology. Read more: <a href="https://thewaywardaxolotl.blogspot.com/2014/07/the-communists-who-took-power-in.html">Utopian Ideology</a>.</dd>
<dt>The Rhetoric of Exploitation</dt><dd>A Classic Tactic used by Utopian Ideologists to replace rationalist thinking with rhetoric and self-righteous nonsense. The key is to use selective metaphors and phrases and portray the &ldquo;oppressors&rdquo; as having agency and the &ldquo;victims&rdquo; as having no agency. Read more: <a href="https://thewaywardaxolotl.blogspot.com/2013/12/the-rhetoric-of-exploitation_21.html">The Rhetoric of Exploitation</a>.</dd>
</dl>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1" role="doc-backlink">1</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
These paragraphs were copy-edited from Sebastian Jensen&rsquo;s essay, &ldquo;<a href="https://theuntangler.wordpress.com/2022/03/06/problems-with-libertarianism/">Problems with Libertarianism</a>&rdquo;.
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2" role="doc-backlink">2</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Also see: <a href="https://www.reddit.com/r/BlackPillScience/top/">r/BlackPillScience</a>.
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3" role="doc-backlink">3</a></sup> <div class="footpara" role="doc-footnote"><p class="footpara">
Hypothetically, a vegan diet could be healthy as long as it is accompanied with sufficient supplements. In any case, a Mediterranean-like Diet is probably the healthiest for most humans, bearing some considerations relating to genetics. This is not medical, health, or dieting advice.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="date">Last Modified: 2025 February 16, 09:39</p><p class="author">Author: Zero Contradictions</p>
</div>
</body>
</html>
