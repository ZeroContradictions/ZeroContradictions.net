<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2024 April 01, 03:12 -->
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Morality And Selfishness FAQs</title>
<meta name="author" content="Zero Contradictions" />
<meta name="description" content="Morality, selfishness, and altruism are best understood via game theory and biological realism. These FAQs address the objections against moral relativism." />
<meta name="generator" content="Org Mode" />
<meta property="og:url" content="https://zerocontradictions.net/FAQs/morality-FAQs">
<meta property="og:type" content="article">
<meta property="og:image" content="https://zerocontradictions.net/images/bad-guys-vs-anti-bad-guys-meme.jpg">
<!-- Google tag (gtag.js) --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-S8XK8JC00G"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-S8XK8JC00G'); </script>
<link rel="stylesheet" type="text/css" href="/style.css">
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href="/"> UP </a>
 |
 <a accesskey="H" href="/"> HOME </a>
</div><div id="content" class="content">
<header>
<h1 class="title">Morality And Selfishness FAQs</h1>
<p class="subtitle" role="doc-subtitle">Understanding Morality with Game Theory and Biological Realism</p>
</header><nav id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#intro">1. Introduction (Start Here)</a></li>
<li><a href="#general-questions">2. General Questions</a>
<ul>
<li><a href="#origin-of-morality">2.1. Where does morality come from?</a>
<ul>
<li><a href="#memetic-traditions">2.1.1. How is morality related to memetic traditions?</a></li>
<li><a href="#why-value-equality">2.1.2. Why is equality a common moral value?</a></li>
</ul>
</li>
<li><a href="#evolution-effects-on-morality">2.2. How has evolution affected human morality?</a></li>
<li><a href="#humans-are-biological-species">2.3. Do you view humans to simply be a biological species, like any other?</a></li>
<li><a href="#problems-with-deontological-ethics">2.4. Why are consequentialist ethics better than deontological ethics?</a></li>
<li><a href="#morality-and-technology">2.5. Aren&rsquo;t technological advancements in the standard of living driven by improving morality?</a></li>
<li><a href="#morality-vs-ethics">2.6. What is the difference between morality and ethics?</a></li>
<li><a href="#what-is-humanism">2.7. What is Humanism?</a></li>
<li><a href="#rational-humanism">2.8. What is Rational Humanism?</a></li>
<li><a href="#abyss-for-value">2.9. How does the abyss for truth and value change how humans should act or view the world?</a></li>
<li><a href="#shoulds-and-shouldnts">2.10. In terms of should&rsquo;s and shouldn&rsquo;ts, what would be your ideal ethical system for a society?</a></li>
</ul>
</li>
<li><a href="#objectivity-questions">3. Subjectivity/Objectivity Questions</a>
<ul>
<li><a href="#why-not-objective">3.1. Why isn&rsquo;t morality objective?</a></li>
<li><a href="#reason-and-morality">3.2. Why can&rsquo;t the reason and rationality be the basis for objective morality?</a></li>
<li><a href="#dangerous-black-and-white-morals">3.3. Why is it dangerous to have a black-and-white sense of morality?</a></li>
<li><a href="#utilitarianism">3.4. Why is Utilitarianism <i>not</i> the best way to define morality?</a></li>
<li><a href="#common-laws">3.5. Most societies have laws that prohibit theft, murder, and rape, so doesn&rsquo;t this indicate that some things are objectively immoral?</a></li>
<li><a href="#cooperation-not-objectively-moral">3.6. Why are contract-ethics and cooperation not objectively moral?</a></li>
<li><a href="#moral-progress">3.7. Isn&rsquo;t historical moral progress evidence that morality is objective?</a></li>
<li><a href="#not-everybody-wants-tech-society">3.8. Surely everybody wants to live in a prosperous, technologically-advanced society, right?</a></li>
<li><a href="#not-an-appeal-to-people">3.9. Isn&rsquo;t it an appeal to the people fallacy to argue for societies based on consensus?</a></li>
<li><a href="#not-a-subjectivist-fallacy">3.10. Isn&rsquo;t it a subjectivist fallacy to insist that morality is perspective-dependent?</a></li>
<li><a href="#Qs-for-moralists">3.11. Questions For Moralists About Universal Rights</a></li>
</ul>
</li>
<li><a href="#selfishnes-vs-altruism-questions">4. Selfishness Versus Altruism Questions</a>
<ul>
<li><a href="#definition-of-selfishness">4.1. Wouldn&rsquo;t a more coherent definition of the word &ldquo;selfishness&rdquo; be &ldquo;pursuing your own interests at the expense of others&rdquo;?</a></li>
<li><a href="#altruism-and-evolution">4.2. Isn&rsquo;t Altruism part of human evolution?</a>
<ul>
<li><a href="#reciprocal-altruism">4.2.1. What about Reciprocal Altruism?</a></li>
<li><a href="#kin-selection-theory-bogus">4.2.2. What about Kin Selection Theory providing a basis for Altruism?</a></li>
<li><a href="#bees-and-ants-arent-altruistic">4.2.3. Aren&rsquo;t worker ants and worker bees examples of altruism existing in Nature, since they can&rsquo;t reproduce and thus only work for the good of their species?</a></li>
</ul>
</li>
<li><a href="#helping-others">4.3. Doesn&rsquo;t helping out your friends and family count as altruism?</a></li>
<li><a href="#helping-everybody">4.4. Why shouldn&rsquo;t we help everybody?</a></li>
<li><a href="#effective-altruism">4.5. What&rsquo;s wrong with Effective Altruism?</a></li>
<li><a href="#cynicalism-is-not-selfishness">4.6. Isn&rsquo;t it misguided to have such a cynical view of human nature?</a></li>
<li><a href="#why-we-should-be-selfish">4.7. Why should we be selfish?</a></li>
<li><a href="#altruism-and-civilization">4.8. Isn&rsquo;t Altruism integral to human civilization?</a>
<ul>
<li><a href="#cooperation-vs-collectivism">4.8.1. The difference between cooperation versus collectivism</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#libertarian-questions">5. Libertarian Questions</a>
<ul>
<li><a href="#the-NAP">5.1. Isn&rsquo;t the Libertarian Non-Aggression Principle (NAP) the objective origin of morality?</a></li>
<li><a href="#necessary-evil">5.2. But there&rsquo;s no such thing as a necessary evil.</a></li>
<li><a href="#universally-preferable">5.3. Why isn&rsquo;t morality the same thing as &ldquo;universally preferable behavior&rdquo;?</a></li>
</ul>
</li>
<li><a href="#misc-questions">6. Miscellaneous Questions</a>
<ul>
<li><a href="#meaningless-of-standpoint-theory">6.1. The Meaninglessness of the Standpoint Theory of Truth</a></li>
<li><a href="#thoughts-on-less-wrong">6.2. What do you think about rationalist forums like lesswrong.com?</a></li>
</ul>
</li>
<li><a href="#technology-and-moral-progress">7. How Does Technology Create The Illusion Of Moral Progress?</a>
<ul>
<li><a href="#illusions-in-moralist-communities">7.1. Technological Changes That Various Moralists Would Claim To Be &ldquo;Moral Progress&rdquo;</a></li>
<li><a href="#ideologies-future-progress">7.2. Future Moral Progress According To Various Ideologues</a></li>
<li><a href="#moral-progress-without-tech">7.3. &ldquo;Moral Progress&rdquo; That Wasn&rsquo;t Caused By Advancing Technology</a></li>
</ul>
</li>
<li><a href="#when-life-becomes-zero-sum">8. When Life Becomes Zero-Sum</a></li>
<li><a href="#glossary">9. Glossary</a></li>
</ul>
</div>
</nav>

<div id="outline-container-intro" class="outline-2">
<h2 id="intro"><span class="section-number-2">1.</span> Introduction (Start Here)</h2>
<div class="outline-text-2" id="text-intro">
<p>
Many of the questions on this page address the same objections and misunderstandings, so it will feel repetitive and redundant to read <i>all</i> the questions and answers on this page.
If you would like to read an actual essay explaining what morality is, then we recommend reading: <a href="https://thewaywardaxolotl.blogspot.com/2020/07/what-is-morality.html">What is morality?</a>
We also recommend reading <a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-value.html">What is value?</a> for understanding axiology and normative claims, which is important for being able to better understand the answers presented in these FAQs.
</p>

<p>
Summary of this Ethical Philosophy:
</p>
<ul class="org-ul">
<li>Morality depends on value, and value is perspective-dependent. <a href="../epistemology/axiology">There is no objective foundation for value</a>. Likewise for morality.</li>
<li>Morality is heavily shaped by <a href="https://thewaywardaxolotl.blogspot.com/2017/09/evolution-and-morality.html">evolution</a> and <a href="https://thewaywardaxolotl.blogspot.com/2015/12/god-is-telomeme.html">memetic traditions and fashions</a>. Most people&rsquo;s moral values <a href="#origin-of-morality">were formed in a 6-step process</a>.</li>
<li><a href="#kin-selection-theory-bogus">Every purported example of altruism occurring in nature is actually selfishness</a>.</li>
<li>It&rsquo;s unreasonable to oppose natural phenomena that are beyond mankind&rsquo;s control. For example, it&rsquo;s unreasonable to oppose hierarchy because social hierarchies are natural and <a href="https://en.wikipedia.org/wiki/The_Son_Also_Rises_(book)">they&rsquo;re often strongly influenced by people&rsquo;s genetics</a>, which we cannot change. For similar reasons, it&rsquo;s also pointless to oppose <a href="https://thewaywardaxolotl.blogspot.com/2015/09/life-is-violent.html">violence in nature</a>, to <a href="../misc/case-against-efilism#self-defeating">oppose the existence of life (efilism)</a>, or to <a href="https://www.reddit.com/r/AntiVegan/wiki/index/health">be vegan if it&rsquo;s necessary for humans to eat animals in order to be healthy</a>.</li>
<li><a href="../civilization/political-philosophy#intro">Evolutionary Biology is the best initial field to study for forming social frameworks</a>.</li>
<li>&ldquo;Moral Progress&rdquo; is an <a href="#technology-and-moral-progress">illusion that is primarily created by the advancement of technology</a>.</li>
<li>Without cooperation, <a href="#when-life-becomes-zero-sum">life becomes zero-sum when the population reaches the carrying capacity</a> of its environment.</li>
</ul>
<p>
Note: Given that there are so many diverse ideas, viewpoints, and moral philosophies that a random person could have about morality, it&rsquo;s likely that only a fraction of these FAQs will answer any random people&rsquo;s questions or beliefs about morality.
But many of these questions are discussed often, and it&rsquo;s convenient for other pages on this website to link to these questions and explanations when relevant, hence why this page exists.
</p>
</div>
</div>

<div id="outline-container-general-questions" class="outline-2">
<h2 id="general-questions"><span class="section-number-2">2.</span> General Questions</h2>
<div class="outline-text-2" id="text-general-questions">
</div>
<div id="outline-container-origin-of-morality" class="outline-3">
<h3 id="origin-of-morality"><span class="section-number-3">2.1.</span> Where does morality come from?</h3>
<div class="outline-text-3" id="text-origin-of-morality">
<p>
In this context, we are defining morality as &ldquo;what a person thinks people should and shouldn&rsquo;t do, i.e. what a person <i>wants</i> other people to do, <a href="../epistemology/axiology">according to their values</a>&rdquo;.
Note that &ldquo;morality&rdquo; has <a href="https://en.wiktionary.org/wiki/morality#English">many different definitions</a>, so it is highly vulnerable to the <a href="../language/sapir-whorf-theory">Sapir-Whorf Effect</a>.
</p>


<p>
Morality originates from one&rsquo;s personal values, in a 6-step process that typically consists of:
</p>
<ul class="org-ul">
<li>Collective values.</li>
<li>The individual internalization of collective values.</li>
<li>The assumption that collective values are objective, and thus &ldquo;moral&rdquo;.</li>
<li>A folk theory of morality.</li>
<li>Individual and collective moral myths.</li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2023/10/israel-palestine-and-moral-confusion.html?m=1">Pattern-matching situations</a> with evaluated moral judgements and assumptions to situations that are unevaluated or need to be re-evaluated.</li>
</ul>

<p>
Read More: <a href="https://thewaywardaxolotl.blogspot.com/2020/07/what-is-morality.html">What is Morality?</a>
</p>
</div>

<div id="outline-container-memetic-traditions" class="outline-4">
<h4 id="memetic-traditions"><span class="section-number-4">2.1.1.</span> How is morality related to memetic traditions?</h4>
<div class="outline-text-4" id="text-memetic-traditions">
<p>
To a large extent, culture is arbitrary.
Other aspects are less arbitrary in the sense that there are strong tendencies for different cultures to arrive at the same customs.
Many of these less arbitrary customs and taboos originated because they increased the reproductive success of the people who practiced them to the point of becoming dominant habits within the culture.
These are also known as <a href="https://thewaywardaxolotl.blogspot.com/2015/12/god-is-telomeme.html">traditions</a>.
Over time, these traditions and taboos come to be collective values of the practicing cultures.
In turn, they form a substantial basis for what is deemed &ldquo;moral&rdquo; and &ldquo;immoral&rdquo;.
The traditions then propagate onto the next generations via the individual internalization of collective values for every individual.
</p>

<p>
More Information: <a href="https://thewaywardaxolotl.blogspot.com/2020/07/what-is-morality.html">What is Morality? - Blithering Genius</a>
</p>
</div>
</div>

<div id="outline-container-why-value-equality" class="outline-4">
<h4 id="why-value-equality"><span class="section-number-4">2.1.2.</span> Why is equality a common moral value?</h4>
<div class="outline-text-4" id="text-why-value-equality">
<p>
There are various reasons why it makes sense to value equality from a societal perspective:
</p>

<ul class="org-ul">
<li>Social Stability: Societies that strive for equality may be more stable than less equal societies, depending on the balance of power between all of society&rsquo;s members. Equality is more likely to be achieved when <i>power</i> has a relatively equal distribution among a population. For instance, it&rsquo;s not easy for a dictator to rise to amass great power and rule with an iron fist when <a href="../FAQs/pro-gun-arguments-guide.pdf">every other citizen is armed with a gun</a>.</li>
<li>Uniformity: The more uniform everything is in an industrial civilization, the more interchangeable and thus cheaper everything becomes.</li>
<li>Meritocracy: Equality is necessary for meritocracy. If people are born with less equal opportunities than others, then human capital is more likely to be misallocated.</li>
<li>Economic Prosperity: Reducing economic inequality may increase economic prosperity and growth. When wealth is distributed more evenly, a larger portion of the population has the means to participate in economic activities.</li>
</ul>
<p>
However, there are no reasons why people necessarily have to value equality from an individual perspective(s).
Equality is a means to an end.
From a biological perspective, the best society is the one that does everything to serve you, while you give nothing in return.
<a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Humans are intrinsically selfish</a>.
</p>

<p>
Thomas Jefferson&rsquo;s &ldquo;all men are created equal&rdquo; was about rejecting the divine right of kings.
However, some ideologues ignore this context and teach that the Founding Fathers of the United States believed in their ideological definition of equality, as opposed to stability or freedom.
This is a misinterpretation, and thus not true.
</p>
</div>
</div>
</div>

<div id="outline-container-evolution-effects-on-morality" class="outline-3">
<h3 id="evolution-effects-on-morality"><span class="section-number-3">2.2.</span> How has evolution affected human morality?</h3>
<div class="outline-text-3" id="text-evolution-effects-on-morality">
<ul class="org-ul">
<li>Evolution selected for egoism and selfishness over altruism. Hence, altruism is a losing reproductive strategy whenever there is a competing pro-selfishness strategy.</li>
<li>Since mutual cooperation among selfishness individuals enables each individual to gain more than if they each worked alone, humans evolved a moral accounting system to keep track of what they owe and what they are owed from their respective communities.</li>
<li>Humans have a natural intuition that life is good and life should be preserved in many cases, even when it&rsquo;s not very practical (e.g. pro-lifers being against abortion, people against death penalties, people against suicide, assisted suicide, or even suicide with dignity, etc).</li>
<li>Humans are more likely to favor their children, spouses, family, friends, and other people in their social networks and communities over outsiders, in terms of perks, special advice/tips/tricks, and goods (cronyism/tribalism/favoritism).</li>
<li>Humans are tribalistic, and develop their own internal labels for who to designate within their in-groups and out-groups.</li>
<li>Humanists view love as sacred, even though it doesn&rsquo;t exist merely to make humans feel good. Likewise, people may feel spiteful and vengeful when their partners cheat or break up with them. Regarding cheating, this implicitly causes humans to value consent.</li>
<li>Humans dislike loneliness and favor being in communities and groups.</li>
<li>Humans will tend to justify themselves, even if doing so is hypocritical or wrong from the collective moral perspective.</li>
</ul>
<p>
Read More: <a href="https://thewaywardaxolotl.blogspot.com/2017/09/evolution-and-morality.html">Evolution and Morality - Blithering Genius</a>
</p>
</div>
</div>

<div id="outline-container-humans-are-biological-species" class="outline-3">
<h3 id="humans-are-biological-species"><span class="section-number-3">2.3.</span> Do you view humans to simply be a biological species, like any other?</h3>
<div class="outline-text-3" id="text-humans-are-biological-species">
<p>
Yes. <a href="https://thewaywardaxolotl.blogspot.com/2014/02/we-cannot-transcend-evolution.html">Humans cannot transcend evolution</a>.
<a href="../misc/industrial-society-and-its-future-manifesto">Technology does not make humans invincible</a>.
And just because humans are the most intelligent form of life ever known to have existed, that doesn&rsquo;t mean that humans aren&rsquo;t susceptible to the same population dynamics and other biological realities that all other animals must face.
It is still the case that <a href="../FAQs/eugenics-FAQs#gattaca-caste-based-society">genes are largely responsible for predetermining every person&rsquo;s destiny</a>, that whoever has the most children is destined to have their genes become more common in the future, and that <a href="https://thewaywardaxolotl.blogspot.com/2015/09/life-is-violent.html">human populations have the potential to exceed their carrying capacities</a> to the point of causing war, disease, and famine in order to decrease their populations.
</p>
</div>
</div>

<div id="outline-container-problems-with-deontological-ethics" class="outline-3">
<h3 id="problems-with-deontological-ethics"><span class="section-number-3">2.4.</span> Why are consequentialist ethics better than deontological ethics?</h3>
<div class="outline-text-3" id="text-problems-with-deontological-ethics">
<p>
Some people view morality as a list of rules that shall never be violated.
The justification at a macro-level is that these rules have consequences that cannot be considered at a micro-level.
To put this in perspective, let&rsquo;s take the example of lying.
If a drug addict lies to a police officer about the presence of cocaine in his house, he can avoid getting arrested.
But if too many people lie, then people won&rsquo;t trust each other.
Here the micro level concern is getting arrested, and the macro level concern is social trust.
</p>

<p>
Deontology needlessly elevates the value of rules over the consequences of them.
Rules cannot be reasonably formed without some sort of appeal to consequence, because <a href="../epistemology/axiology#intro">it&rsquo;s not possible to judge a value without another value to judge it by</a>.
When rules and values are made without appreciating the consequences of them, they become arbitrary and shitty.
For example, you can&rsquo;t explain why a rule saying that a man can have sex with whichever women he wants is a bad rule without an appeal to the consequences of that rule.
You could argue that the first rule violates the autonomy of the women.
However, you would need to justify why women are entitled to a certain amount of autonomy, which requires appealing to the consequences of implementing that autonomy.
In these scenarios, the appeal of the Non-Aggression comes from reducing the amount of coercion that occurs.
<span class="underline"><i>If the justification for the NAP ultimately appeals to consequences, then why not evaluate the actions and specific rules you make based on the consequences themselves rather than some general rule that doesn&rsquo;t always work out?</i></span>
</p>

<p>
It is true that rules are important for setting precedents.
If people stole and pirated whenever they want in a society, people would be less incentivized to create wealth, which is a net negative.
On the other hand, respecting private property creates a macro-level effect of encouraging wealth because people will think it won&rsquo;t be stolen.
However, would 10 acts of fraud intended to fund research into embryo selection be ethical? I would say yes – you increase the amount of utility in the society without severely damaging the precedent of private property.
10 acts of fraud are the kind of crime that makes the papers for a few days until people forget about it, rather than something that seriously undermines people&rsquo;s trust.
</p>

<p>
Sure, people frequently engaging in actions that break rules would undermine the precedents that these rules uphold.
However, there are clearly violations of rules that don&rsquo;t break the precedent they set.
Let&rsquo;s take private property as an example.
When people having a right to property, that incentivizes them to protect it and create more value.
Taxing people at the threat of incarceration would be a violation of private property.
However, if these taxes are used for institutions that help uphold private property, then there is no moral objection to it as they are massively preventing the very thing they are violating.
</p>


<p>
Read More: <a href="../epistemology/reasoning-skills#appeal-to-consequences">When Appeal to Consequences <i>is</i> a Valid Fallacy</a>.
</p>
</div>
</div>

<div id="outline-container-morality-and-technology" class="outline-3">
<h3 id="morality-and-technology"><span class="section-number-3">2.5.</span> Aren&rsquo;t technological advancements in the standard of living driven by improving morality?</h3>
<div class="outline-text-3" id="text-morality-and-technology">
<p>
No, this is backwards. &ldquo;Moral progress&rdquo; is an illusion, and <a href="#technology-and-moral-progress">the illusion is created by technological advancements</a>.
</p>
</div>
</div>

<div id="outline-container-morality-vs-ethics" class="outline-3">
<h3 id="morality-vs-ethics"><span class="section-number-3">2.6.</span> What is the difference between morality and ethics?</h3>
<div class="outline-text-3" id="text-morality-vs-ethics">
<p>
&ldquo;Ethics&rdquo; and &ldquo;Morality&rdquo; are often used interchangeably in common discourse.
But when they are used for more specific connotations, they are as follows:
</p>
<ul class="org-ul">
<li>Ethics is generally considered the standards of &ldquo;good&rdquo; and &ldquo;bad&rdquo;, &ldquo;right&rdquo; or &ldquo;wrong&rdquo; that are imposed by some outside group, (e.g. a society or profession).</li>
<li>Morality is one&rsquo;s own personal sense of right and wrong.
It&rsquo;s not imposed by anyone.
It&rsquo;s just what you <i>personally</i> think is &ldquo;good&rdquo; and &ldquo;bad&rdquo;.</li>
</ul>

<p>
Morality and Ethics can both conflict.
For example, one might live in a society that agrees on a certain code of conduct that you personally disagree with.
For example, you might think that free speech is always going to be right, but live somewhere that if people think defaming religious icons for example is wrong.
The ethics say that you should do what the society imposes on you, whereas your morals (your own personal beliefs about what&rsquo;s right and wrong) say you should do something else.
Your ethics and your morality disagree.
</p>

<p>
It is important to note that philosophers are generally talking about what is <i>universally</i> right or wrong, when they&rsquo;re using these terms.
They&rsquo;re not talking about what a specific society says, or what a person thinks.
They&rsquo;re talking about what is right or wrong <i>universally</i>.
</p>

<p>
Some philosophers believe that all we can say about &ldquo;good&rdquo; and &ldquo;bad&rdquo; is just what societies or groups say (ethics).
This is called <a href="https://en.wikipedia.org/wiki/Relativism">Relativism</a>.
</p>

<p>
Others think that all we can say about right and wrong is what we personally feel (morals, using this distinction).
This is called <a href="https://en.wikipedia.org/wiki/Emotivism">Emotivism</a>.
</p>

<p>
However, philosophers rarely use these two terms, &ldquo;ethics&rdquo; and &ldquo;morals&rdquo; to mean two different concepts in philosophy.
Generally they&rsquo;re going to be interchangeable.
</p>
</div>
</div>

<div id="outline-container-what-is-humanism" class="outline-3">
<h3 id="what-is-humanism"><span class="section-number-3">2.7.</span> What is Humanism?</h3>
<div class="outline-text-3" id="text-what-is-humanism">
<p>
Humanism is a secular, liberal, hedonistic, pro-altruism <a href="https://thewaywardaxolotl.blogspot.com/2014/07/the-communists-who-took-power-in.html">utopian ideology</a> and religion that has supplanted Christianity as the main moral value system of the Western World.
Humanists take for granted that personal happiness is the purpose of life, technology is always good, humans are naturally morally good, sympathy is always &ldquo;better&rdquo; than hate, and that tolerance of other cultures and beliefs is good, as long as they agree with humanism.
Humanism is popular because it appeals to moral intuitions in the absence of traditional supernatural religious beliefs.
</p>

<p>
Humanism is not a legitimate philosophy because it doesn&rsquo;t have a theory of truth, nor a theory of value, nor a theory of society.
<a href="https://americanhumanist.org/what-is-humanism/manifesto3/">When we investigate and critique the Humanist Manifesto</a>, we find that it&rsquo;s all just rhetoric designed to affirm prior intuitions, rather than question them.
</p>

<p>
<a href="https://en.wiktionary.org/wiki/humanism">The third sense of &ldquo;humanism&rdquo; defined on Wiktionary</a> is the most similar to this section&rsquo;s definition:
</p>
<blockquote>
<p>
An ethical system that centers on humans and their values, needs, interests, abilities, dignity and freedom; especially used for a secular one which rejects theistic religion and superstition.
</p>
</blockquote>

<p>
Watch: <a href="https://www.youtube.com/watch?v=GRRmqpsbVkY">Dissecting Humanism</a>.
</p>
</div>
</div>

<div id="outline-container-rational-humanism" class="outline-3">
<h3 id="rational-humanism"><span class="section-number-3">2.8.</span> What is Rational Humanism?</h3>
<div class="outline-text-3" id="text-rational-humanism">
<p>
Rational Humanism is a proposed ideology for replacing (Naive) Humanism as the primary ideology of the Western World.
The individual core value of Rational Humanism is Reproduction, while the collective core value is Civilization.
In comparison to Naive Humanism, Rational Humanism embraces selfishness, it defines more sustainable values, and it isn&rsquo;t fundamentally deceptive.
</p>

<p>
Read More: <a href="https://thewaywardaxolotl.blogspot.com/2020/04/toward-rational-humanism.html">Toward Rational Humanism</a>
</p>
</div>
</div>

<div id="outline-container-abyss-for-value" class="outline-3">
<h3 id="abyss-for-value"><span class="section-number-3">2.9.</span> How does the abyss for truth and value change how humans should act or view the world?</h3>
<div class="outline-text-3" id="text-abyss-for-value">
<p>
Accepting the abyss {<a href="https://thewaywardaxolotl.blogspot.com/2016/07/what-is-abyss.html">(1)</a>, <a href="https://thewaywardaxolotl.blogspot.com/2023/06/lucifers-question.html">(2)</a>, <a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-value.html">(3)</a>} enables us to reject assumptions about how we should live our lives.
</p>

<p>
In my own experience, <a href="../misc/philosophical-journey#efilism-phase">when I was Efilist-leaning</a>, it was a problem for me because my desires contradicted what seemed to have been the &ldquo;right thing to do&rdquo;.
Once I recognized that there&rsquo;s no objective basis for morality, this enabled me to reject the values and beliefs that conflicted with my desires.
So, recognizing that there&rsquo;s an abyss for value and morality has helped me.
</p>

<p>
Recognizing that biological value arises from causality by the loop of reproduction also gives me a way to &ldquo;immanentize the abyss&rdquo; by <a href="../epistemology/axiology#reproduction-objective-purpose">fulfilling my objective purpose and what I evolved to do (reproduction)</a>.
</p>
</div>
</div>

<div id="outline-container-shoulds-and-shouldnts" class="outline-3">
<h3 id="shoulds-and-shouldnts"><span class="section-number-3">2.10.</span> In terms of should&rsquo;s and shouldn&rsquo;ts, what would be your ideal ethical system for a society?</h3>
<div class="outline-text-3" id="text-shoulds-and-shouldnts">
<p>
We favor a society based on <a href="https://thewaywardaxolotl.blogspot.com/2020/04/toward-rational-humanism.html">rational humanism</a>
and a <a href="https://brittonicmemetics.wordpress.com/2020/06/26/designed-culture/">rationally designed culture</a>.
The society would value cooperation and shun defecting.
Legally speaking, this ideal society would have a lot of individual freedom, but <a href="#memetic-traditions">memetic traditions that promote higher fertility</a> would naturally be the most prevalent in the society.
Over time, those traditions would likely be deemed &ldquo;moral&rdquo; and actions that don&rsquo;t conform with those traditions would be deemed &ldquo;immoral&rdquo;.
However, the society would theoretically become very intelligent and culturally aware after a few hundred years since it would practical <a href="../FAQs/eugenics-FAQs">eugenic population control</a>, so it&rsquo;s reasonably possible that the society would eventually adopt a rational, laissez-faire approach to morality as well.
</p>
</div>
</div>
</div>

<div id="outline-container-objectivity-questions" class="outline-2">
<h2 id="objectivity-questions"><span class="section-number-2">3.</span> Subjectivity/Objectivity Questions</h2>
<div class="outline-text-2" id="text-objectivity-questions">
</div>
<div id="outline-container-why-not-objective" class="outline-3">
<h3 id="why-not-objective"><span class="section-number-3">3.1.</span> Why isn&rsquo;t morality objective?</h3>
<div class="outline-text-3" id="text-why-not-objective">
<p>
Moral Objectivism is the ethical view that all or some actions have intrinsic positive value (&ldquo;are good&rdquo;) and intrinsic negative value (&ldquo;are bad/evil&rdquo;), regardless of context, consequence, or perspective.
</p>

<p>
It&rsquo;s important to note that morality is not a set of &ldquo;rules&rdquo;, but rather a set of &ldquo;values&rdquo;.
The values may appear and be described as &ldquo;rules&rdquo; by people who believe in objective morality, but we shall show why it&rsquo;s more appropriate to describe them as &ldquo;values&rdquo;.
</p>



<p>
This FAQs page disproves many arguments in favor of objective morality, but for an essay-style format, we recommend reading: <a href="https://thewaywardaxolotl.blogspot.com/2020/07/what-is-morality.html">What is morality?</a>
</p>



<figure id="org50c5652">
<img src="../images/is-ought-explanation-of-morality.jpg" alt="The is-ought gap explanation of morality.">

</figure>

<p>
The act of crossing the is-ought gap may even be called the &ldquo;Is-Ought Fallacy&rdquo; in appropriate cases.
</p>
</div>
</div>

<div id="outline-container-reason-and-morality" class="outline-3">
<h3 id="reason-and-morality"><span class="section-number-3">3.2.</span> Why can&rsquo;t the reason and rationality be the basis for objective morality?</h3>
<div class="outline-text-3" id="text-reason-and-morality">
<p>
The following paragraphs were paraphrased and written more concisely from StateOfTheNihil&rsquo;s essay, &ldquo;<a href="https://stateofthenihil.wordpress.com/2019/09/22/reason-is-not-the-basis-for-morality/">Reason is Not the Basis for Morality</a>&rdquo;.
</p>

<p>
This assumption relies on a misunderstanding of how reason and knowledge work.
Reason is a psychological mechanism where thought conforms to rules for thinking (a logic).
The nature of logical reasoning prevents it from being a suitable foundation for anything, let alone morality.
</p>

<p>
It can be tempting to conclude that morality is based on rationality since <a href="../epistemology/axiology#intro">it&rsquo;s possible for values to contradict each other, to be based on false or unquestioned assumptions, and/or to be justified by fallacious reasoning</a>.
If some value systems are contradictory and others are not, that should imply that some moral systems are better than others, right?
It does, but reason alone is still not sufficient for building an incontrovertible moral foundation.
There is no uniquely rational way to define value philosophically since values depend on other values.
Reason makes your thinking consistent, but reason does not provide a foundation.
</p>

<p>
When you make a valid deduction, you are reasoning from established propositions.
The established propositions are assumptions made for that particular step of reasoning.
The act of making a valid inference does not depend on the actual truth-value of any given assumption.
They are merely assumed to be true in the abstract.
The point here is that the starting point, particularly the truth-value of the starting point, is not relevant to validity.
Logic is only concerned with the transmission of assumed truth down into a conclusion.
Logic has to do with the flow of thought, not the starting point of thought.
</p>

<p>
Any attempt to provide a rational foundation for morality will invariably require contradicting itself.
To start, there needs to be a framework where specific ethical actions can be deduced from more general first principles.
But these first principles will never have a justification, themselves.
Reason makes it possible to construct a valid flow of thought from first principles, but it does not have the artillery to provide justification for those first principles.
If you appeal to some principle from which you can deduce that first principle, then the first principle loses its status and the principle you&rsquo;ve deduced it from is now the new first principle.
We&rsquo;re now back where we started, needing justification for our starting point.
</p>

<blockquote>
<p>
But first principles are self-evidently true. They do not depend on other principles for justification, as they justify their own truth-value.
</p>
</blockquote>
<p>
&ldquo;Self-evidence&rdquo; is a gloriously vague assertion, ripe for equivocation.
It&rsquo;s also not a valid epistemological concept since anything can be questioned and rejected.
</p>

<blockquote>
<p>
Intuition can form a basis for morality.
</p>
</blockquote>
<p>
First, intuition is not universal, just as self-evidence is not universal.
What strikes you as intuitive will depend, in part, on culture.
Most people accepted slavery as a norm in society for thousands of years, until within the last couple centuries.
Whatever intuition you go with is arbitrary.
</p>

<p>
Second, intuition is not necessarily coherent, as is assumed by these lapsed rationalists.
The idea is that we are able to come up with a complete and coherent framework that will jive with all of our intuitions.
But there is no reason to assume this.
Intuition is influenced by indoctrination, education, and social factors, which destabilizes the first principle as well.
Appeals to self-evidence or to intuition are arbitrary and there is no way to settle disputes between different parties.
</p>

<p>
It&rsquo;s also a mistake to assume that values can be based on sensory knowledge instead of emotional knowledge.
<a href="../epistemology/axiology#intro">Values can be coordinated with reason</a>, but reason and sensory knowledge alone cannot form an objective basis for morality.
</p>
</div>
</div>

<div id="outline-container-dangerous-black-and-white-morals" class="outline-3">
<h3 id="dangerous-black-and-white-morals"><span class="section-number-3">3.3.</span> Why is it dangerous to have a black-and-white sense of morality?</h3>
<div class="outline-text-3" id="text-dangerous-black-and-white-morals">
<p>
Even if morality were objective, there&rsquo;s always more ways to be wrong than there are ways to be right, so anybody who <i>thinks</i> that they are abiding by supposedly objective moral standards is probably wrong.
Many people would also use their belief that they are imposing the one and only true &ldquo;objective&rdquo; morality as a justification to rule with an iron fist.
</p>
</div>
</div>

<div id="outline-container-utilitarianism" class="outline-3">
<h3 id="utilitarianism"><span class="section-number-3">3.4.</span> Why is Utilitarianism <i>not</i> the best way to define morality?</h3>
<div class="outline-text-3" id="text-utilitarianism">
<p>
There are multiple reasons:
</p>
<ol class="org-ol">
<li>Utilitarianism is defined as maximizing &ldquo;well-being&rdquo;, and &ldquo;well-being&rdquo; is subjective.
That&rsquo;s why there&rsquo;s <a href="https://en.wikipedia.org/wiki/Utilitarianism">many different types of Utiliarianism</a>.</li>
<li>Utilitarianism doesn&rsquo;t have any practical solutions to the moral calculation problem.
Every single person and faction of society has different utilitarian calculations that would be &ldquo;best&rdquo; for their own lives.
A lot of Utilitarians get caught up in failing to recognize that corruption within a society is &ldquo;morally good&rdquo; from the perspective of the corrupt people.
Corruption is cooperation in such contexts.</li>
<li>Utilitarianism implies that I should sacrifice my own well-being if there are situations where it would benefit everybody else.
It depends on the situation of course, but I wouldn&rsquo;t do that in most cases.
Fortunately, I rarely face dilemmas where I have sacrifice my own self-interests.
I do cooperate with others, but those relationships are reciprocal chains of giving and taking.</li>
<li>It simply isn&rsquo;t feasible for each individual to act according to utilitarianism. In practice, an individual has the knowledge to act selfishly in his own interests, but not the knowledge to act altruistically for maximizing <i>everybody&rsquo;s</i> collective average self interests.</li>
</ol>


<figure id="org68ecdb1">
<img src="../images/yet-another-universal-moral-system.jpg" alt="Yet another purportedly universal moral system.">

</figure>


<p>
The Connection Between The Various Types Of Utiliarianism With The Various Types Of Hedonism
</p>

<table>


<colgroup>
<col  class="org-left">

<col  class="org-center">

<col  class="org-center">

<col  class="org-center">
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Question</th>
<th scope="col" class="org-center">Mainstream</th>
<th scope="col" class="org-center">Efilism</th>
<th scope="col" class="org-center">Zero Contradictions</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">If Life Violent?</td>
<td class="org-center">It shouldn&rsquo;t be</td>
<td class="org-center">Yes, and life is worse thing ever.</td>
<td class="org-center">Yes, but this isn&rsquo;t necessarily a &ldquo;bad&rdquo; thing.</td>
</tr>

<tr>
<td class="org-left">Hedonism/Utilitarianism?</td>
<td class="org-center">Positive &amp; Negative Utilitarianism</td>
<td class="org-center">Supremacy of Negative Utilitarianism</td>
<td class="org-center">N/A, they balance out, and it&rsquo;s subjective.</td>
</tr>

<tr>
<td class="org-left">Altruism?</td>
<td class="org-center">Yes.</td>
<td class="org-center">Yes, absolutely.</td>
<td class="org-center">No, because nature is intrinsically selfish.</td>
</tr>
</tbody>
</table>

<p>
Most people and all Efilists are Utilitarians. The difference is that most people will assign some value to positive hedonism, whereas Efilists will assign either no value to positive hedonism or value it as completely subordinate to Utilitarianism (Positive Hedonism is only valuable if Negative Hedonism is satisfied). In addition, Efilists recognize that life is inherently violent.
</p>

<p>
Positive and Negative Utilitarianism only differ by the type of hedonism that they favor. <a href="../misc/case-against-efilism#hedonism-is-not-self-evident">Hedonism is not self-evident</a>.
</p>
</div>
</div>

<div id="outline-container-common-laws" class="outline-3">
<h3 id="common-laws"><span class="section-number-3">3.5.</span> Most societies have laws that prohibit theft, murder, and rape, so doesn&rsquo;t this indicate that some things are objectively immoral?</h3>
<div class="outline-text-3" id="text-common-laws">
<p>
Legal systems are intersubjective, but that&rsquo;s not the same thing as objective.
</p>
<blockquote>
<p>
Every civilization has to solve the same problems of cooperation.
And every civilization solved those problems with the state.
Every civilization has laws that solve problems of cooperation.
E.g. the law against murder solves the prisoner’s dilemma that exists between strangers: that each might kill the other.
The law allows strangers to live and work together, so it enables large-scale societies.
Likewise for the other core laws, such as laws establishing property rights and marriage, etc.
These solve problems of cooperation.
Those laws are part of the overall package of civilization, which includes the state, written language, and math.
</p>

<p>
Humans have roughly the same emotional structure, although individuals vary.
That common human nature is not “good” by your moral standards.
We have the capacity for positive and negative empathy, cooperation and competition.
</p>

<p>
Human nature is selfish, and humans can often benefit by killing other humans, raping other humans, taking their stuff, etc.
So, we evolved the capacity for both friendship and hatred, cooperation and violent competition.
Societies have to prevent internal violence, but they project violence outward, and societies use violence to impose internal non-violence.
We often cooperate to compete.
War is a cooperative endeavor.
</p>

<p>
All civilizations fought wars in which they killed, raped, seized property, etc.
Civilization is based on conquering land and establishing a monopoly on violence by the use of violence.
War is a human universal.
Society is cooperative, but we often cooperate to compete.
Society doesn’t eliminate competition.
It transfers it to a higher level, so we are competing as a unit with other societies or with nature.
At the margins, life is zero-sum.
Once an ecosystem is fully populated, one way of life can only increase at the expense of another.
That applies to species, societies and civilizations.
&#x2013; Blithering Genius, <a href="https://thewaywardaxolotl.blogspot.com/2022/07/answering-ancap-questions.html"> Answering Ancap Questions</a>
</p>
</blockquote>
<p>
It&rsquo;s also incorrect to assert that theft, murder, rape, etc are objectively wrong.
If it&rsquo;s possible for someone to benefit themself by killing, raping, and stealing, then that implies that those actions can be subjectively good from a person&rsquo;s point of view.
</p>
</div>
</div>

<div id="outline-container-cooperation-not-objectively-moral" class="outline-3">
<h3 id="cooperation-not-objectively-moral"><span class="section-number-3">3.6.</span> Why are contract-ethics and cooperation not objectively moral?</h3>
<div class="outline-text-3" id="text-cooperation-not-objectively-moral">
<p>
If cooperating together was the objectively best choice (i.e. it offers the greatest individual reward for each player and defection is guaranteed to not happen), then prisoner&rsquo;s dilemmas wouldn&rsquo;t exist at all in the first place.
Conversely, if prisoner&rsquo;s dilemmas didn&rsquo;t exist, then there would be no inquiry as to why someone would choose anything less than the option with the greatest potential reward and what can be done to achieve that.
The fact that game theoretical problems exist is evidence enough that contract ethics are subjective, rather than objective.
</p>
</div>
</div>

<div id="outline-container-moral-progress" class="outline-3">
<h3 id="moral-progress"><span class="section-number-3">3.7.</span> Isn&rsquo;t historical moral progress evidence that morality is objective?</h3>
<div class="outline-text-3" id="text-moral-progress">
<p>
No. <a href="#technology-and-moral-progress">The creation of &ldquo;Moral progress&rdquo; is an illusion</a>.
Most &ldquo;improvements&rdquo; in &ldquo;moral progress&rdquo; are really just advancements in technology, not so much improvements in people deciding to behave &ldquo;better&rdquo;.
</p>

<p>
Moreover, most people who make this argument are defining &ldquo;moral progress&rdquo; according to modern Western standards of morality, but those are far from being a universal conception of morality.
For example, traditionalists and Fundamentalist Muslims both have very different idea of moral progress, and would disagree with the Western conception.
</p>
</div>
</div>

<div id="outline-container-not-everybody-wants-tech-society" class="outline-3">
<h3 id="not-everybody-wants-tech-society"><span class="section-number-3">3.8.</span> Surely everybody wants to live in a prosperous, technologically-advanced society, right?</h3>
<div class="outline-text-3" id="text-not-everybody-wants-tech-society">
<p>
Contrary to popular belief, not everybody wants to live in a technologically-advanced society where everybody lives harmoniously with each other.
Many people assume that everybody wants exactly this, and that this implies the existence of an objectively-correct morality, but there are some notably interesting ideologies that oppose it: Efilism and Anarcho-Primitivism.
</p>

<p>
<a href="https://thewaywardaxolotl.blogspot.com/2017/06/efilism.html">Efilists</a> disagree because they believe in absolute negative-utilitarianism, that not even the existence of the smallest quantity of pain can ever be morally justified.
Efilists recognize that wherever life exists, problems will never go away.
Efilists thus believe that the most morally correct thing to do would be to eliminate all life so that problems will stop existing forever.
</p>

<p>
It&rsquo;s also naive to believe that technology is the solution to all of humanity&rsquo;s problems.
It is impossible for life to exist without problems, because once again, problems will never go away for as long as life continues to exist.
Anarcho-Primitivists (Anprims) even argue that technology causes more problems than it solves.
</p>

<p>
Both of these ideologies have their shortfallings, but in some ways, these two ideologies are more enlightened than the conventional Humanist worldview of the West.
There might even be more ideologies that oppose this premise than just the two counter-examples that I have mentioned here.
But the bottom line is that it&rsquo;s not universally agreed upon that a utopia where maximal morality is achieved would be a harmonious, technologically-advanced society.
Hence, the premise that everybody wants to achieve that cannot be assumed as a basis for objective morality.
</p>

<p>
The instinctive generation of values by our brains does not provide us with a basis for value either, unless we make a conscious choice to an important question, and we recognize that it technically has no rational basis.
Answering <a href="https://thewaywardaxolotl.blogspot.com/2023/06/lucifers-question.html">Lucifer&rsquo;s Question to affirm or reject life</a> is the point at which a subject crosses the <a href="#why-not-objective">is-ought gap</a>.
</p>
</div>
</div>

<div id="outline-container-not-an-appeal-to-people" class="outline-3">
<h3 id="not-an-appeal-to-people"><span class="section-number-3">3.9.</span> Isn&rsquo;t it an appeal to the people fallacy to argue for societies based on consensus?</h3>
<div class="outline-text-3" id="text-not-an-appeal-to-people">
<p>
No. Appeal to the People might be a valid fallacy for epistemological or scientific reasoning, but it&rsquo;s <i>not</i> a legitimate fallacy when reasoning about ethical or political philosophy.
Epistemology and Science are based on sensory knowledge, whereas Ethics and Politics are based on emotional/value knowledge.
If anything, the real fallacy here is trying to apply sensory knowledge outside of its scope of appropriate use.
</p>
</div>
</div>

<div id="outline-container-not-a-subjectivist-fallacy" class="outline-3">
<h3 id="not-a-subjectivist-fallacy"><span class="section-number-3">3.10.</span> Isn&rsquo;t it a subjectivist fallacy to insist that morality is perspective-dependent?</h3>
<div class="outline-text-3" id="text-not-a-subjectivist-fallacy">
<p>
No. This lacks an understanding about the epistemological limits of human reasoning.
Epistemology and science are based on sensory knowledge, whereas morality is based on emotional/value knowledge.
Sensory knowledge about reality is convergent between multiple minds, whereas <a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-subjectivity.html">emotional/value knowledge isn&rsquo;t necessarily so</a>.
The real fallacy here is trying to apply sensory knowledge outside of its scope of appropriate use.
</p>

<blockquote>
<p>
Doesn&rsquo;t science use some value judgments too? (e.g. certain analytical methods on observation are more accurate than others) This would mean that science is also based on value to some extent, right?
</p>
</blockquote>
<p>
To an extent, yes.
But the difference is that morality isn&rsquo;t based on sensory knowledge at all.
Read more: <a href="https://thewaywardaxolotl.blogspot.com/2023/08/theories-of-knowledge.html">Theories of Knowledge</a>
</p>

<blockquote>
<p>
But if we assume there couldn&rsquo;t be objective moral standards, then people will have the freedom to do whatever they want.
It would also imply that no one and no action can be morally judged as &ldquo;bad&rdquo; or &ldquo;good&rdquo;, including the Holocaust.
</p>
</blockquote>
<p>
Not necessarily.
Even if we conclude subjective morality, there are still laws that are <a href="https://en.wikipedia.org/wiki/Intersubjectivity">intersubjectively</a> agreed upon that prevent people from doing whatever they want.
And I can still judge people even though I don&rsquo;t believe in objective morality.
I do it all the time, so there&rsquo;s no contradictions there.
</p>

<p>
It is true that the Holocaust (and every historical event for that matters) is and was not objectively bad since there&rsquo;s always a perspective from which they could be viewed as &ldquo;good&rdquo;.
But that doesn&rsquo;t mean that we can&rsquo;t still view them as &ldquo;bad&rdquo; from a rational and clearly-defined perspective.
</p>
</div>
</div>

<div id="outline-container-Qs-for-moralists" class="outline-3">
<h3 id="Qs-for-moralists"><span class="section-number-3">3.11.</span> Questions For Moralists About Universal Rights</h3>
<div class="outline-text-3" id="text-Qs-for-moralists">
<blockquote>
<p>
There is a universal set of rights that every individual should be entitled to.
</p>
</blockquote>
<ul class="org-ul">
<li>What is this so-called universal set of rights?</li>
<li>Can you please state every right within this universal set?</li>
<li>Why does this universal set of rights exist?</li>
<li>Where does this universal set of rights come from? What is your <a href="https://thewaywardaxolotl.blogspot.com/2023/05/what-is-value.html">theory of value</a>?</li>
<li>Why is this so-called universal set of rights better than every other theory of rights?</li>
<li>Who enforces it? If you can&rsquo;t enforce it, why should I care about it?</li>
<li>What happens if people disobey or violate it?</li>
<li>Why can&rsquo;t everybody agree on which rights should be included in the universal set?</li>
<li>Why don&rsquo;t most people already follow and abide by this universal set of rights?</li>
<li>Do you believe it&rsquo;s immoral to force someone else to conform to your own morality? Why or why not?</li>
<li>How do you explain and reconcile how moral views vary from culture to culture, and have changed over time?</li>
<li>Why should I support other people&rsquo;s universal rights, when it doesn&rsquo;t benefit or affect me?</li>
<li>How can you prove to me that you didn&rsquo;t just make this all up?</li>
</ul>
<p>
<a href="../epistemology/reasoning-skills#philosophical-razors">Occam&rsquo;s Razor</a> concludes that the simpler belief is that there is no universal set of human rights.
If moralists don&rsquo;t have any arguments for why there is a &ldquo;universal set of human rights&rdquo;, then they should concede that it doesn&rsquo;t exist.
</p>

<p>
People understand that international human rights are a recent construct, one that has been <i>selectively</i> applied over and over.
But they ignore that history has rarely ever operated in this fashion, except in limited capacity.
</p>
</div>
</div>
</div>

<div id="outline-container-selfishnes-vs-altruism-questions" class="outline-2">
<h2 id="selfishnes-vs-altruism-questions"><span class="section-number-2">4.</span> Selfishness Versus Altruism Questions</h2>
<div class="outline-text-2" id="text-selfishnes-vs-altruism-questions">
</div>
<div id="outline-container-definition-of-selfishness" class="outline-3">
<h3 id="definition-of-selfishness"><span class="section-number-3">4.1.</span> Wouldn&rsquo;t a more coherent definition of the word &ldquo;selfishness&rdquo; be &ldquo;pursuing your own interests at the expense of others&rdquo;?</h3>
<div class="outline-text-3" id="text-definition-of-selfishness">
<p>
No, not at all. Consider the following dictionary entries:
</p>
<ul class="org-ul">
<li><a href="https://en.wiktionary.org/wiki/selfishness#English">Wiktionary defines selfishness as</a>: The quality of being selfish; the condition of putting one&rsquo;s own interests before those of others.</li>
<li><a href="https://www.merriam-webster.com/dictionary/selfishness">Merriam Webster defines selfishness as</a>: The quality or state of being selfish : a concern for one&rsquo;s own welfare or advantage at the expense of or in disregard of others.</li>
<li><a href="https://www.dictionary.com/browse/selfishness">Dictionary.com defines selfishness as</a>: The quality or state of caring only for oneself or one&rsquo;s own interests.</li>
</ul>
<p>
The phrases &ldquo;regardless of others&rdquo;, &ldquo;without regard for others&rdquo;, or &ldquo;in disregard of others&rdquo; all simply mean that you are concerned with yourself, and not concerned with other people. In other words, you are acting for your benefit, not theirs. On the other hand, a prepositional phrase like &ldquo;at the expense of others&rdquo; has very different semantics since it would imply that you can only benefit yourself if others are negatively affected by your actions.
</p>
</div>
</div>

<div id="outline-container-altruism-and-evolution" class="outline-3">
<h3 id="altruism-and-evolution"><span class="section-number-3">4.2.</span> Isn&rsquo;t Altruism part of human evolution?</h3>
<div class="outline-text-3" id="text-altruism-and-evolution">
<p>
No, it isn&rsquo;t. All of the so-called examples of altruism in human evolution are misunderstandings of how evolution actually works:
</p>
<ul class="org-ul">
<li><a href="https://www.amazon.com/dp/B0BPXJ85W7">Debunking the Selfish Gene by T. K. Van Allen</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Altruism and Selfishness</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2014/04/bees-are-not-social.html">Bees are not Altruistic</a></li>
<li><a href="https://www.youtube.com/watch?v=K97OP2p9JTQ">Pathological Altruism</a></li>
<li><a href="https://thewaywardaxolotl.blogspot.com/2014/04/family-and-society.html">Family, Transfers of Energy, and Exchanges of Labor</a></li>
</ul>
<p>
If anything, altruism is self-defeating, and any attempt to establish altruism in nature would be quickly erased as soon as evolution takes back the helm and reinstates selfishness.
Altruism cannot evolve, due to the free-rider problem.
</p>
</div>

<div id="outline-container-reciprocal-altruism" class="outline-4">
<h4 id="reciprocal-altruism"><span class="section-number-4">4.2.1.</span> What about Reciprocal Altruism?</h4>
<div class="outline-text-4" id="text-reciprocal-altruism">
<p>
If Altruism is defined as &ldquo;acting to benefit others&rdquo;, then Reciprocal Altruism is an oxymoron.
If it&rsquo;s guaranteed that you&rsquo;re going to get helped back, then it&rsquo;s not really altruism. It&rsquo;s selfishness and <a href="../FAQs/morality-FAQs#cooperation-vs-collectivism">cooperation</a>.
</p>
</div>
</div>

<div id="outline-container-kin-selection-theory-bogus" class="outline-4">
<h4 id="kin-selection-theory-bogus"><span class="section-number-4">4.2.2.</span> What about Kin Selection Theory providing a basis for Altruism?</h4>
<div class="outline-text-4" id="text-kin-selection-theory-bogus">
<p>
Main Article: <a href="https://thewaywardaxolotl.blogspot.com/2019/07/kin-selection-theory-is-wrong.html">Why Kin Selection Theory is Wrong</a>.
</p>

<p>
The nutshell summary is that:
</p>
<ol class="org-ol">
<li>Parents care for their children because they have strong selfish incentives to do so for their own reproductive success,</li>
<li>Kin altruism between siblings is best explained as the parents&rsquo; selfish behavior being expressed in the children as part of their extended phenotype (cooperative children are easier to raise than non-cooperative children),</li>
<li>Stotting/pronking is a demonstration to predators to try catching someone else in the herd that is obviously less physically fit than the pronker, and</li>
<li>Friends helping friends is cooperation motivated by selfish interest and the <a href="https://thewaywardaxolotl.blogspot.com/2014/04/family-and-society.html">moral accounting system</a>, not &ldquo;reciprocal altruism&rdquo; (which is oxymoronic since altruism is selfless).</li>
<li>Other purported examples of kin altruism can be further debunked on a case-by-case basis.</li>
</ol>

<p>
Suppose you have a population of individuals who are altruistic (that is, self-sacrificing) for the good of the race or species (or any group &#x2013; it doesn&rsquo;t matter).
Now suppose you introduce a variant individual who is purely selfish: only works for the good of his children, not the good of the group.
As a member of the group, he will receive transfers of energy from others, but he will not give anything back, and thus he will have more energy to invest in his offspring.
The selfish strategy will always outcompete the altruistic strategy.
</p>

<p>
That is why love is a very narrow thing.
We care for our mates, our children, our grandchildren, perhaps a little for our nephews and nieces, but that&rsquo;s about it.
Even though we all share 99.9% of our DNA with one another, we are still selected for reproductive selfishness, because any deviation from that strategy would be quickly eliminated by natural selection.
</p>
</div>
</div>

<div id="outline-container-bees-and-ants-arent-altruistic" class="outline-4">
<h4 id="bees-and-ants-arent-altruistic"><span class="section-number-4">4.2.3.</span> Aren&rsquo;t worker ants and worker bees examples of altruism existing in Nature, since they can&rsquo;t reproduce and thus only work for the good of their species?</h4>
<div class="outline-text-4" id="text-bees-and-ants-arent-altruistic">
<p>
It is true that worker bees and worker ants can&rsquo;t reproduce, but once again, this is a misunderstanding of how evolution works in <a href="https://en.wikipedia.org/wiki/Haplodiploidy">haplodiploid species like ants, bees, and wasps</a>.
Evolution is selecting for the genes of the Queens, not the worker ants.
The Queen has control over which eggs get fertilized with sperm stored from mating, so the drones are pure extensions of the Queen because they only carry her genes.
A male&rsquo;s genes are from its mother, a worker&rsquo;s genes are from its mother and its father&rsquo;s mother.
In bees and ants, all genes pass through a female body at least every second generation.
Usually, that female body was a Queen. This means that all ant genes are selected for their ability to help Queens reproduce.
Thus, this is <i>not</i> a case of altruism existing in Nature.
</p>

<p>
In other cases when organisms ostensibly sacrifice themselves for the survival of the species, they do so because it ensures the survival of their children, not their species, which increases their reproductive success.
If organisms did sacrifice themselves for their own species, but not their children, then their genes would die out, and altruism would cease to exist within that species.
</p>

<p>
For more information, read: <a href="https://thewaywardaxolotl.blogspot.com/2014/04/bees-are-not-social.html">Bees are not Altruistic</a>.
</p>
</div>
</div>
</div>

<div id="outline-container-helping-others" class="outline-3">
<h3 id="helping-others"><span class="section-number-3">4.3.</span> Doesn&rsquo;t helping out your friends and family count as altruism?</h3>
<div class="outline-text-3" id="text-helping-others">
<p>
Usually no, and this is also a misunderstanding of what true altruism actually is.
If you&rsquo;re helping people out who will probably help you back in the future or return the favor, then that&rsquo;s selfish behavior, not altruistic behavior.
When people are helping out their family and friends, <a href="https://thewaywardaxolotl.blogspot.com/2014/04/family-and-society.html">they are typically doing transactions between their moral accounting systems</a>.
These accounting systems evolved not because humans evolved to be altruistic, but rather because <a href="https://en.wikipedia.org/wiki/Tit_for_tat">tit-for-tat</a> has proven to be the most effective game-theoretical strategy.
</p>
</div>
</div>

<div id="outline-container-helping-everybody" class="outline-3">
<h3 id="helping-everybody"><span class="section-number-3">4.4.</span> Why shouldn&rsquo;t we help everybody?</h3>
<div class="outline-text-3" id="text-helping-everybody">
<p>
It&rsquo;s a <a href="https://en.wikipedia.org/wiki/Fallacy_of_composition">Composition Fallacy</a> to assume that being able to help others implies that we can collectively help the entire world.
<a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Altruism is not sustainable in nature</a>.
At most, we can help people who are likely to help ourselves, and that is the natural limit to which people can sustainably help others.
</p>
</div>
</div>

<div id="outline-container-effective-altruism" class="outline-3">
<h3 id="effective-altruism"><span class="section-number-3">4.5.</span> What&rsquo;s wrong with Effective Altruism?</h3>
<div class="outline-text-3" id="text-effective-altruism">
<p>
Effective Altruism (EA) is a 21st-century social movement that purports to &ldquo;use evidence and reason to figure out how to benefit others as much as possible, and taking action on that basis&rdquo;.
EA is a <a href="#what-is-humanism">Humanist ideology</a> that is based on false assumptions, and is contrary to <a href="../">biological realism</a>.
</p>

<p>
For starters, EA raises the question of why anyone should be obligated to help others, at the expense of improving their own future and their descendants&rsquo; futures instead.
<a href="https://thewaywardaxolotl.blogspot.com/2015/04/altruism-and-selfishness.html">Humans are naturally selfish</a>.
While people could help others if they wanted to, the people who do so are ultimately self-sacrificing their own futures, so EA is not a sustainable ideology for humanity.
EA also assumes a <a href="#helping-everybody">fallacy of composition</a> since EA believes that people can and should help everyone.
</p>

<p>
EA also assumes Utilitarianism, <a href="../FAQs/morality-FAQs#utilitarianism">which fails to account for individual perspectives and the calculation problem</a>.
To the contrary, a lot of charities that would supposedly have the greatest amount of &ldquo;good&rdquo; for humanity would actually <i>worsen</i> the greatest problems that humanity is currently facing.
For example, programs to prevent malaria, provide clean water, and feed starving families in Sub-Saharan Africa would <a href="../FAQs/overpopulation-FAQs#rising-wealth-and-fertility">hasten the Earth&rsquo;s likelihood of becoming overpopulated</a> and exacerbate dysgenics.
We certainly sympathize with those who do not have enough to eat or drink, but inadvertently boosting the fertility of the developing world would still make the humanity worse off as a whole by exacerbating ecological overshoot, while doing nothing to raise the Earth&rsquo;s carrying capacity or to slow its population growth.
</p>

<p>
Unfortunately, most EA proponents are oblivious to the Earth&rsquo;s ongoing ecological overshoot because they tend to believe in <a href="../FAQs/overpopulation-FAQs#why-DTT-is-wrong">Demographic Transition Theory</a> (they think that populations stabilize).
<a href="../FAQs/overpopulation-FAQs#if-no-pop-regulation">Billions of people will die without population control</a>,
and yet there are no major EA proponents who are doing anything to educate people and raise the political will to enforce EPC.
In fact, many effective altruists oppose population control on the basis that it would prevent some people from fulfilling their desires.
They believe that population control is immoral because it conflicts with their humanist values.
This ignores that reproduction has serious consequences that affect <i>everybody</i>, and it also ignores how <a href="../FAQs/overpopulation-FAQs#human-rights">population control would protect more human rights than it &ldquo;violates&rdquo;</a>.
Since EA proponents have a flawed understanding of human nature and they don&rsquo;t understand population dynamics, this is a great illustration of how the calculation problem undermines the EA intent to accomplish the &ldquo;greatest benefit for all&rdquo;.
Ironically, many of our <a href="https://www.youtube.com/watch?v=I9gu-Nodlnc">Pragmatopian proposals</a> would accomplish what effective altruists would want to achieve for Humanity, if only they had the knowledge and rationality for understanding and accepting them.
And yet, most EAs would still oppose EPC anyway because it does not align with their Humanist values.
</p>

<p>
Two other focuses of EA are animal welfare and AI existential risk, but it&rsquo;s debatable if these are even worth pursuing.
Humans are omnivores, and <a href="https://expandingrationality.substack.com/p/diet-and-human-evolution">we evolved to eat meat</a>.
Additionally, <a href="https://thewaywardaxolotl.blogspot.com/2022/02/motivation.html">if pain and pleasure balance out</a>, then it&rsquo;s questionable if animals even suffer as much as it&rsquo;s claimed that they do.
I&rsquo;m also not convinced that AGI will pose an existential risk to humanity, but <a href="../civilization/technology#AI-pros-cons">I am pessimistic about how AI will affect humanity&rsquo;s future</a>.
</p>

<p>
Lastly, I agree with the <a href="https://en.wikipedia.org/wiki/Effective_altruism#Other_criticisms">other criticisms made against EA on Wikipedia</a>, aside from the BS concern on demographics.
EA is likely to give more influence to society&rsquo;s wealthy elites if it continues to rise in popularity, and every effective altruist will use EA to mask their selfishness.
EA is a pseudo-intellectual movement and <a href="https://thewaywardaxolotl.blogspot.com/2014/07/the-communists-who-took-power-in.html">utopian ideology</a>, and it has cult tendencies.
<a href="https://www.youtube.com/watch?v=I9gu-Nodlnc">EA is not focused on Humanity&rsquo;s greatest problems</a>.
</p>
</div>
</div>

<div id="outline-container-cynicalism-is-not-selfishness" class="outline-3">
<h3 id="cynicalism-is-not-selfishness"><span class="section-number-3">4.6.</span> Isn&rsquo;t it misguided to have such a cynical view of human nature?</h3>
<div class="outline-text-3" id="text-cynicalism-is-not-selfishness">
<p>
We don&rsquo;t equate selfishness to &ldquo;cynicalism&rdquo;, hence why we define the two differently.
If someone is selfish, then they are prioritizing the pursuit of their self interests first and foremost, but they will often have to obey their moral accounting systems as a means to an end.
</p>

<p>
We define cynicalism as being selfish, except that you don&rsquo;t adhere to your moral accounting system.
If someone helps out a cynical person, the cynical person would accept the help, but then they wouldn&rsquo;t help the helper back, which would incentivize the helper to not help the cynical person in the future.
</p>
</div>
</div>

<div id="outline-container-why-we-should-be-selfish" class="outline-3">
<h3 id="why-we-should-be-selfish"><span class="section-number-3">4.7.</span> Why should we be selfish?</h3>
<div class="outline-text-3" id="text-why-we-should-be-selfish">
<p>
Because we have no other choice.
We can only do what we want to do, so in that sense, we&rsquo;re always being (psychologically) selfish.
Some people might want to be nicer than others, and some might want to be cruel.
Regardless, all voluntary acts are based on desires.
</p>

<p>
<a href="../epistemology/free-will#determinism-vs-free-will">Desires are not chosen</a>.
A serial killer chooses to kill, but does not choose to want to kill.
Likewise, a philanthropist chooses to help the poor, but does not choose to want to help the poor.
Both are acting on their desires.
Both are psychologically selfish.
</p>

<p>
<a href="#altruism-and-evolution">Altruism cannot evolve due to the free-rider problem</a>, so life evolved to be selfish instead.
</p>
</div>
</div>

<div id="outline-container-altruism-and-civilization" class="outline-3">
<h3 id="altruism-and-civilization"><span class="section-number-3">4.8.</span> Isn&rsquo;t Altruism integral to human civilization?</h3>
<div class="outline-text-3" id="text-altruism-and-civilization">
<p>
No, not at all.
Society is not based on altruism at any level: global, racial, national, or even tribal.
Society is based on cooperation between selfish individuals, not Altruism and Collectivism.
</p>

<p>
<a href="https://www.youtube.com/watch?v=K97OP2p9JTQ">Every altruistic civilization is doomed to fail</a>.
</p>
</div>

<div id="outline-container-cooperation-vs-collectivism" class="outline-4">
<h4 id="cooperation-vs-collectivism"><span class="section-number-4">4.8.1.</span> The difference between cooperation versus collectivism</h4>
<div class="outline-text-4" id="text-cooperation-vs-collectivism">
<p>
First, we have to define <i>collectivism</i>: when individuals place the collective above the individual for the sake of the collective.
</p>

<p>
Next, we have to define <i>cooperation</i>.
Cooperation is when rational individuals work together for mutual benefit as a way to achieve their self-interests, however, they <i>never</i> place the group above the individuals for the sake of the group.
Cooperation requires trust (the expectation of reciprocity), and every individual who <i>collaborates</i> does so with the expectation that they will get something in return.
</p>

<p>
Typically, most collectivists will take examples of <i>cooperation</i> and erroneously classify those examples as situations where collectivism is a good thing, in order to promote actual instances of collectivism, such as socialism, pious religions, and authoritarianism.
When collectivists frame cooperation as collectivism, they often portray it as being based on empathy or affection instead of trust since they don&rsquo;t understand that cooperation is based on selfishness.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-libertarian-questions" class="outline-2">
<h2 id="libertarian-questions"><span class="section-number-2">5.</span> Libertarian Questions</h2>
<div class="outline-text-2" id="text-libertarian-questions">
</div>
<div id="outline-container-the-NAP" class="outline-3">
<h3 id="the-NAP"><span class="section-number-3">5.1.</span> Isn&rsquo;t the Libertarian Non-Aggression Principle (NAP) the objective origin of morality?</h3>
<div class="outline-text-3" id="text-the-NAP">
<p>
No, and for several reasons.
</p>
<ol class="org-ol">
<li><a href="../civilization/case-against-libertarianism#problems-with-deontological-ethics">Consequentialist Ethics are superior to deontological ethics</a>.</li>
<li><a href="../civilization/case-against-libertarianism#NAP">It is misleading to think of the Libertarian NAP as a single principle</a>.</li>
<li><a href="../civilization/case-against-libertarianism#life-is-zero-sum">The Libertarian NAP ignores that life becomes zero-sum when a population reaches the carrying capacity of the environment</a>.</li>
</ol>
</div>
</div>

<div id="outline-container-necessary-evil" class="outline-3">
<h3 id="necessary-evil"><span class="section-number-3">5.2.</span> But there&rsquo;s no such thing as a necessary evil.</h3>
<div class="outline-text-3" id="text-necessary-evil">
<p>
This question assumes that &ldquo;evil&rdquo; is well-defined and objective, but it isn&rsquo;t. <a href="#problems-with-deontological-ethics">It also assumes that humans should act according to deontological ethics</a>.
</p>
</div>
</div>

<div id="outline-container-universally-preferable" class="outline-3">
<h3 id="universally-preferable"><span class="section-number-3">5.3.</span> Why isn&rsquo;t morality the same thing as &ldquo;universally preferable behavior&rdquo;?</h3>
<div class="outline-text-3" id="text-universally-preferable">
<p>
Because moral preferences depend on perspective.
</p>

<p>
For example, most people in Japan, the United States, and Europe view the <a href="https://en.wikipedia.org/wiki/Assassination_of_Shinzo_Abe">Assassination of Shinzo Abe</a> to be a &ldquo;morally bad&rdquo; thing since they like Japan, but most people in China and Korea view his assassination to be a &ldquo;morally good&rdquo; thing because they hate Japan.
If it was truly the case that it is &ldquo;universally preferable&rdquo; to condemn murder, then why are there hundreds of millions people who applaud the assassination and celebrate the assassin as a hero?
</p>


<p>
The following addresses a list of objections by someone who defines morality as &ldquo;universally preferable behavior&rdquo;.
</p>

<blockquote>
<p>
Nobody can logically defend the position that NAP-violations can be morally good.
</p>
</blockquote>
<p>
Of course they can.
For the same reason why Libertarians can&rsquo;t agree on whether abortion violates the NAP or not.
Or how Libertarians can&rsquo;t agree on whether blackmailing is NAP-compliant.
Or how Ancaps may drop-kick people out who disagree with their interpretation of the NAP.
The bottom line is that &ldquo;Aggression&rdquo; is subjective, so the NAP is also subjective.
</p>

<blockquote>
<p>
Only creatures that have the mental capacity to conceive of abstract rules can be bound and protected by said rules - and only if they reciprocate.
</p>
</blockquote>
<p>
That is very arbitrary.
By the same logic, a newborn infant or a person with severe dementia may not be protected by the Libertarian NAP if they lack the mentally ability to understand it.
Most people would disagree and insist that those humans deserve the same legal protections as more mentally capable humans.
</p>

<blockquote>
<p>
In moral terms, the only important criteria is if they&rsquo;re able to understand and reciprocate rules. Moral rules, if they exist, are a subset of these that ought to be universally upheld.
</p>
</blockquote>
<p>
According to who, and why?
For starters, this claim doesn&rsquo;t make any sense since your definition of morality has been easily debunked.
</p>

<blockquote>
<p>
Modern moral theory says you aren&rsquo;t obligated to help someone hanging off the edge of a cliff.
</p>
</blockquote>
<p>
Modern Liberals disagree.
Who&rsquo;s to say that your beliefs are more correct than theirs, besides yourself?
</p>

<blockquote>
<p>
Other species are not subject to the same moral protections as us, since they can neither conceive nor reciprocate moral norms.
</p>
</blockquote>
<p>
If that&rsquo;s true, then human babies, severely retarded people, and the mentally disabled elderly do not have the same legal protections as everyone else.
This contradicts most people&rsquo;s moral intuitions in the modern world.
</p>

<blockquote>
<p>
Animals shouldn&rsquo;t breed if there isn&rsquo;t enough energy around to sustain themselves. Just like a mother is being cruel/evil if she has babies that she cannot feed.
</p>
</blockquote>
<p>
And yet animals will still breed anyway irregardless.
If there&rsquo;s a famine and civilization collapses, the most reasonable thing to do from a biological/evolutionary/game-theoretic point-of-view is to take what you can and give nothing back.
Because that is what will maximize your reproductive success.
And all the organisms that follow that strategy will spread their genes to a greater extent, whereas the most altruistic ones who choose to have fewer offspring will have their kind die out.
</p>

<blockquote>
<p>
&ldquo;Humans aren&rsquo;t fighting over the last bits of air, land, water, etc.
</p>
</blockquote>
<p>
That&rsquo;s literally what they&rsquo;ve done all throughout modern history.
The modern era is only an exception to that, and <a href="../civilization/technology#modern-civilization-permanent-collapse">it won&rsquo;t last forever unless we do something about it</a>.
</p>

<blockquote>
<p>
Our competitions are chosen / voluntary.
</p>
</blockquote>
<p>
No, they aren&rsquo;t.
If competition was truly voluntary, then there would be no competition at all because everyone would avoid it.
One of the most fundamental principles of geopolitics is that selfish players (countries in this case) will compete against each other for scarce resources.
And there are no permanent friends, only temporary allies for as long as the right conditions for cooperation hold true.
</p>

<blockquote>
<p>
Having one more human born on this planet won&rsquo;t hurt any existing human.
</p>
</blockquote>
<p>
If it&rsquo;s exactly <i>one</i> human, then probably not.
But it isn&rsquo;t.
The world population is increasing by several tens of millions of humans every year.
Only a fool would insist that this continuing trend could never go wrong on a planet with finite resources.
Unlimited population growth is unsustainable, and that&rsquo;s what we&rsquo;re heading towards.
</p>

<blockquote>
<p>
The energies in our ecosystems aren&rsquo;t that scarce.
</p>
</blockquote>
<p>
Yes they are, and they always have been.
And it will only become more apparent as the world population continues to grow.
If that continues, all it will take is another major crisis or two to catastrophically disrupt the world&rsquo;s food/resource supply chains.
In such an unfortunate event, humanity will catch a glimpse of how biological systems have <i>always</i> worked.
</p>
</div>
</div>
</div>

<div id="outline-container-misc-questions" class="outline-2">
<h2 id="misc-questions"><span class="section-number-2">6.</span> Miscellaneous Questions</h2>
<div class="outline-text-2" id="text-misc-questions">
</div>
<div id="outline-container-meaningless-of-standpoint-theory" class="outline-3">
<h3 id="meaningless-of-standpoint-theory"><span class="section-number-3">6.1.</span> The Meaninglessness of the Standpoint Theory of Truth</h3>
<div class="outline-text-3" id="text-meaningless-of-standpoint-theory">
<p>
See: <a href="../epistemology/representationalism#meaningless-of-standpoint-theory">Philosophy of Truth: The Meaninglessness of the Standpoint Theory of Truth</a>.
</p>
</div>
</div>

<div id="outline-container-thoughts-on-less-wrong" class="outline-3">
<h3 id="thoughts-on-less-wrong"><span class="section-number-3">6.2.</span> What do you think about rationalist forums like lesswrong.com?</h3>
<div class="outline-text-3" id="text-thoughts-on-less-wrong">
<p>
There are multiple reasons why I don&rsquo;t feel aligned with online rationalist forums like <a href="https://www.lesswrong.com/">lesswrong.com</a>:
</p>
<ul class="org-ul">
<li>They believe in morality, and they&rsquo;re <a href="#what-is-humanism">humanists</a>.</li>
<li>They believe in altruism (e.g. <a href="#effective-altruism">Effective Altruism</a>).</li>
<li>Many/Most of them aren&rsquo;t <a href="https://odysee.com/@BlitheringGenius:2/BiologicalRealism:b">biological realists</a> (selfishness, sex realism, <a href="../FAQs/race-FAQs">race realism</a>, sexuality, population dynamics, eugenics/dysgenics, etc and the <a href="https://thewaywardaxolotl.blogspot.com/2023/11/debunking-selfish-gene.html">phenocentric theory of biological purpose</a>).</li>
<li>I agree with them that it&rsquo;s rational to be concerned with how the ongoing advancement of AI will affect humans. However, <a href="../civilization/technology#AI-pros-cons">the bigger problem that we should be concerned with for the immediate future is how people will misuse and/or abuse AI</a>. This is guaranteed to happen regardless of whether AI leads to a malevolent singularity or not.</li>
<li>They are <a href="https://thewaywardaxolotl.blogspot.com/2015/01/technology-and-progress.html">too optimistic about technology</a> and its (future) effects on humanity (e.g. space colonization, cryogenics, <a href="../FAQs/eugenics-FAQs#genetic-engineering">genetic engineering</a>, etc).</li>
<li>They tend to place <a href="../epistemology/critique-of-academic-research">too much faith in academic research</a>.</li>
<li>There isn&rsquo;t enough discussion of <a href="../civilization/georgism-crash-course">Georgism</a> and resource scarcity in those circles.</li>
<li>Most of them greatly underestimate how much <a href="../FAQs/overpopulation-FAQs">overpopulation is a potential threat to humanity</a>.</li>
<li>Most of them aren&rsquo;t in favor of <a href="../FAQs/eugenics-FAQs">Eugenic Population Control</a>, even though <a href="../FAQs/overpopulation-FAQs#low-fertility-countries-and-EPC">there&rsquo;s good reasons to enforce it even in low-fertility countries</a>.</li>
<li>Most of them don&rsquo;t apply the <a href="https://en.wikipedia.org/wiki/Subject_and_object_(philosophy)">subject-object dichotomy</a> for understanding truth, knowledge, free will, value, etc.</li>
<li>Most of them aren&rsquo;t consciously aware of <a href="../language/sapir-whorf-theory">Sapir-Whorf Theory</a>, its implications, and its applications.</li>
<li>The rest of their epistemology is hit-or-miss.</li>
</ul>
<p>
To be fair though, most of them are smarter and more rational than the average person.
</p>
</div>
</div>
</div>

<div id="outline-container-technology-and-moral-progress" class="outline-2">
<h2 id="technology-and-moral-progress"><span class="section-number-2">7.</span> How Does Technology Create The Illusion Of Moral Progress?</h2>
<div class="outline-text-2" id="text-technology-and-moral-progress">
<p>
&ldquo;Moral Progress&rdquo; is an illusion created by the advancement of technology.
Without technology, we wouldn&rsquo;t have seen any improvements in material conditions for humans.
Historically, humans only started to care about moral progress when they no longer had to focus on just being able to survive 24/7, something that has only been made possible by the advent of technology.
A human who is focused on survival 24/7 would never have any time to think nor care about what&rsquo;s moral because they&rsquo;re only focused on what helps them survive, as well as what helps their community survive since the community aids the survival.
If humans had historically prioritize the morals that most people have in the modern world over their own survival, then their genes and memes would fail to make the next generation, compared to other humans who did.
</p>


<p>
Large-scale cooperation facilitated by Capitalism and the Rule of Law has made it possible for more people than ever to not have to live in abject poverty.
</p>
<ul class="org-ul">
<li>The widespread adoption of vaccines and modern medicine has made it possible to eradicate many diseases that have historically plagued human societies.</li>
<li>In modern post-WWII times, war has been quite uncommon compared to its historical presence, but this has only been made possible due to the establishment of improved living conditions around the world (thus reducing the need to compete for resources worldwide), free trade (which reduces conflicts between nations), and the intense favorability to avoid the gruesome potential for destruction and nuclear war that has never been seen before.</li>
<li>Modern contraception and birth control made it possible to not have children born into undesirable conditions.</li>
<li><a href="../civilization/why-georgism-lost-popularity#20th-century-mistakes">The automobile relieved the pressure on land values</a> and land rent by making it possible for people to move out of the cities and into the suburbs, although this has only been a temporary fix since the core problem has yet to be resolved by universal LVT.</li>
</ul>
</div>

<div id="outline-container-illusions-in-moralist-communities" class="outline-3">
<h3 id="illusions-in-moralist-communities"><span class="section-number-3">7.1.</span> Technological Changes That Various Moralists Would Claim To Be &ldquo;Moral Progress&rdquo;</h3>
<div class="outline-text-3" id="text-illusions-in-moralist-communities">
<p>
The following is a list of changes enabled by technology that various moralists would claim to be &ldquo;moral progress&rdquo; according to their perceptions of the world.
</p>
<ul class="org-ul">
<li>Vegan diets only being made possible since humans don&rsquo;t rely on hunting and gathering anymore, clothing made from plants or plant materials instead of animal hides and fabrics, et cetera (according to vegans&rsquo; perspectives).</li>
<li>Gender reassignment surgeries / sex change operations / hormone therapies that make it possible for gender dysphoric people to change their bodies to be more like the opposite sex and less like the biological sex that they were born to.</li>
<li>Dating websites and dating apps have made it easier than ever for homosexuals and bisexuals to find a partner, and they are now the leading method for finding a partner in many parts of the world.</li>
<li>Anti-natalists view contraception and abortion as some of the most important technological inventions ever.</li>
<li>Capitalists view technology favorably because technology has caused capitalism to progress and improve people&rsquo;s standard of living.</li>
</ul>
</div>
</div>

<div id="outline-container-ideologies-future-progress" class="outline-3">
<h3 id="ideologies-future-progress"><span class="section-number-3">7.2.</span> Future Moral Progress According To Various Ideologues</h3>
<div class="outline-text-3" id="text-ideologies-future-progress">
<ul class="org-ul">
<li>The technological ability to create synthetic pills that could supply humans with necessary vitamins and minerals that can only be found in animals and not plants (some nutrition-conscious vegans have argued that this should replace eating animal products as the way to acquire those nutrients for humans and other necessarily omnivorous species).</li>
<li>Ancaps often argue that their fantasy worlds will have amazing technologies like seasteading, blockchains, and more that will enable them to live in a super &ldquo;ethical&rdquo; utopia that has never been seen before. But if new/innovative technologies are necessary to make such utopias possible, then hypothetical &ldquo;moral improvements&rdquo; like the kinds alluded to by ancaps are only made possible by advancing technologies, as it has always been the case.</li>
<li>Efilists believe that humanity should destroy the Earth and render it uninhabitable for all sentient life, but this never would have been possible in previous eras because the necessary technology for accomplishing this goal never existed prior to modernity.</li>
<li>All kinds of Utopian Ideologists want to colonize Mars because it gives them something to work towards as a means of fulfilling their needs for the <a href="../misc/industrial-society-and-its-future-manifesto#power-process">power process</a>. They also because they perceive Mars as a place of opportunity and free of foreign interference to set up whatever so-called utopia and utopian ideology that they believe in. Examples:
<ul class="org-ul">
<li>Ancaps who want Mars to be a so-called Ancapistan paradise.</li>
<li>Communists and Anarcho-Communists who want Mars to be a so-called (Anarcho)-Communist paradise.</li>
<li>Some Esperanto Speakers who would like Esperanto to become the language of Mars.</li>
</ul></li>
</ul>

<p>
Moreover, <a href="../civilization/technology#futurist-fantasies">it&rsquo;s extremely unlikely that humanity will ever colonize Mars due to the Laws of Physics and Economic Realities</a>.
</p>
</div>
</div>

<div id="outline-container-moral-progress-without-tech" class="outline-3">
<h3 id="moral-progress-without-tech"><span class="section-number-3">7.3.</span> &ldquo;Moral Progress&rdquo; That Wasn&rsquo;t Caused By Advancing Technology</h3>
<div class="outline-text-3" id="text-moral-progress-without-tech">
<ul class="org-ul">
<li>The replacement of monarchies by democracies.</li>
<li>The abolition of many cruel punishments.</li>
<li>The progression of human rights (e.g. freedom of expression, right to fair trial, etc).</li>
<li>The decline of religious persecution, racial segregation, racism, sexism, homophobia, xenophobia, ableism, etc.</li>
<li>The decline of European colonialism (it became too expensive to rule overseas colonies, and the local populations began protesting and fighting for independence). It should be noted however that European colonialism seems to have been mostly beneficial in most (but not all) cases since technologies caused declines in infant mortality rates, starvation, diseases, and other factors that have limited the local populations.</li>
</ul>

<p>
Interestingly, anarcho-primitivists are some of the few people who would argue that the progression of technology has actually caused a significant regression in moral progress, whereas virtually everyone else enthusiastically views technology as a way to continue &ldquo;moral progress&rdquo;.
Besides anarcho-primitivists, some of the most extreme communists and socialists might would believe that humanity has not made much if any moral progress since they hate capitalism so much, even though capitalism has been largely beneficial for humanity.
</p>
</div>
</div>
</div>

<div id="outline-container-when-life-becomes-zero-sum" class="outline-2">
<h2 id="when-life-becomes-zero-sum"><span class="section-number-2">8.</span> When Life Becomes Zero-Sum</h2>
<div class="outline-text-2" id="text-when-life-becomes-zero-sum">
<p>
Without cooperation, life becomes zero-sum when the population reaches the carrying capacity of its environment.
If either of those conditions are not meant (not possible to cooperate with others, or population is below environment&rsquo;s carrying capacity), then life can be &ldquo;positive sum&rdquo;.
The point in recognizing the conditions for life to be zero-sum is to show further evidence why morality is not objective.
When life does become zero-sum, it&rsquo;s every man for himself.
</p>
<ul class="org-ul">
<li>For every prey that gets eaten alive, there is a predator who doesn&rsquo;t starve to death.</li>
<li>For every prey that escapes, there is a predator who ends up starving to death.</li>
<li>For every guy who misses a job opportunity, someone else will get it instead.</li>
<li>For every male that doesn&rsquo;t get to mate with the prized female, some other victorious male does.</li>
<li>For every slave, there is a slave owner who profits big time.</li>
<li>For every guy who lost money on the stock market, someone else gained money. For every buyer, there is a seller and vice versa.</li>
<li>For every guy who lost scarce, precious resources, someone else acquired those valuable resources and used them to survive another day, become more reproductively successful, and have more offspring than the loser.</li>
<li>And so forth.</li>
</ul>
<p>
When there are winners who can only come at the expense of losers, it&rsquo;s in everyone&rsquo;s self-interest to be a winner rather than a loser.
In such cases, people are <i>not</i> obligated to care about whether that causes someone else to incur negative consequences.
Evolution is the game that runs literally everything, so that&rsquo;s the game everybody <i>has to</i> play, even if it comes at the cost of others.
</p>


<p>
Now, life doesn&rsquo;t always have to be a zero-sum game.
When individuals cooperate with each other, they can both become better off if they manage to solve the prisoner&rsquo;s dilemma between each other.
Unfortunately, it isn&rsquo;t always guaranteed that the other side won&rsquo;t defect, and that&rsquo;s why cooperating is not an objectively good choice.
</p>


<figure id="org0490cea">
<img src="../images/bad-guys-vs-anti-bad-guys-meme.jpg" alt="Meme about determining who the bad guys are.">

</figure>


<figure id="orge33693e">
<img src="../images/russell-emotive-conjugation.jpg" alt="Meme about hating foreigners to justify conquering them.">

</figure>
</div>
</div>

<div id="outline-container-glossary" class="outline-2">
<h2 id="glossary"><span class="section-number-2">9.</span> Glossary</h2>
<div class="outline-text-2" id="text-glossary">
<p>
For clarity, these are the definitions that are used throughout this FAQs post:
</p>
<dl class="org-dl">
<dt>Morality (subjective)</dt><dd>What a person thinks people should and shouldn&rsquo;t do, i.e. what a person <i>wants</i> other people to do and/or how a person <i>wants</i> other people to behave, <a href="../epistemology/axiology">according to their values</a>. Note that &ldquo;morality&rdquo; has <a href="https://en.wiktionary.org/wiki/morality#English">many different definitions</a>, so it is highly vulnerable to the <a href="../language/sapir-whorf-theory">Sapir-Whorf Effect</a>.</dd>
<dt>Morality (colloquial)</dt><dd>The intersubjective consensus (within some group of people) of &ldquo;right&rdquo; and &ldquo;wrong&rdquo;, &ldquo;good&rdquo; and &ldquo;bad/evil&rdquo;, or what people should and shouldn&rsquo;t do, usually formed according to collective values. Since what people consider to be morally right or morally wrong depends on morality, this is a circular definition, and hence a meaningless one.</dd>
<dt>Morality (platonic realm)</dt><dd>The conception that morality has a platonic realm that everybody should try to follow. This does not exist in reality.</dd>
<dt>Post-Overton</dt><dd>The philosophical position that game theory, the intrinsic selfishness of life, and <a href="../FAQs/morality-FAQs#memetics">memetics</a> are the best way to understand morality. It is similar to moral relativism since it posits that morality can only be based on subjective values (which are perspective-dependent), but it&rsquo;s different since it also embraces the game-theoretic assumptions of selfishness and rationality, as well as the <a href="../FAQs/morality-FAQs#when-life-becomes-zero-sum">zero-sum nature of life</a>. Post-Overtons believe that the only legitimate rights are legal rights.</dd>
<dt>Post-Moralism</dt><dd>The same thing as Post-Overton, but with a different name.</dd>
<dt>Amoralism</dt><dd>An absence of, indifference towards, disregard for, or incapacity for morality.</dd>
<dt>(no term)</dt><dd>Moral Objectivism is the ethical view that all or some actions have intrinsic positive value (&ldquo;are good&rdquo;) and intrinsic negative value (&ldquo;are bad/evil&rdquo;), regardless of context, consequence, or perspective.</dd>
<dt>Moral Relativism</dt><dd>The position that morality is subjective and perspective-dependent. This term covers a range of different philosophical positions with different nuances. Moral Relativists believe that different individuals, groups, and cultures can all have different conceptions of morality that are each justified according to their own perspectives.</dd>
<dt>Moral Nihilism</dt><dd>The view that nothing is morally right or morally wrong.</dd>
<dt>Moral Realism</dt><dd>The position that moral propositions refer to objective features of the world. &ldquo;Moral Realism&rdquo; is a misnomer, and a sub-category of moral objectivism.</dd>
<dt>Is-Ought Gap</dt><dd>i</dd>
<dt>Is-Ought Fallacy</dt><dd>i</dd>
<dt>Selfishness</dt><dd>Acting for your own benefit, regardless of others.</dd>
<dt>Altruism</dt><dd>Acting for the benefit of other, at some cost to oneself.</dd>
<dt>Cynicalism</dt><dd>Selfishness, except that you take what you can, and give nothing back. A cynical person does not use a moral accounting system, nor are they interested in cooperating during a prisoner&rsquo;s dilemma.
<ul class="org-ul">
<li>Note: We are aware that we are defining Cynicalism in a non-standard way, but we are doing so because we believe that the most common definition of &ldquo;Cynicalism&rdquo; is too closely related to the definition for &ldquo;Selfishness&rdquo;, and we think that &ldquo;Cynicalism&rdquo; would be better used to convey a shade of meaning that most people tend to mistakenly associate with the headword &ldquo;Selfishness&rdquo;. By explicitly defining &ldquo;Selfishness&rdquo; and &ldquo;Cynicalism&rdquo;, we can contrast the two definitions to show what &ldquo;Selfishness&rdquo; is not what most people think it is.</li>
</ul></dd>
<dt>Moral Accounting System (MAS)</dt><dd>The system of emotions in a human&rsquo;s brain (and some other species&rsquo; brains too) that motivates people to do give-and-take behavior, or exchanges of labor. Evolution caused the MAS to develop in humans since they are more reproductively successful when they engage in give and take behavior within human tribes. The MAS is the primary reason why people are not <b>cynical</b>, and the behavior that MASs encourage does not count as &ldquo;reciprocal altruism&rdquo; since &ldquo;reciprocal altruism&rdquo; is an oxymoron.</dd>
<dt>Collaboration/Cooperation</dt><dd>When rational individuals work together for mutual benefit. When people are collaborating, the group is <i>never</i> places above the individuals for the sake of the group. Cooperation requires trust (the expectation of reciprocity), and every individual who <i>collaborates</i> does so with the expectation that they will get something in return.</dd>
<dt>Collectivism</dt><dd>When individuals place the collective above the individual for the sake of the collective.</dd>
<dt>Utopian Ideology</dt><dd>Any naive ideology that people will believe in order to claim moral superiority and maintain the illusion of knowledge. <b>Utopian Ideologies</b> typically use the <b>Rhetoric of Exploitation</b>, simple-minded worldviews, moral narratives, visionary fantasies, and effective memetic propagations to delude people and spread the ideology. Read more: <a href="https://thewaywardaxolotl.blogspot.com/2014/07/the-communists-who-took-power-in.html">Utopian Ideology</a>.</dd>
<dt>The Rhetoric of Exploitation</dt><dd>A Classic Tactic used by Utopian Ideologists to replace rationalist thinking with rhetoric and self-righteous nonsense. The key is to use selective metaphors and phrases and portray the &ldquo;oppressors&rdquo; as having agency and the &ldquo;victims&rdquo; as having no agency. Read more: <a href="https://thewaywardaxolotl.blogspot.com/2013/12/the-rhetoric-of-exploitation_21.html">The Rhetoric of Exploitation</a>.</dd>
</dl>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Last Modified: 2024 April 01, 03:12</p><p class="author">Author: Zero Contradictions</p>
</div>
</body>
</html>
